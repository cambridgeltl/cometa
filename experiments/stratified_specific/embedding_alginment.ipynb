{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_INDEX=0\n",
    "DATA_DIR=\"../../data/splits/stratified_specific/\"\n",
    "FULL_CHV_PATH=\"../../data/chv.csv\"\n",
    "FEATURE_PATH=\"../../data/precomputed_features/\"\n",
    "SNOMED_PATH = \"../../data/SnomedCT_201907/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(2020) \n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))\n",
    "from src.data import *\n",
    "from src.loss import *\n",
    "from src.models import *\n",
    "from src.evaluation import *\n",
    "from src.train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load some dicts (to be used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SNOMED graph\n",
    "from data.Snomed import Snomed\n",
    "snomed = Snomed(SNOMED_PATH, taxonomy=False)\n",
    "snomed.load_snomed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create surface_to_snomed_id dict\n",
    "SF2ID = build_surface_to_snomed_id(snomed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testset_row_index_to_ed_dict dict\n",
    "ED_DICT = pkl.load(open(os.path.join(FEATURE_PATH,\"term_ed_dic_stratified_specific.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### static term -> surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "# input: static term\n",
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_bert_ts100k_embeddings_all_names_mean_full_new.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"chv_plain_term_embeddings_BERTbr_ts100k.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path, \n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path,\n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.001 AccSum: 0.001\n",
      "[epoch 1][dev ] Acc@1: 0.048 Acc@10: 0.188 Acc@100: 0.397 AccSum: 0.633\n",
      "[epoch 1][test] Acc@1: 0.056 Acc@10: 0.185 Acc@100: 0.385 AccSum: 0.626\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.103 Acc@10: 0.293 Acc@100: 0.493 AccSum: 0.889\n",
      "[epoch 2][test] Acc@1: 0.106 Acc@10: 0.295 Acc@100: 0.489 AccSum: 0.890\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.176 Acc@10: 0.400 Acc@100: 0.587 AccSum: 1.163\n",
      "[epoch 3][test] Acc@1: 0.181 Acc@10: 0.397 Acc@100: 0.589 AccSum: 1.167\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.179 Acc@10: 0.408 Acc@100: 0.592 AccSum: 1.180\n",
      "[epoch 4][test] Acc@1: 0.188 Acc@10: 0.404 Acc@100: 0.593 AccSum: 1.184\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.191 Acc@10: 0.423 Acc@100: 0.609 AccSum: 1.223\n",
      "[epoch 5][test] Acc@1: 0.200 Acc@10: 0.419 Acc@100: 0.609 AccSum: 1.227\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.201 Acc@10: 0.429 Acc@100: 0.615 AccSum: 1.244\n",
      "[epoch 6][test] Acc@1: 0.211 Acc@10: 0.429 Acc@100: 0.621 AccSum: 1.262\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.205 Acc@10: 0.435 Acc@100: 0.611 AccSum: 1.251\n",
      "[epoch 7][test] Acc@1: 0.213 Acc@10: 0.436 Acc@100: 0.619 AccSum: 1.268\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.201 Acc@10: 0.436 Acc@100: 0.610 AccSum: 1.248\n",
      "[epoch 9][dev ] Acc@1: 0.205 Acc@10: 0.441 Acc@100: 0.620 AccSum: 1.266\n",
      "[epoch 9][test] Acc@1: 0.220 Acc@10: 0.440 Acc@100: 0.622 AccSum: 1.282\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.215 Acc@10: 0.455 Acc@100: 0.631 AccSum: 1.301\n",
      "[epoch 10][test] Acc@1: 0.228 Acc@10: 0.452 Acc@100: 0.636 AccSum: 1.316\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.223 Acc@10: 0.458 Acc@100: 0.631 AccSum: 1.312\n",
      "[epoch 11][test] Acc@1: 0.237 Acc@10: 0.458 Acc@100: 0.639 AccSum: 1.334\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.226 Acc@10: 0.465 Acc@100: 0.634 AccSum: 1.326\n",
      "[epoch 12][test] Acc@1: 0.241 Acc@10: 0.464 Acc@100: 0.641 AccSum: 1.346\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.234 Acc@10: 0.473 Acc@100: 0.642 AccSum: 1.348\n",
      "[epoch 13][test] Acc@1: 0.247 Acc@10: 0.471 Acc@100: 0.649 AccSum: 1.367\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.235 Acc@10: 0.476 Acc@100: 0.643 AccSum: 1.354\n",
      "[epoch 14][test] Acc@1: 0.249 Acc@10: 0.475 Acc@100: 0.651 AccSum: 1.375\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.237 Acc@10: 0.475 Acc@100: 0.643 AccSum: 1.356\n",
      "[epoch 15][test] Acc@1: 0.250 Acc@10: 0.474 Acc@100: 0.651 AccSum: 1.375\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.244 Acc@10: 0.478 Acc@100: 0.647 AccSum: 1.368\n",
      "[epoch 16][test] Acc@1: 0.252 Acc@10: 0.479 Acc@100: 0.656 AccSum: 1.387\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.245 Acc@10: 0.486 Acc@100: 0.650 AccSum: 1.382\n",
      "[epoch 17][test] Acc@1: 0.255 Acc@10: 0.488 Acc@100: 0.660 AccSum: 1.403\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.244 Acc@10: 0.489 Acc@100: 0.650 AccSum: 1.384\n",
      "[epoch 18][test] Acc@1: 0.257 Acc@10: 0.490 Acc@100: 0.659 AccSum: 1.406\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.245 Acc@10: 0.492 Acc@100: 0.650 AccSum: 1.387\n",
      "[epoch 19][test] Acc@1: 0.258 Acc@10: 0.493 Acc@100: 0.657 AccSum: 1.408\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.247 Acc@10: 0.494 Acc@100: 0.653 AccSum: 1.393\n",
      "[epoch 20][test] Acc@1: 0.260 Acc@10: 0.496 Acc@100: 0.662 AccSum: 1.418\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.248 Acc@10: 0.496 Acc@100: 0.654 AccSum: 1.398\n",
      "[epoch 21][test] Acc@1: 0.261 Acc@10: 0.499 Acc@100: 0.663 AccSum: 1.422\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.253 Acc@10: 0.496 Acc@100: 0.654 AccSum: 1.403\n",
      "[epoch 22][test] Acc@1: 0.263 Acc@10: 0.499 Acc@100: 0.663 AccSum: 1.424\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.252 Acc@10: 0.497 Acc@100: 0.654 AccSum: 1.403\n",
      "[epoch 24][dev ] Acc@1: 0.253 Acc@10: 0.496 Acc@100: 0.654 AccSum: 1.403\n",
      "[epoch 25][dev ] Acc@1: 0.254 Acc@10: 0.498 Acc@100: 0.655 AccSum: 1.407\n",
      "[epoch 25][test] Acc@1: 0.266 Acc@10: 0.499 Acc@100: 0.665 AccSum: 1.431\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.256 Acc@10: 0.499 Acc@100: 0.657 AccSum: 1.413\n",
      "[epoch 26][test] Acc@1: 0.269 Acc@10: 0.501 Acc@100: 0.667 AccSum: 1.437\n",
      "[best epoch: 26]\n",
      "[epoch 27][dev ] Acc@1: 0.259 Acc@10: 0.502 Acc@100: 0.660 AccSum: 1.422\n",
      "[epoch 27][test] Acc@1: 0.270 Acc@10: 0.503 Acc@100: 0.670 AccSum: 1.443\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.263 Acc@10: 0.505 Acc@100: 0.666 AccSum: 1.434\n",
      "[epoch 28][test] Acc@1: 0.272 Acc@10: 0.508 Acc@100: 0.674 AccSum: 1.455\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.263 Acc@10: 0.506 Acc@100: 0.667 AccSum: 1.435\n",
      "[epoch 29][test] Acc@1: 0.271 Acc@10: 0.509 Acc@100: 0.674 AccSum: 1.454\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.261 Acc@10: 0.505 Acc@100: 0.665 AccSum: 1.431\n",
      "[epoch 31][dev ] Acc@1: 0.262 Acc@10: 0.504 Acc@100: 0.665 AccSum: 1.431\n",
      "[epoch 32][dev ] Acc@1: 0.264 Acc@10: 0.506 Acc@100: 0.666 AccSum: 1.436\n",
      "[epoch 32][test] Acc@1: 0.273 Acc@10: 0.508 Acc@100: 0.675 AccSum: 1.456\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.266 Acc@10: 0.507 Acc@100: 0.666 AccSum: 1.439\n",
      "[epoch 33][test] Acc@1: 0.277 Acc@10: 0.508 Acc@100: 0.675 AccSum: 1.460\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.266 Acc@10: 0.507 Acc@100: 0.667 AccSum: 1.440\n",
      "[epoch 34][test] Acc@1: 0.276 Acc@10: 0.510 Acc@100: 0.676 AccSum: 1.462\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.268 Acc@10: 0.510 Acc@100: 0.666 AccSum: 1.443\n",
      "[epoch 35][test] Acc@1: 0.278 Acc@10: 0.512 Acc@100: 0.676 AccSum: 1.466\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.268 Acc@10: 0.512 Acc@100: 0.668 AccSum: 1.448\n",
      "[epoch 36][test] Acc@1: 0.279 Acc@10: 0.515 Acc@100: 0.677 AccSum: 1.471\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.270 Acc@10: 0.512 Acc@100: 0.668 AccSum: 1.450\n",
      "[epoch 37][test] Acc@1: 0.280 Acc@10: 0.515 Acc@100: 0.678 AccSum: 1.474\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.270 Acc@10: 0.511 Acc@100: 0.669 AccSum: 1.449\n",
      "[epoch 39][dev ] Acc@1: 0.272 Acc@10: 0.512 Acc@100: 0.669 AccSum: 1.452\n",
      "[epoch 39][test] Acc@1: 0.283 Acc@10: 0.515 Acc@100: 0.679 AccSum: 1.476\n",
      "[best epoch: 39]\n",
      "[epoch 40][dev ] Acc@1: 0.269 Acc@10: 0.512 Acc@100: 0.670 AccSum: 1.451\n",
      "[epoch 41][dev ] Acc@1: 0.269 Acc@10: 0.512 Acc@100: 0.669 AccSum: 1.450\n",
      "[epoch 42][dev ] Acc@1: 0.272 Acc@10: 0.515 Acc@100: 0.672 AccSum: 1.459\n",
      "[epoch 42][test] Acc@1: 0.282 Acc@10: 0.516 Acc@100: 0.681 AccSum: 1.479\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.273 Acc@10: 0.514 Acc@100: 0.673 AccSum: 1.460\n",
      "[epoch 43][test] Acc@1: 0.281 Acc@10: 0.517 Acc@100: 0.682 AccSum: 1.480\n",
      "[best epoch: 43]\n",
      "[epoch 44][dev ] Acc@1: 0.273 Acc@10: 0.516 Acc@100: 0.672 AccSum: 1.461\n",
      "[epoch 44][test] Acc@1: 0.281 Acc@10: 0.517 Acc@100: 0.681 AccSum: 1.479\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.275 Acc@10: 0.516 Acc@100: 0.672 AccSum: 1.463\n",
      "[epoch 45][test] Acc@1: 0.282 Acc@10: 0.517 Acc@100: 0.682 AccSum: 1.480\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.276 Acc@10: 0.515 Acc@100: 0.673 AccSum: 1.463\n",
      "[epoch 46][test] Acc@1: 0.284 Acc@10: 0.516 Acc@100: 0.682 AccSum: 1.482\n",
      "[best epoch: 46]\n",
      "[epoch 47][dev ] Acc@1: 0.276 Acc@10: 0.515 Acc@100: 0.673 AccSum: 1.464\n",
      "[epoch 47][test] Acc@1: 0.284 Acc@10: 0.517 Acc@100: 0.681 AccSum: 1.483\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.277 Acc@10: 0.515 Acc@100: 0.674 AccSum: 1.467\n",
      "[epoch 48][test] Acc@1: 0.286 Acc@10: 0.518 Acc@100: 0.684 AccSum: 1.488\n",
      "[best epoch: 48]\n",
      "[epoch 49][dev ] Acc@1: 0.277 Acc@10: 0.516 Acc@100: 0.673 AccSum: 1.466\n",
      "[epoch 50][dev ] Acc@1: 0.277 Acc@10: 0.515 Acc@100: 0.674 AccSum: 1.466\n",
      "[epoch 51][dev ] Acc@1: 0.279 Acc@10: 0.517 Acc@100: 0.675 AccSum: 1.470\n",
      "[epoch 51][test] Acc@1: 0.288 Acc@10: 0.520 Acc@100: 0.685 AccSum: 1.493\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.280 Acc@10: 0.518 Acc@100: 0.676 AccSum: 1.474\n",
      "[epoch 52][test] Acc@1: 0.289 Acc@10: 0.522 Acc@100: 0.686 AccSum: 1.496\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.281 Acc@10: 0.518 Acc@100: 0.677 AccSum: 1.476\n",
      "[epoch 53][test] Acc@1: 0.289 Acc@10: 0.522 Acc@100: 0.686 AccSum: 1.497\n",
      "[best epoch: 53]\n",
      "[epoch 54][dev ] Acc@1: 0.280 Acc@10: 0.518 Acc@100: 0.677 AccSum: 1.475\n",
      "[epoch 55][dev ] Acc@1: 0.281 Acc@10: 0.518 Acc@100: 0.680 AccSum: 1.479\n",
      "[epoch 55][test] Acc@1: 0.288 Acc@10: 0.520 Acc@100: 0.688 AccSum: 1.497\n",
      "[best epoch: 55]\n",
      "[epoch 56][dev ] Acc@1: 0.282 Acc@10: 0.517 Acc@100: 0.681 AccSum: 1.481\n",
      "[epoch 56][test] Acc@1: 0.288 Acc@10: 0.520 Acc@100: 0.690 AccSum: 1.498\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.283 Acc@10: 0.518 Acc@100: 0.681 AccSum: 1.483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 57][test] Acc@1: 0.288 Acc@10: 0.520 Acc@100: 0.689 AccSum: 1.498\n",
      "[best epoch: 57]\n",
      "[epoch 58][dev ] Acc@1: 0.284 Acc@10: 0.522 Acc@100: 0.679 AccSum: 1.484\n",
      "[epoch 58][test] Acc@1: 0.291 Acc@10: 0.523 Acc@100: 0.689 AccSum: 1.503\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.284 Acc@10: 0.522 Acc@100: 0.678 AccSum: 1.485\n",
      "[epoch 59][test] Acc@1: 0.290 Acc@10: 0.524 Acc@100: 0.688 AccSum: 1.503\n",
      "[best epoch: 59]\n",
      "[epoch 60][dev ] Acc@1: 0.284 Acc@10: 0.522 Acc@100: 0.679 AccSum: 1.486\n",
      "[epoch 60][test] Acc@1: 0.290 Acc@10: 0.525 Acc@100: 0.689 AccSum: 1.504\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.283 Acc@10: 0.522 Acc@100: 0.679 AccSum: 1.484\n",
      "[epoch 62][dev ] Acc@1: 0.283 Acc@10: 0.522 Acc@100: 0.680 AccSum: 1.485\n",
      "[epoch 63][dev ] Acc@1: 0.284 Acc@10: 0.522 Acc@100: 0.680 AccSum: 1.486\n",
      "[epoch 64][dev ] Acc@1: 0.284 Acc@10: 0.521 Acc@100: 0.682 AccSum: 1.487\n",
      "[epoch 64][test] Acc@1: 0.290 Acc@10: 0.525 Acc@100: 0.691 AccSum: 1.506\n",
      "[best epoch: 64]\n",
      "[epoch 65][dev ] Acc@1: 0.284 Acc@10: 0.523 Acc@100: 0.682 AccSum: 1.488\n",
      "[epoch 65][test] Acc@1: 0.291 Acc@10: 0.526 Acc@100: 0.691 AccSum: 1.508\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.286 Acc@10: 0.525 Acc@100: 0.682 AccSum: 1.493\n",
      "[epoch 66][test] Acc@1: 0.293 Acc@10: 0.527 Acc@100: 0.692 AccSum: 1.512\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.286 Acc@10: 0.525 Acc@100: 0.683 AccSum: 1.494\n",
      "[epoch 67][test] Acc@1: 0.294 Acc@10: 0.528 Acc@100: 0.692 AccSum: 1.514\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.287 Acc@10: 0.524 Acc@100: 0.683 AccSum: 1.494\n",
      "[epoch 68][test] Acc@1: 0.295 Acc@10: 0.528 Acc@100: 0.693 AccSum: 1.515\n",
      "[best epoch: 68]\n",
      "[epoch 69][dev ] Acc@1: 0.287 Acc@10: 0.524 Acc@100: 0.683 AccSum: 1.494\n",
      "[epoch 70][dev ] Acc@1: 0.288 Acc@10: 0.524 Acc@100: 0.683 AccSum: 1.495\n",
      "[epoch 70][test] Acc@1: 0.294 Acc@10: 0.529 Acc@100: 0.692 AccSum: 1.516\n",
      "[best epoch: 70]\n",
      "[epoch 71][dev ] Acc@1: 0.287 Acc@10: 0.524 Acc@100: 0.683 AccSum: 1.494\n",
      "[epoch 72][dev ] Acc@1: 0.288 Acc@10: 0.523 Acc@100: 0.685 AccSum: 1.496\n",
      "[epoch 72][test] Acc@1: 0.294 Acc@10: 0.528 Acc@100: 0.691 AccSum: 1.514\n",
      "[best epoch: 72]\n",
      "[epoch 73][dev ] Acc@1: 0.287 Acc@10: 0.522 Acc@100: 0.685 AccSum: 1.494\n",
      "[epoch 74][dev ] Acc@1: 0.287 Acc@10: 0.522 Acc@100: 0.685 AccSum: 1.494\n",
      "[epoch 75][dev ] Acc@1: 0.288 Acc@10: 0.524 Acc@100: 0.686 AccSum: 1.498\n",
      "[epoch 75][test] Acc@1: 0.295 Acc@10: 0.529 Acc@100: 0.693 AccSum: 1.518\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.288 Acc@10: 0.525 Acc@100: 0.684 AccSum: 1.498\n",
      "[epoch 77][dev ] Acc@1: 0.290 Acc@10: 0.526 Acc@100: 0.684 AccSum: 1.500\n",
      "[epoch 77][test] Acc@1: 0.297 Acc@10: 0.530 Acc@100: 0.694 AccSum: 1.521\n",
      "[best epoch: 77]\n",
      "[epoch 78][dev ] Acc@1: 0.289 Acc@10: 0.527 Acc@100: 0.683 AccSum: 1.499\n",
      "[epoch 79][dev ] Acc@1: 0.289 Acc@10: 0.528 Acc@100: 0.682 AccSum: 1.499\n",
      "[epoch 80][dev ] Acc@1: 0.288 Acc@10: 0.528 Acc@100: 0.684 AccSum: 1.500\n",
      "[epoch 80][test] Acc@1: 0.298 Acc@10: 0.531 Acc@100: 0.694 AccSum: 1.522\n",
      "[best epoch: 80]\n",
      "[epoch 81][dev ] Acc@1: 0.289 Acc@10: 0.528 Acc@100: 0.684 AccSum: 1.501\n",
      "[epoch 81][test] Acc@1: 0.298 Acc@10: 0.530 Acc@100: 0.694 AccSum: 1.522\n",
      "[best epoch: 81]\n",
      "[epoch 82][dev ] Acc@1: 0.289 Acc@10: 0.528 Acc@100: 0.685 AccSum: 1.502\n",
      "[epoch 82][test] Acc@1: 0.299 Acc@10: 0.531 Acc@100: 0.694 AccSum: 1.524\n",
      "[best epoch: 82]\n",
      "[epoch 83][dev ] Acc@1: 0.289 Acc@10: 0.529 Acc@100: 0.686 AccSum: 1.504\n",
      "[epoch 83][test] Acc@1: 0.299 Acc@10: 0.531 Acc@100: 0.694 AccSum: 1.524\n",
      "[best epoch: 83]\n",
      "[epoch 84][dev ] Acc@1: 0.290 Acc@10: 0.528 Acc@100: 0.685 AccSum: 1.504\n",
      "[epoch 85][dev ] Acc@1: 0.291 Acc@10: 0.528 Acc@100: 0.686 AccSum: 1.505\n",
      "[epoch 85][test] Acc@1: 0.301 Acc@10: 0.532 Acc@100: 0.695 AccSum: 1.528\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.293 Acc@10: 0.528 Acc@100: 0.688 AccSum: 1.509\n",
      "[epoch 86][test] Acc@1: 0.302 Acc@10: 0.533 Acc@100: 0.696 AccSum: 1.531\n",
      "[best epoch: 86]\n",
      "[epoch 87][dev ] Acc@1: 0.292 Acc@10: 0.528 Acc@100: 0.690 AccSum: 1.510\n",
      "[epoch 87][test] Acc@1: 0.301 Acc@10: 0.533 Acc@100: 0.698 AccSum: 1.532\n",
      "[best epoch: 87]\n",
      "[epoch 88][dev ] Acc@1: 0.292 Acc@10: 0.528 Acc@100: 0.689 AccSum: 1.509\n",
      "[epoch 89][dev ] Acc@1: 0.292 Acc@10: 0.527 Acc@100: 0.690 AccSum: 1.509\n",
      "[epoch 90][dev ] Acc@1: 0.291 Acc@10: 0.527 Acc@100: 0.690 AccSum: 1.508\n",
      "[epoch 91][dev ] Acc@1: 0.290 Acc@10: 0.528 Acc@100: 0.691 AccSum: 1.509\n",
      "[epoch 92][dev ] Acc@1: 0.288 Acc@10: 0.530 Acc@100: 0.691 AccSum: 1.509\n",
      "[epoch 93][dev ] Acc@1: 0.288 Acc@10: 0.530 Acc@100: 0.693 AccSum: 1.510\n",
      "[epoch 94][dev ] Acc@1: 0.288 Acc@10: 0.531 Acc@100: 0.693 AccSum: 1.512\n",
      "[epoch 94][test] Acc@1: 0.300 Acc@10: 0.534 Acc@100: 0.699 AccSum: 1.533\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.289 Acc@10: 0.530 Acc@100: 0.692 AccSum: 1.512\n",
      "[epoch 96][dev ] Acc@1: 0.290 Acc@10: 0.530 Acc@100: 0.692 AccSum: 1.512\n",
      "[epoch 97][dev ] Acc@1: 0.290 Acc@10: 0.530 Acc@100: 0.692 AccSum: 1.512\n",
      "[epoch 98][dev ] Acc@1: 0.290 Acc@10: 0.530 Acc@100: 0.692 AccSum: 1.512\n",
      "[epoch 99][dev ] Acc@1: 0.291 Acc@10: 0.530 Acc@100: 0.691 AccSum: 1.512\n",
      "[epoch 99][test] Acc@1: 0.301 Acc@10: 0.534 Acc@100: 0.701 AccSum: 1.537\n",
      "[best epoch: 99]\n",
      "[epoch 100][dev ] Acc@1: 0.291 Acc@10: 0.530 Acc@100: 0.692 AccSum: 1.513\n",
      "[epoch 100][test] Acc@1: 0.301 Acc@10: 0.534 Acc@100: 0.702 AccSum: 1.537\n",
      "[best epoch: 100]\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=768, target_size=768).cuda(GPU_INDEX)\n",
    "train_params = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_params, lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True)\n",
    "\n",
    "best_sd = train(model, train_params, optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"bert_static_term_to_surface_state_dict.pkl\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "model = fc_aligner(input_size=768, target_size=768).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd292d5cc0ea48d399b4942e5faf2bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.379\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=128)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128)\n",
    "# print (\"MGRD: %.3f MGRD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contextual_term -> surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mutlilevel attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "# input: contextual_term\n",
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_bert_ts100k_embeddings_all_names_mean_full_last_layer_with_ST.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"chv_term_embeddings_BERTbr_ts100k_multilevel_all.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.000 AccSum: 0.001\n",
      "[epoch 1][dev ] Acc@1: 0.211 Acc@10: 0.463 Acc@100: 0.651 AccSum: 1.325\n",
      "[epoch 1][test] Acc@1: 0.217 Acc@10: 0.467 Acc@100: 0.656 AccSum: 1.340\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.233 Acc@10: 0.487 Acc@100: 0.672 AccSum: 1.392\n",
      "[epoch 2][test] Acc@1: 0.239 Acc@10: 0.489 Acc@100: 0.679 AccSum: 1.407\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.277 Acc@10: 0.527 Acc@100: 0.713 AccSum: 1.517\n",
      "[epoch 3][test] Acc@1: 0.278 Acc@10: 0.534 Acc@100: 0.720 AccSum: 1.531\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.274 Acc@10: 0.527 Acc@100: 0.709 AccSum: 1.511\n",
      "[epoch 5][dev ] Acc@1: 0.297 Acc@10: 0.550 Acc@100: 0.732 AccSum: 1.579\n",
      "[epoch 5][test] Acc@1: 0.295 Acc@10: 0.559 Acc@100: 0.737 AccSum: 1.591\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.286 Acc@10: 0.541 Acc@100: 0.719 AccSum: 1.546\n",
      "[epoch 7][dev ] Acc@1: 0.309 Acc@10: 0.566 Acc@100: 0.744 AccSum: 1.619\n",
      "[epoch 7][test] Acc@1: 0.309 Acc@10: 0.579 Acc@100: 0.749 AccSum: 1.637\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.312 Acc@10: 0.566 Acc@100: 0.746 AccSum: 1.624\n",
      "[epoch 8][test] Acc@1: 0.322 Acc@10: 0.580 Acc@100: 0.747 AccSum: 1.649\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.308 Acc@10: 0.555 Acc@100: 0.737 AccSum: 1.600\n",
      "[epoch 10][dev ] Acc@1: 0.312 Acc@10: 0.566 Acc@100: 0.746 AccSum: 1.624\n",
      "[epoch 10][test] Acc@1: 0.318 Acc@10: 0.580 Acc@100: 0.750 AccSum: 1.648\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.313 Acc@10: 0.576 Acc@100: 0.754 AccSum: 1.643\n",
      "[epoch 11][test] Acc@1: 0.317 Acc@10: 0.584 Acc@100: 0.755 AccSum: 1.656\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.312 Acc@10: 0.573 Acc@100: 0.749 AccSum: 1.634\n",
      "[epoch 13][dev ] Acc@1: 0.320 Acc@10: 0.576 Acc@100: 0.745 AccSum: 1.641\n",
      "[epoch 14][dev ] Acc@1: 0.330 Acc@10: 0.584 Acc@100: 0.756 AccSum: 1.669\n",
      "[epoch 14][test] Acc@1: 0.334 Acc@10: 0.595 Acc@100: 0.761 AccSum: 1.690\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.331 Acc@10: 0.589 Acc@100: 0.762 AccSum: 1.682\n",
      "[epoch 15][test] Acc@1: 0.337 Acc@10: 0.601 Acc@100: 0.768 AccSum: 1.706\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.331 Acc@10: 0.589 Acc@100: 0.758 AccSum: 1.678\n",
      "[epoch 17][dev ] Acc@1: 0.327 Acc@10: 0.589 Acc@100: 0.756 AccSum: 1.672\n",
      "[epoch 18][dev ] Acc@1: 0.328 Acc@10: 0.587 Acc@100: 0.759 AccSum: 1.674\n",
      "[epoch 19][dev ] Acc@1: 0.334 Acc@10: 0.594 Acc@100: 0.763 AccSum: 1.691\n",
      "[epoch 19][test] Acc@1: 0.335 Acc@10: 0.604 Acc@100: 0.769 AccSum: 1.708\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.336 Acc@10: 0.598 Acc@100: 0.764 AccSum: 1.698\n",
      "[epoch 20][test] Acc@1: 0.335 Acc@10: 0.609 Acc@100: 0.770 AccSum: 1.714\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.330 Acc@10: 0.595 Acc@100: 0.763 AccSum: 1.688\n",
      "[epoch 22][dev ] Acc@1: 0.327 Acc@10: 0.591 Acc@100: 0.763 AccSum: 1.682\n",
      "[epoch 23][dev ] Acc@1: 0.332 Acc@10: 0.594 Acc@100: 0.764 AccSum: 1.689\n",
      "[epoch 24][dev ] Acc@1: 0.336 Acc@10: 0.598 Acc@100: 0.769 AccSum: 1.703\n",
      "[epoch 24][test] Acc@1: 0.338 Acc@10: 0.612 Acc@100: 0.774 AccSum: 1.724\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.341 Acc@10: 0.603 Acc@100: 0.771 AccSum: 1.714\n",
      "[epoch 25][test] Acc@1: 0.342 Acc@10: 0.615 Acc@100: 0.777 AccSum: 1.733\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.341 Acc@10: 0.599 Acc@100: 0.769 AccSum: 1.709\n",
      "[epoch 27][dev ] Acc@1: 0.341 Acc@10: 0.596 Acc@100: 0.766 AccSum: 1.703\n",
      "[epoch 28][dev ] Acc@1: 0.336 Acc@10: 0.596 Acc@100: 0.768 AccSum: 1.700\n",
      "[epoch 29][dev ] Acc@1: 0.343 Acc@10: 0.598 Acc@100: 0.767 AccSum: 1.708\n",
      "[epoch 30][dev ] Acc@1: 0.346 Acc@10: 0.600 Acc@100: 0.772 AccSum: 1.718\n",
      "[epoch 30][test] Acc@1: 0.344 Acc@10: 0.619 Acc@100: 0.778 AccSum: 1.742\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.346 Acc@10: 0.604 Acc@100: 0.773 AccSum: 1.722\n",
      "[epoch 31][test] Acc@1: 0.343 Acc@10: 0.617 Acc@100: 0.780 AccSum: 1.740\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.347 Acc@10: 0.605 Acc@100: 0.775 AccSum: 1.727\n",
      "[epoch 32][test] Acc@1: 0.343 Acc@10: 0.619 Acc@100: 0.780 AccSum: 1.742\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.347 Acc@10: 0.602 Acc@100: 0.773 AccSum: 1.722\n",
      "[epoch 34][dev ] Acc@1: 0.350 Acc@10: 0.602 Acc@100: 0.773 AccSum: 1.726\n",
      "[epoch 35][dev ] Acc@1: 0.353 Acc@10: 0.603 Acc@100: 0.775 AccSum: 1.731\n",
      "[epoch 35][test] Acc@1: 0.345 Acc@10: 0.618 Acc@100: 0.777 AccSum: 1.740\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.353 Acc@10: 0.606 Acc@100: 0.776 AccSum: 1.735\n",
      "[epoch 36][test] Acc@1: 0.347 Acc@10: 0.619 Acc@100: 0.778 AccSum: 1.745\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.354 Acc@10: 0.609 Acc@100: 0.778 AccSum: 1.741\n",
      "[epoch 37][test] Acc@1: 0.347 Acc@10: 0.621 Acc@100: 0.782 AccSum: 1.750\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.353 Acc@10: 0.610 Acc@100: 0.779 AccSum: 1.742\n",
      "[epoch 38][test] Acc@1: 0.347 Acc@10: 0.623 Acc@100: 0.784 AccSum: 1.754\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.351 Acc@10: 0.608 Acc@100: 0.778 AccSum: 1.737\n",
      "[epoch 40][dev ] Acc@1: 0.351 Acc@10: 0.606 Acc@100: 0.779 AccSum: 1.737\n",
      "[epoch 41][dev ] Acc@1: 0.354 Acc@10: 0.605 Acc@100: 0.778 AccSum: 1.737\n",
      "[epoch 42][dev ] Acc@1: 0.349 Acc@10: 0.607 Acc@100: 0.780 AccSum: 1.736\n",
      "[epoch 43][dev ] Acc@1: 0.349 Acc@10: 0.607 Acc@100: 0.780 AccSum: 1.736\n",
      "[epoch 44][dev ] Acc@1: 0.349 Acc@10: 0.610 Acc@100: 0.781 AccSum: 1.740\n",
      "[epoch 45][dev ] Acc@1: 0.348 Acc@10: 0.610 Acc@100: 0.782 AccSum: 1.740\n",
      "[epoch 46][dev ] Acc@1: 0.348 Acc@10: 0.610 Acc@100: 0.782 AccSum: 1.741\n",
      "[epoch 47][dev ] Acc@1: 0.348 Acc@10: 0.609 Acc@100: 0.781 AccSum: 1.738\n",
      "[epoch 48][dev ] Acc@1: 0.351 Acc@10: 0.610 Acc@100: 0.782 AccSum: 1.743\n",
      "[epoch 48][test] Acc@1: 0.346 Acc@10: 0.625 Acc@100: 0.787 AccSum: 1.758\n",
      "[best epoch: 48]\n",
      "[epoch 49][dev ] Acc@1: 0.349 Acc@10: 0.610 Acc@100: 0.783 AccSum: 1.742\n",
      "[epoch 50][dev ] Acc@1: 0.352 Acc@10: 0.613 Acc@100: 0.782 AccSum: 1.747\n",
      "[epoch 50][test] Acc@1: 0.350 Acc@10: 0.627 Acc@100: 0.787 AccSum: 1.764\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.353 Acc@10: 0.608 Acc@100: 0.783 AccSum: 1.744\n",
      "[epoch 52][dev ] Acc@1: 0.350 Acc@10: 0.606 Acc@100: 0.782 AccSum: 1.738\n",
      "[epoch 53][dev ] Acc@1: 0.351 Acc@10: 0.605 Acc@100: 0.781 AccSum: 1.737\n",
      "[epoch 54][dev ] Acc@1: 0.352 Acc@10: 0.609 Acc@100: 0.782 AccSum: 1.743\n",
      "[epoch 55][dev ] Acc@1: 0.350 Acc@10: 0.611 Acc@100: 0.782 AccSum: 1.743\n",
      "[epoch 56][dev ] Acc@1: 0.349 Acc@10: 0.613 Acc@100: 0.783 AccSum: 1.745\n",
      "[epoch 57][dev ] Acc@1: 0.352 Acc@10: 0.612 Acc@100: 0.784 AccSum: 1.747\n",
      "[epoch 58][dev ] Acc@1: 0.352 Acc@10: 0.611 Acc@100: 0.785 AccSum: 1.748\n",
      "[epoch 58][test] Acc@1: 0.351 Acc@10: 0.629 Acc@100: 0.786 AccSum: 1.767\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.351 Acc@10: 0.611 Acc@100: 0.785 AccSum: 1.747\n",
      "[epoch 60][dev ] Acc@1: 0.346 Acc@10: 0.613 Acc@100: 0.783 AccSum: 1.741\n",
      "[epoch 61][dev ] Acc@1: 0.349 Acc@10: 0.614 Acc@100: 0.782 AccSum: 1.745\n",
      "[epoch 62][dev ] Acc@1: 0.352 Acc@10: 0.613 Acc@100: 0.783 AccSum: 1.748\n",
      "[epoch 63][dev ] Acc@1: 0.351 Acc@10: 0.612 Acc@100: 0.784 AccSum: 1.746\n",
      "[epoch 64][dev ] Acc@1: 0.353 Acc@10: 0.616 Acc@100: 0.784 AccSum: 1.753\n",
      "[epoch 64][test] Acc@1: 0.349 Acc@10: 0.631 Acc@100: 0.788 AccSum: 1.767\n",
      "[best epoch: 64]\n",
      "[epoch 65][dev ] Acc@1: 0.355 Acc@10: 0.618 Acc@100: 0.783 AccSum: 1.755\n",
      "[epoch 65][test] Acc@1: 0.350 Acc@10: 0.631 Acc@100: 0.787 AccSum: 1.768\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.351 Acc@10: 0.614 Acc@100: 0.783 AccSum: 1.747\n",
      "[epoch 67][dev ] Acc@1: 0.351 Acc@10: 0.614 Acc@100: 0.783 AccSum: 1.747\n",
      "[epoch 68][dev ] Acc@1: 0.353 Acc@10: 0.616 Acc@100: 0.782 AccSum: 1.752\n",
      "[epoch 69][dev ] Acc@1: 0.354 Acc@10: 0.616 Acc@100: 0.785 AccSum: 1.755\n",
      "[epoch 70][dev ] Acc@1: 0.352 Acc@10: 0.617 Acc@100: 0.787 AccSum: 1.756\n",
      "[epoch 70][test] Acc@1: 0.349 Acc@10: 0.632 Acc@100: 0.788 AccSum: 1.769\n",
      "[best epoch: 70]\n",
      "[epoch 71][dev ] Acc@1: 0.354 Acc@10: 0.614 Acc@100: 0.785 AccSum: 1.753\n",
      "[epoch 72][dev ] Acc@1: 0.354 Acc@10: 0.615 Acc@100: 0.783 AccSum: 1.752\n",
      "[epoch 73][dev ] Acc@1: 0.356 Acc@10: 0.614 Acc@100: 0.785 AccSum: 1.755\n",
      "[epoch 74][dev ] Acc@1: 0.353 Acc@10: 0.615 Acc@100: 0.785 AccSum: 1.753\n",
      "[epoch 75][dev ] Acc@1: 0.354 Acc@10: 0.614 Acc@100: 0.786 AccSum: 1.754\n",
      "[epoch 76][dev ] Acc@1: 0.355 Acc@10: 0.618 Acc@100: 0.785 AccSum: 1.757\n",
      "[epoch 76][test] Acc@1: 0.350 Acc@10: 0.633 Acc@100: 0.789 AccSum: 1.772\n",
      "[best epoch: 76]\n",
      "[epoch 77][dev ] Acc@1: 0.356 Acc@10: 0.618 Acc@100: 0.785 AccSum: 1.760\n",
      "[epoch 77][test] Acc@1: 0.353 Acc@10: 0.633 Acc@100: 0.790 AccSum: 1.776\n",
      "[best epoch: 77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 78][dev ] Acc@1: 0.356 Acc@10: 0.618 Acc@100: 0.788 AccSum: 1.762\n",
      "[epoch 78][test] Acc@1: 0.354 Acc@10: 0.634 Acc@100: 0.792 AccSum: 1.780\n",
      "[best epoch: 78]\n",
      "[epoch 79][dev ] Acc@1: 0.357 Acc@10: 0.619 Acc@100: 0.787 AccSum: 1.763\n",
      "[epoch 79][test] Acc@1: 0.355 Acc@10: 0.635 Acc@100: 0.792 AccSum: 1.782\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.357 Acc@10: 0.621 Acc@100: 0.786 AccSum: 1.764\n",
      "[epoch 80][test] Acc@1: 0.352 Acc@10: 0.636 Acc@100: 0.792 AccSum: 1.779\n",
      "[best epoch: 80]\n",
      "[epoch 81][dev ] Acc@1: 0.356 Acc@10: 0.619 Acc@100: 0.785 AccSum: 1.760\n",
      "[epoch 82][dev ] Acc@1: 0.353 Acc@10: 0.618 Acc@100: 0.785 AccSum: 1.756\n",
      "[epoch 83][dev ] Acc@1: 0.354 Acc@10: 0.616 Acc@100: 0.784 AccSum: 1.755\n",
      "[epoch 84][dev ] Acc@1: 0.356 Acc@10: 0.615 Acc@100: 0.785 AccSum: 1.756\n",
      "[epoch 85][dev ] Acc@1: 0.356 Acc@10: 0.615 Acc@100: 0.784 AccSum: 1.755\n",
      "[epoch 86][dev ] Acc@1: 0.356 Acc@10: 0.616 Acc@100: 0.784 AccSum: 1.756\n",
      "[epoch 87][dev ] Acc@1: 0.356 Acc@10: 0.617 Acc@100: 0.784 AccSum: 1.757\n",
      "[epoch 88][dev ] Acc@1: 0.356 Acc@10: 0.617 Acc@100: 0.783 AccSum: 1.756\n",
      "[epoch 89][dev ] Acc@1: 0.356 Acc@10: 0.616 Acc@100: 0.784 AccSum: 1.757\n",
      "[epoch 90][dev ] Acc@1: 0.353 Acc@10: 0.617 Acc@100: 0.785 AccSum: 1.755\n",
      "[epoch 91][dev ] Acc@1: 0.356 Acc@10: 0.619 Acc@100: 0.785 AccSum: 1.759\n",
      "[epoch 92][dev ] Acc@1: 0.358 Acc@10: 0.618 Acc@100: 0.786 AccSum: 1.763\n",
      "[epoch 93][dev ] Acc@1: 0.359 Acc@10: 0.620 Acc@100: 0.786 AccSum: 1.765\n",
      "[epoch 93][test] Acc@1: 0.355 Acc@10: 0.638 Acc@100: 0.793 AccSum: 1.786\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.359 Acc@10: 0.620 Acc@100: 0.785 AccSum: 1.764\n",
      "[epoch 95][dev ] Acc@1: 0.360 Acc@10: 0.620 Acc@100: 0.785 AccSum: 1.765\n",
      "[epoch 96][dev ] Acc@1: 0.358 Acc@10: 0.620 Acc@100: 0.787 AccSum: 1.765\n",
      "[epoch 97][dev ] Acc@1: 0.356 Acc@10: 0.619 Acc@100: 0.787 AccSum: 1.762\n",
      "[epoch 98][dev ] Acc@1: 0.357 Acc@10: 0.618 Acc@100: 0.788 AccSum: 1.762\n",
      "[epoch 99][dev ] Acc@1: 0.356 Acc@10: 0.620 Acc@100: 0.789 AccSum: 1.765\n",
      "[epoch 100][dev ] Acc@1: 0.357 Acc@10: 0.621 Acc@100: 0.788 AccSum: 1.767\n",
      "[epoch 100][test] Acc@1: 0.357 Acc@10: 0.642 Acc@100: 0.794 AccSum: 1.793\n",
      "[best epoch: 100]\n"
     ]
    }
   ],
   "source": [
    "model = multilevel_attention(input_size=768, target_size=768, lin=True).cuda(GPU_INDEX)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multilevel_attention(\n",
       "  (self_attn): SelfAttention()\n",
       "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"bert_context_term_to_surface_attn_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = multilevel_attention(input_size=768, target_size=768, lin=True).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4328fec14f40ff947fad35df25a069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.455\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=128, \\\n",
    "              dumb=True, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, \\\n",
    "#             GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGD: %.3f MGD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear + relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "# input: contextual_term\n",
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_bert_ts100k_embeddings_all_names_mean_full_new.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"chv_term_embeddings_BERTbr_ts100k.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.001 AccSum: 0.001\n",
      "[epoch 1][dev ] Acc@1: 0.123 Acc@10: 0.356 Acc@100: 0.578 AccSum: 1.057\n",
      "[epoch 1][test] Acc@1: 0.133 Acc@10: 0.343 Acc@100: 0.575 AccSum: 1.051\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.189 Acc@10: 0.421 Acc@100: 0.640 AccSum: 1.249\n",
      "[epoch 2][test] Acc@1: 0.182 Acc@10: 0.420 Acc@100: 0.637 AccSum: 1.240\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.181 Acc@10: 0.426 Acc@100: 0.631 AccSum: 1.239\n",
      "[epoch 4][dev ] Acc@1: 0.203 Acc@10: 0.453 Acc@100: 0.649 AccSum: 1.305\n",
      "[epoch 4][test] Acc@1: 0.202 Acc@10: 0.458 Acc@100: 0.657 AccSum: 1.317\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.204 Acc@10: 0.453 Acc@100: 0.652 AccSum: 1.309\n",
      "[epoch 5][test] Acc@1: 0.210 Acc@10: 0.460 Acc@100: 0.657 AccSum: 1.328\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.221 Acc@10: 0.479 Acc@100: 0.668 AccSum: 1.368\n",
      "[epoch 6][test] Acc@1: 0.225 Acc@10: 0.478 Acc@100: 0.675 AccSum: 1.378\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.229 Acc@10: 0.479 Acc@100: 0.669 AccSum: 1.377\n",
      "[epoch 7][test] Acc@1: 0.227 Acc@10: 0.481 Acc@100: 0.677 AccSum: 1.385\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.230 Acc@10: 0.489 Acc@100: 0.675 AccSum: 1.394\n",
      "[epoch 8][test] Acc@1: 0.237 Acc@10: 0.486 Acc@100: 0.684 AccSum: 1.407\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.235 Acc@10: 0.490 Acc@100: 0.683 AccSum: 1.408\n",
      "[epoch 9][test] Acc@1: 0.238 Acc@10: 0.490 Acc@100: 0.686 AccSum: 1.414\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.234 Acc@10: 0.495 Acc@100: 0.681 AccSum: 1.410\n",
      "[epoch 10][test] Acc@1: 0.237 Acc@10: 0.492 Acc@100: 0.686 AccSum: 1.415\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.239 Acc@10: 0.498 Acc@100: 0.685 AccSum: 1.422\n",
      "[epoch 11][test] Acc@1: 0.240 Acc@10: 0.494 Acc@100: 0.688 AccSum: 1.422\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.242 Acc@10: 0.502 Acc@100: 0.688 AccSum: 1.432\n",
      "[epoch 12][test] Acc@1: 0.247 Acc@10: 0.501 Acc@100: 0.693 AccSum: 1.442\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.249 Acc@10: 0.506 Acc@100: 0.690 AccSum: 1.446\n",
      "[epoch 13][test] Acc@1: 0.252 Acc@10: 0.507 Acc@100: 0.697 AccSum: 1.456\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.250 Acc@10: 0.509 Acc@100: 0.693 AccSum: 1.452\n",
      "[epoch 14][test] Acc@1: 0.253 Acc@10: 0.507 Acc@100: 0.700 AccSum: 1.461\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.247 Acc@10: 0.507 Acc@100: 0.691 AccSum: 1.445\n",
      "[epoch 16][dev ] Acc@1: 0.250 Acc@10: 0.507 Acc@100: 0.690 AccSum: 1.448\n",
      "[epoch 17][dev ] Acc@1: 0.253 Acc@10: 0.511 Acc@100: 0.693 AccSum: 1.456\n",
      "[epoch 17][test] Acc@1: 0.252 Acc@10: 0.511 Acc@100: 0.703 AccSum: 1.467\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.250 Acc@10: 0.513 Acc@100: 0.697 AccSum: 1.460\n",
      "[epoch 18][test] Acc@1: 0.255 Acc@10: 0.515 Acc@100: 0.705 AccSum: 1.474\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.252 Acc@10: 0.515 Acc@100: 0.697 AccSum: 1.464\n",
      "[epoch 19][test] Acc@1: 0.258 Acc@10: 0.517 Acc@100: 0.706 AccSum: 1.480\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.254 Acc@10: 0.517 Acc@100: 0.701 AccSum: 1.473\n",
      "[epoch 20][test] Acc@1: 0.262 Acc@10: 0.518 Acc@100: 0.708 AccSum: 1.488\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.259 Acc@10: 0.520 Acc@100: 0.699 AccSum: 1.479\n",
      "[epoch 21][test] Acc@1: 0.265 Acc@10: 0.519 Acc@100: 0.709 AccSum: 1.493\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.259 Acc@10: 0.521 Acc@100: 0.700 AccSum: 1.481\n",
      "[epoch 22][test] Acc@1: 0.262 Acc@10: 0.518 Acc@100: 0.709 AccSum: 1.490\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.262 Acc@10: 0.522 Acc@100: 0.704 AccSum: 1.489\n",
      "[epoch 23][test] Acc@1: 0.264 Acc@10: 0.520 Acc@100: 0.710 AccSum: 1.494\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.260 Acc@10: 0.522 Acc@100: 0.707 AccSum: 1.490\n",
      "[epoch 24][test] Acc@1: 0.265 Acc@10: 0.521 Acc@100: 0.710 AccSum: 1.496\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.261 Acc@10: 0.521 Acc@100: 0.708 AccSum: 1.490\n",
      "[epoch 25][test] Acc@1: 0.266 Acc@10: 0.522 Acc@100: 0.711 AccSum: 1.499\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.261 Acc@10: 0.522 Acc@100: 0.707 AccSum: 1.489\n",
      "[epoch 27][dev ] Acc@1: 0.264 Acc@10: 0.522 Acc@100: 0.709 AccSum: 1.495\n",
      "[epoch 27][test] Acc@1: 0.269 Acc@10: 0.524 Acc@100: 0.714 AccSum: 1.507\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.266 Acc@10: 0.521 Acc@100: 0.709 AccSum: 1.496\n",
      "[epoch 28][test] Acc@1: 0.268 Acc@10: 0.526 Acc@100: 0.714 AccSum: 1.509\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.268 Acc@10: 0.526 Acc@100: 0.710 AccSum: 1.504\n",
      "[epoch 29][test] Acc@1: 0.269 Acc@10: 0.525 Acc@100: 0.716 AccSum: 1.511\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.267 Acc@10: 0.526 Acc@100: 0.709 AccSum: 1.502\n",
      "[epoch 31][dev ] Acc@1: 0.267 Acc@10: 0.526 Acc@100: 0.710 AccSum: 1.502\n",
      "[epoch 32][dev ] Acc@1: 0.265 Acc@10: 0.527 Acc@100: 0.710 AccSum: 1.502\n",
      "[epoch 33][dev ] Acc@1: 0.264 Acc@10: 0.528 Acc@100: 0.711 AccSum: 1.503\n",
      "[epoch 34][dev ] Acc@1: 0.264 Acc@10: 0.531 Acc@100: 0.712 AccSum: 1.507\n",
      "[epoch 34][test] Acc@1: 0.276 Acc@10: 0.527 Acc@100: 0.719 AccSum: 1.523\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.265 Acc@10: 0.530 Acc@100: 0.714 AccSum: 1.509\n",
      "[epoch 35][test] Acc@1: 0.276 Acc@10: 0.528 Acc@100: 0.720 AccSum: 1.525\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.268 Acc@10: 0.531 Acc@100: 0.714 AccSum: 1.513\n",
      "[epoch 36][test] Acc@1: 0.277 Acc@10: 0.529 Acc@100: 0.721 AccSum: 1.527\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.268 Acc@10: 0.531 Acc@100: 0.714 AccSum: 1.513\n",
      "[epoch 38][dev ] Acc@1: 0.272 Acc@10: 0.530 Acc@100: 0.713 AccSum: 1.515\n",
      "[epoch 38][test] Acc@1: 0.275 Acc@10: 0.529 Acc@100: 0.720 AccSum: 1.524\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.270 Acc@10: 0.529 Acc@100: 0.713 AccSum: 1.512\n",
      "[epoch 40][dev ] Acc@1: 0.268 Acc@10: 0.531 Acc@100: 0.717 AccSum: 1.516\n",
      "[epoch 40][test] Acc@1: 0.275 Acc@10: 0.530 Acc@100: 0.722 AccSum: 1.528\n",
      "[best epoch: 40]\n",
      "[epoch 41][dev ] Acc@1: 0.270 Acc@10: 0.532 Acc@100: 0.719 AccSum: 1.520\n",
      "[epoch 41][test] Acc@1: 0.277 Acc@10: 0.532 Acc@100: 0.724 AccSum: 1.533\n",
      "[best epoch: 41]\n",
      "[epoch 42][dev ] Acc@1: 0.268 Acc@10: 0.533 Acc@100: 0.719 AccSum: 1.520\n",
      "[epoch 42][test] Acc@1: 0.276 Acc@10: 0.534 Acc@100: 0.725 AccSum: 1.536\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.268 Acc@10: 0.533 Acc@100: 0.719 AccSum: 1.521\n",
      "[epoch 43][test] Acc@1: 0.277 Acc@10: 0.534 Acc@100: 0.725 AccSum: 1.537\n",
      "[best epoch: 43]\n",
      "[epoch 44][dev ] Acc@1: 0.269 Acc@10: 0.534 Acc@100: 0.717 AccSum: 1.520\n",
      "[epoch 45][dev ] Acc@1: 0.268 Acc@10: 0.535 Acc@100: 0.716 AccSum: 1.519\n",
      "[epoch 46][dev ] Acc@1: 0.269 Acc@10: 0.532 Acc@100: 0.717 AccSum: 1.518\n",
      "[epoch 47][dev ] Acc@1: 0.270 Acc@10: 0.533 Acc@100: 0.719 AccSum: 1.522\n",
      "[epoch 47][test] Acc@1: 0.279 Acc@10: 0.535 Acc@100: 0.724 AccSum: 1.538\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.271 Acc@10: 0.534 Acc@100: 0.719 AccSum: 1.524\n",
      "[epoch 48][test] Acc@1: 0.279 Acc@10: 0.538 Acc@100: 0.725 AccSum: 1.543\n",
      "[best epoch: 48]\n",
      "[epoch 49][dev ] Acc@1: 0.272 Acc@10: 0.534 Acc@100: 0.721 AccSum: 1.527\n",
      "[epoch 49][test] Acc@1: 0.280 Acc@10: 0.540 Acc@100: 0.727 AccSum: 1.548\n",
      "[best epoch: 49]\n",
      "[epoch 50][dev ] Acc@1: 0.273 Acc@10: 0.535 Acc@100: 0.722 AccSum: 1.529\n",
      "[epoch 50][test] Acc@1: 0.280 Acc@10: 0.539 Acc@100: 0.727 AccSum: 1.546\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.272 Acc@10: 0.536 Acc@100: 0.722 AccSum: 1.529\n",
      "[epoch 52][dev ] Acc@1: 0.273 Acc@10: 0.536 Acc@100: 0.720 AccSum: 1.528\n",
      "[epoch 53][dev ] Acc@1: 0.272 Acc@10: 0.533 Acc@100: 0.719 AccSum: 1.524\n",
      "[epoch 54][dev ] Acc@1: 0.271 Acc@10: 0.535 Acc@100: 0.718 AccSum: 1.524\n",
      "[epoch 55][dev ] Acc@1: 0.273 Acc@10: 0.535 Acc@100: 0.720 AccSum: 1.528\n",
      "[epoch 56][dev ] Acc@1: 0.273 Acc@10: 0.536 Acc@100: 0.721 AccSum: 1.530\n",
      "[epoch 56][test] Acc@1: 0.282 Acc@10: 0.539 Acc@100: 0.729 AccSum: 1.549\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.273 Acc@10: 0.538 Acc@100: 0.722 AccSum: 1.533\n",
      "[epoch 57][test] Acc@1: 0.282 Acc@10: 0.539 Acc@100: 0.730 AccSum: 1.551\n",
      "[best epoch: 57]\n",
      "[epoch 58][dev ] Acc@1: 0.273 Acc@10: 0.539 Acc@100: 0.723 AccSum: 1.536\n",
      "[epoch 58][test] Acc@1: 0.282 Acc@10: 0.539 Acc@100: 0.730 AccSum: 1.551\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.273 Acc@10: 0.538 Acc@100: 0.722 AccSum: 1.534\n",
      "[epoch 60][dev ] Acc@1: 0.274 Acc@10: 0.539 Acc@100: 0.722 AccSum: 1.536\n",
      "[epoch 60][test] Acc@1: 0.282 Acc@10: 0.539 Acc@100: 0.729 AccSum: 1.550\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.273 Acc@10: 0.538 Acc@100: 0.722 AccSum: 1.533\n",
      "[epoch 62][dev ] Acc@1: 0.272 Acc@10: 0.538 Acc@100: 0.721 AccSum: 1.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 63][dev ] Acc@1: 0.273 Acc@10: 0.539 Acc@100: 0.721 AccSum: 1.533\n",
      "[epoch 64][dev ] Acc@1: 0.274 Acc@10: 0.538 Acc@100: 0.720 AccSum: 1.532\n",
      "[epoch 65][dev ] Acc@1: 0.276 Acc@10: 0.539 Acc@100: 0.721 AccSum: 1.536\n",
      "[epoch 66][dev ] Acc@1: 0.276 Acc@10: 0.540 Acc@100: 0.722 AccSum: 1.537\n",
      "[epoch 66][test] Acc@1: 0.282 Acc@10: 0.539 Acc@100: 0.731 AccSum: 1.552\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.276 Acc@10: 0.540 Acc@100: 0.724 AccSum: 1.540\n",
      "[epoch 67][test] Acc@1: 0.284 Acc@10: 0.539 Acc@100: 0.731 AccSum: 1.554\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.277 Acc@10: 0.540 Acc@100: 0.725 AccSum: 1.542\n",
      "[epoch 68][test] Acc@1: 0.283 Acc@10: 0.541 Acc@100: 0.732 AccSum: 1.555\n",
      "[best epoch: 68]\n",
      "[epoch 69][dev ] Acc@1: 0.275 Acc@10: 0.541 Acc@100: 0.724 AccSum: 1.541\n",
      "[epoch 70][dev ] Acc@1: 0.275 Acc@10: 0.541 Acc@100: 0.723 AccSum: 1.540\n",
      "[epoch 71][dev ] Acc@1: 0.276 Acc@10: 0.541 Acc@100: 0.723 AccSum: 1.540\n",
      "[epoch 72][dev ] Acc@1: 0.277 Acc@10: 0.541 Acc@100: 0.723 AccSum: 1.540\n",
      "[epoch 73][dev ] Acc@1: 0.277 Acc@10: 0.542 Acc@100: 0.722 AccSum: 1.541\n",
      "[epoch 74][dev ] Acc@1: 0.277 Acc@10: 0.544 Acc@100: 0.724 AccSum: 1.545\n",
      "[epoch 74][test] Acc@1: 0.285 Acc@10: 0.544 Acc@100: 0.734 AccSum: 1.563\n",
      "[best epoch: 74]\n",
      "[epoch 75][dev ] Acc@1: 0.277 Acc@10: 0.543 Acc@100: 0.725 AccSum: 1.545\n",
      "[epoch 75][test] Acc@1: 0.286 Acc@10: 0.543 Acc@100: 0.735 AccSum: 1.564\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.278 Acc@10: 0.544 Acc@100: 0.726 AccSum: 1.548\n",
      "[epoch 76][test] Acc@1: 0.286 Acc@10: 0.544 Acc@100: 0.734 AccSum: 1.564\n",
      "[best epoch: 76]\n",
      "[epoch 77][dev ] Acc@1: 0.279 Acc@10: 0.545 Acc@100: 0.726 AccSum: 1.549\n",
      "[epoch 77][test] Acc@1: 0.285 Acc@10: 0.542 Acc@100: 0.734 AccSum: 1.560\n",
      "[best epoch: 77]\n",
      "[epoch 78][dev ] Acc@1: 0.279 Acc@10: 0.545 Acc@100: 0.726 AccSum: 1.550\n",
      "[epoch 78][test] Acc@1: 0.285 Acc@10: 0.541 Acc@100: 0.733 AccSum: 1.559\n",
      "[best epoch: 78]\n",
      "[epoch 79][dev ] Acc@1: 0.279 Acc@10: 0.545 Acc@100: 0.727 AccSum: 1.550\n",
      "[epoch 79][test] Acc@1: 0.285 Acc@10: 0.542 Acc@100: 0.733 AccSum: 1.560\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.278 Acc@10: 0.544 Acc@100: 0.725 AccSum: 1.547\n",
      "[epoch 81][dev ] Acc@1: 0.279 Acc@10: 0.545 Acc@100: 0.725 AccSum: 1.549\n",
      "[epoch 82][dev ] Acc@1: 0.277 Acc@10: 0.544 Acc@100: 0.725 AccSum: 1.546\n",
      "[epoch 83][dev ] Acc@1: 0.278 Acc@10: 0.543 Acc@100: 0.726 AccSum: 1.546\n",
      "[epoch 84][dev ] Acc@1: 0.277 Acc@10: 0.542 Acc@100: 0.726 AccSum: 1.545\n",
      "[epoch 85][dev ] Acc@1: 0.276 Acc@10: 0.542 Acc@100: 0.726 AccSum: 1.544\n",
      "[epoch 86][dev ] Acc@1: 0.278 Acc@10: 0.543 Acc@100: 0.726 AccSum: 1.546\n",
      "[epoch 87][dev ] Acc@1: 0.278 Acc@10: 0.544 Acc@100: 0.726 AccSum: 1.548\n",
      "[epoch 88][dev ] Acc@1: 0.279 Acc@10: 0.545 Acc@100: 0.727 AccSum: 1.551\n",
      "[epoch 88][test] Acc@1: 0.285 Acc@10: 0.546 Acc@100: 0.737 AccSum: 1.568\n",
      "[best epoch: 88]\n",
      "[epoch 89][dev ] Acc@1: 0.278 Acc@10: 0.546 Acc@100: 0.726 AccSum: 1.550\n",
      "[epoch 90][dev ] Acc@1: 0.278 Acc@10: 0.546 Acc@100: 0.727 AccSum: 1.552\n",
      "[epoch 90][test] Acc@1: 0.285 Acc@10: 0.548 Acc@100: 0.736 AccSum: 1.570\n",
      "[best epoch: 90]\n",
      "[epoch 91][dev ] Acc@1: 0.278 Acc@10: 0.546 Acc@100: 0.727 AccSum: 1.551\n",
      "[epoch 92][dev ] Acc@1: 0.278 Acc@10: 0.546 Acc@100: 0.727 AccSum: 1.551\n",
      "[epoch 93][dev ] Acc@1: 0.278 Acc@10: 0.546 Acc@100: 0.728 AccSum: 1.553\n",
      "[epoch 93][test] Acc@1: 0.287 Acc@10: 0.548 Acc@100: 0.737 AccSum: 1.572\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.279 Acc@10: 0.547 Acc@100: 0.727 AccSum: 1.553\n",
      "[epoch 94][test] Acc@1: 0.287 Acc@10: 0.548 Acc@100: 0.738 AccSum: 1.572\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.279 Acc@10: 0.548 Acc@100: 0.727 AccSum: 1.554\n",
      "[epoch 95][test] Acc@1: 0.287 Acc@10: 0.548 Acc@100: 0.738 AccSum: 1.573\n",
      "[best epoch: 95]\n",
      "[epoch 96][dev ] Acc@1: 0.280 Acc@10: 0.548 Acc@100: 0.727 AccSum: 1.555\n",
      "[epoch 96][test] Acc@1: 0.287 Acc@10: 0.548 Acc@100: 0.738 AccSum: 1.574\n",
      "[best epoch: 96]\n",
      "[epoch 97][dev ] Acc@1: 0.281 Acc@10: 0.546 Acc@100: 0.726 AccSum: 1.554\n",
      "[epoch 98][dev ] Acc@1: 0.281 Acc@10: 0.546 Acc@100: 0.727 AccSum: 1.554\n",
      "[epoch 99][dev ] Acc@1: 0.281 Acc@10: 0.546 Acc@100: 0.728 AccSum: 1.555\n",
      "[epoch 100][dev ] Acc@1: 0.280 Acc@10: 0.548 Acc@100: 0.728 AccSum: 1.556\n",
      "[epoch 100][test] Acc@1: 0.286 Acc@10: 0.550 Acc@100: 0.738 AccSum: 1.574\n",
      "[best epoch: 100]\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=768, target_size=768).cuda(GPU_INDEX)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][test] Acc@1: 0.286 Acc@10: 0.550 Acc@100: 0.738 AccSum: 1.574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.285648889906157, 0.550240329594873, 0.737926298924239]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"bert_context_term_to_surface_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=768, target_size=768).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "\n",
    "val_or_test(model, test_loader, testset.search_space_embeddings, \\\n",
    "                epoch=-1, typ=\"test\", bsz=64, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e4f47f20ba484495e45cdf5f05a40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.376\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=64, dumb=True, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, \\\n",
    "#             GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGD: %.3f MGD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fasttext align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### term -> surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_fasttext_embeddings_full.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.003 AccSum: 0.003\n",
      "[epoch 1][dev ] Acc@1: 0.045 Acc@10: 0.189 Acc@100: 0.443 AccSum: 0.677\n",
      "[epoch 1][test] Acc@1: 0.043 Acc@10: 0.191 Acc@100: 0.452 AccSum: 0.685\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.145 Acc@10: 0.382 Acc@100: 0.668 AccSum: 1.195\n",
      "[epoch 2][test] Acc@1: 0.147 Acc@10: 0.399 Acc@100: 0.673 AccSum: 1.219\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.160 Acc@10: 0.450 Acc@100: 0.721 AccSum: 1.332\n",
      "[epoch 3][test] Acc@1: 0.169 Acc@10: 0.459 Acc@100: 0.730 AccSum: 1.358\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.200 Acc@10: 0.519 Acc@100: 0.765 AccSum: 1.485\n",
      "[epoch 4][test] Acc@1: 0.214 Acc@10: 0.522 Acc@100: 0.768 AccSum: 1.505\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.222 Acc@10: 0.536 Acc@100: 0.787 AccSum: 1.546\n",
      "[epoch 5][test] Acc@1: 0.231 Acc@10: 0.547 Acc@100: 0.786 AccSum: 1.564\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.240 Acc@10: 0.557 Acc@100: 0.798 AccSum: 1.595\n",
      "[epoch 6][test] Acc@1: 0.251 Acc@10: 0.564 Acc@100: 0.798 AccSum: 1.613\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.267 Acc@10: 0.586 Acc@100: 0.824 AccSum: 1.677\n",
      "[epoch 7][test] Acc@1: 0.270 Acc@10: 0.593 Acc@100: 0.821 AccSum: 1.683\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.273 Acc@10: 0.592 Acc@100: 0.820 AccSum: 1.686\n",
      "[epoch 8][test] Acc@1: 0.278 Acc@10: 0.595 Acc@100: 0.822 AccSum: 1.694\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.271 Acc@10: 0.590 Acc@100: 0.820 AccSum: 1.682\n",
      "[epoch 10][dev ] Acc@1: 0.281 Acc@10: 0.606 Acc@100: 0.831 AccSum: 1.718\n",
      "[epoch 10][test] Acc@1: 0.287 Acc@10: 0.609 Acc@100: 0.831 AccSum: 1.726\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.291 Acc@10: 0.615 Acc@100: 0.840 AccSum: 1.747\n",
      "[epoch 11][test] Acc@1: 0.295 Acc@10: 0.616 Acc@100: 0.840 AccSum: 1.751\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.291 Acc@10: 0.617 Acc@100: 0.842 AccSum: 1.751\n",
      "[epoch 12][test] Acc@1: 0.295 Acc@10: 0.618 Acc@100: 0.842 AccSum: 1.754\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.296 Acc@10: 0.622 Acc@100: 0.841 AccSum: 1.760\n",
      "[epoch 13][test] Acc@1: 0.297 Acc@10: 0.628 Acc@100: 0.841 AccSum: 1.766\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.303 Acc@10: 0.630 Acc@100: 0.847 AccSum: 1.780\n",
      "[epoch 14][test] Acc@1: 0.306 Acc@10: 0.636 Acc@100: 0.848 AccSum: 1.790\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.303 Acc@10: 0.641 Acc@100: 0.852 AccSum: 1.796\n",
      "[epoch 15][test] Acc@1: 0.305 Acc@10: 0.645 Acc@100: 0.852 AccSum: 1.802\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.307 Acc@10: 0.647 Acc@100: 0.854 AccSum: 1.808\n",
      "[epoch 16][test] Acc@1: 0.310 Acc@10: 0.650 Acc@100: 0.854 AccSum: 1.814\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.310 Acc@10: 0.647 Acc@100: 0.857 AccSum: 1.814\n",
      "[epoch 17][test] Acc@1: 0.314 Acc@10: 0.650 Acc@100: 0.857 AccSum: 1.821\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.315 Acc@10: 0.652 Acc@100: 0.856 AccSum: 1.823\n",
      "[epoch 18][test] Acc@1: 0.320 Acc@10: 0.655 Acc@100: 0.857 AccSum: 1.832\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.319 Acc@10: 0.648 Acc@100: 0.857 AccSum: 1.824\n",
      "[epoch 19][test] Acc@1: 0.320 Acc@10: 0.653 Acc@100: 0.859 AccSum: 1.833\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.320 Acc@10: 0.655 Acc@100: 0.856 AccSum: 1.832\n",
      "[epoch 20][test] Acc@1: 0.322 Acc@10: 0.659 Acc@100: 0.859 AccSum: 1.840\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.324 Acc@10: 0.662 Acc@100: 0.857 AccSum: 1.843\n",
      "[epoch 21][test] Acc@1: 0.325 Acc@10: 0.662 Acc@100: 0.861 AccSum: 1.848\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.325 Acc@10: 0.665 Acc@100: 0.860 AccSum: 1.849\n",
      "[epoch 22][test] Acc@1: 0.325 Acc@10: 0.663 Acc@100: 0.864 AccSum: 1.853\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.329 Acc@10: 0.665 Acc@100: 0.863 AccSum: 1.857\n",
      "[epoch 23][test] Acc@1: 0.329 Acc@10: 0.666 Acc@100: 0.867 AccSum: 1.861\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.331 Acc@10: 0.662 Acc@100: 0.863 AccSum: 1.856\n",
      "[epoch 25][dev ] Acc@1: 0.331 Acc@10: 0.665 Acc@100: 0.862 AccSum: 1.858\n",
      "[epoch 25][test] Acc@1: 0.333 Acc@10: 0.666 Acc@100: 0.867 AccSum: 1.866\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.334 Acc@10: 0.669 Acc@100: 0.863 AccSum: 1.866\n",
      "[epoch 26][test] Acc@1: 0.334 Acc@10: 0.669 Acc@100: 0.868 AccSum: 1.872\n",
      "[best epoch: 26]\n",
      "[epoch 27][dev ] Acc@1: 0.332 Acc@10: 0.670 Acc@100: 0.863 AccSum: 1.865\n",
      "[epoch 28][dev ] Acc@1: 0.335 Acc@10: 0.670 Acc@100: 0.863 AccSum: 1.868\n",
      "[epoch 28][test] Acc@1: 0.340 Acc@10: 0.671 Acc@100: 0.869 AccSum: 1.880\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.337 Acc@10: 0.670 Acc@100: 0.863 AccSum: 1.870\n",
      "[epoch 29][test] Acc@1: 0.342 Acc@10: 0.672 Acc@100: 0.869 AccSum: 1.883\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.341 Acc@10: 0.673 Acc@100: 0.865 AccSum: 1.878\n",
      "[epoch 30][test] Acc@1: 0.344 Acc@10: 0.675 Acc@100: 0.870 AccSum: 1.889\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.344 Acc@10: 0.674 Acc@100: 0.866 AccSum: 1.884\n",
      "[epoch 31][test] Acc@1: 0.345 Acc@10: 0.677 Acc@100: 0.873 AccSum: 1.895\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.351 Acc@10: 0.675 Acc@100: 0.866 AccSum: 1.892\n",
      "[epoch 32][test] Acc@1: 0.350 Acc@10: 0.678 Acc@100: 0.873 AccSum: 1.902\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.352 Acc@10: 0.676 Acc@100: 0.865 AccSum: 1.893\n",
      "[epoch 33][test] Acc@1: 0.351 Acc@10: 0.679 Acc@100: 0.873 AccSum: 1.903\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.351 Acc@10: 0.674 Acc@100: 0.866 AccSum: 1.891\n",
      "[epoch 35][dev ] Acc@1: 0.352 Acc@10: 0.675 Acc@100: 0.867 AccSum: 1.893\n",
      "[epoch 35][test] Acc@1: 0.350 Acc@10: 0.677 Acc@100: 0.875 AccSum: 1.903\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.351 Acc@10: 0.676 Acc@100: 0.866 AccSum: 1.893\n",
      "[epoch 37][dev ] Acc@1: 0.351 Acc@10: 0.678 Acc@100: 0.867 AccSum: 1.896\n",
      "[epoch 37][test] Acc@1: 0.352 Acc@10: 0.680 Acc@100: 0.875 AccSum: 1.907\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.348 Acc@10: 0.676 Acc@100: 0.866 AccSum: 1.891\n",
      "[epoch 39][dev ] Acc@1: 0.351 Acc@10: 0.677 Acc@100: 0.866 AccSum: 1.894\n",
      "[epoch 40][dev ] Acc@1: 0.352 Acc@10: 0.678 Acc@100: 0.865 AccSum: 1.896\n",
      "[epoch 40][test] Acc@1: 0.358 Acc@10: 0.686 Acc@100: 0.875 AccSum: 1.919\n",
      "[best epoch: 40]\n",
      "[epoch 41][dev ] Acc@1: 0.352 Acc@10: 0.678 Acc@100: 0.865 AccSum: 1.896\n",
      "[epoch 42][dev ] Acc@1: 0.355 Acc@10: 0.676 Acc@100: 0.866 AccSum: 1.897\n",
      "[epoch 42][test] Acc@1: 0.358 Acc@10: 0.683 Acc@100: 0.876 AccSum: 1.918\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.357 Acc@10: 0.678 Acc@100: 0.867 AccSum: 1.902\n",
      "[epoch 43][test] Acc@1: 0.360 Acc@10: 0.685 Acc@100: 0.877 AccSum: 1.922\n",
      "[best epoch: 43]\n",
      "[epoch 44][dev ] Acc@1: 0.358 Acc@10: 0.679 Acc@100: 0.868 AccSum: 1.904\n",
      "[epoch 44][test] Acc@1: 0.360 Acc@10: 0.686 Acc@100: 0.878 AccSum: 1.923\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.361 Acc@10: 0.680 Acc@100: 0.867 AccSum: 1.908\n",
      "[epoch 45][test] Acc@1: 0.363 Acc@10: 0.687 Acc@100: 0.877 AccSum: 1.927\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.362 Acc@10: 0.679 Acc@100: 0.867 AccSum: 1.908\n",
      "[epoch 47][dev ] Acc@1: 0.360 Acc@10: 0.678 Acc@100: 0.867 AccSum: 1.905\n",
      "[epoch 48][dev ] Acc@1: 0.363 Acc@10: 0.678 Acc@100: 0.867 AccSum: 1.908\n",
      "[epoch 49][dev ] Acc@1: 0.362 Acc@10: 0.679 Acc@100: 0.868 AccSum: 1.910\n",
      "[epoch 49][test] Acc@1: 0.365 Acc@10: 0.690 Acc@100: 0.877 AccSum: 1.932\n",
      "[best epoch: 49]\n",
      "[epoch 50][dev ] Acc@1: 0.362 Acc@10: 0.682 Acc@100: 0.870 AccSum: 1.915\n",
      "[epoch 50][test] Acc@1: 0.364 Acc@10: 0.691 Acc@100: 0.877 AccSum: 1.932\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.363 Acc@10: 0.681 Acc@100: 0.871 AccSum: 1.915\n",
      "[epoch 51][test] Acc@1: 0.366 Acc@10: 0.689 Acc@100: 0.878 AccSum: 1.934\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.367 Acc@10: 0.682 Acc@100: 0.871 AccSum: 1.920\n",
      "[epoch 52][test] Acc@1: 0.368 Acc@10: 0.690 Acc@100: 0.878 AccSum: 1.935\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.367 Acc@10: 0.683 Acc@100: 0.870 AccSum: 1.920\n",
      "[epoch 53][test] Acc@1: 0.368 Acc@10: 0.690 Acc@100: 0.878 AccSum: 1.935\n",
      "[best epoch: 53]\n",
      "[epoch 54][dev ] Acc@1: 0.367 Acc@10: 0.683 Acc@100: 0.870 AccSum: 1.920\n",
      "[epoch 54][test] Acc@1: 0.368 Acc@10: 0.690 Acc@100: 0.877 AccSum: 1.935\n",
      "[best epoch: 54]\n",
      "[epoch 55][dev ] Acc@1: 0.371 Acc@10: 0.684 Acc@100: 0.870 AccSum: 1.925\n",
      "[epoch 55][test] Acc@1: 0.369 Acc@10: 0.689 Acc@100: 0.878 AccSum: 1.936\n",
      "[best epoch: 55]\n",
      "[epoch 56][dev ] Acc@1: 0.371 Acc@10: 0.684 Acc@100: 0.870 AccSum: 1.925\n",
      "[epoch 57][dev ] Acc@1: 0.372 Acc@10: 0.685 Acc@100: 0.871 AccSum: 1.928\n",
      "[epoch 57][test] Acc@1: 0.371 Acc@10: 0.690 Acc@100: 0.878 AccSum: 1.939\n",
      "[best epoch: 57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 58][dev ] Acc@1: 0.373 Acc@10: 0.684 Acc@100: 0.871 AccSum: 1.927\n",
      "[epoch 59][dev ] Acc@1: 0.373 Acc@10: 0.686 Acc@100: 0.869 AccSum: 1.928\n",
      "[epoch 60][dev ] Acc@1: 0.375 Acc@10: 0.686 Acc@100: 0.869 AccSum: 1.930\n",
      "[epoch 60][test] Acc@1: 0.375 Acc@10: 0.691 Acc@100: 0.877 AccSum: 1.942\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.374 Acc@10: 0.686 Acc@100: 0.870 AccSum: 1.930\n",
      "[epoch 61][test] Acc@1: 0.377 Acc@10: 0.691 Acc@100: 0.877 AccSum: 1.946\n",
      "[best epoch: 61]\n",
      "[epoch 62][dev ] Acc@1: 0.375 Acc@10: 0.688 Acc@100: 0.870 AccSum: 1.933\n",
      "[epoch 62][test] Acc@1: 0.378 Acc@10: 0.693 Acc@100: 0.877 AccSum: 1.948\n",
      "[best epoch: 62]\n",
      "[epoch 63][dev ] Acc@1: 0.374 Acc@10: 0.687 Acc@100: 0.870 AccSum: 1.931\n",
      "[epoch 64][dev ] Acc@1: 0.376 Acc@10: 0.687 Acc@100: 0.870 AccSum: 1.933\n",
      "[epoch 65][dev ] Acc@1: 0.376 Acc@10: 0.688 Acc@100: 0.870 AccSum: 1.934\n",
      "[epoch 65][test] Acc@1: 0.378 Acc@10: 0.691 Acc@100: 0.876 AccSum: 1.945\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.376 Acc@10: 0.689 Acc@100: 0.871 AccSum: 1.937\n",
      "[epoch 66][test] Acc@1: 0.378 Acc@10: 0.692 Acc@100: 0.877 AccSum: 1.948\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.376 Acc@10: 0.688 Acc@100: 0.871 AccSum: 1.935\n",
      "[epoch 68][dev ] Acc@1: 0.375 Acc@10: 0.687 Acc@100: 0.869 AccSum: 1.932\n",
      "[epoch 69][dev ] Acc@1: 0.375 Acc@10: 0.687 Acc@100: 0.871 AccSum: 1.932\n",
      "[epoch 70][dev ] Acc@1: 0.376 Acc@10: 0.687 Acc@100: 0.870 AccSum: 1.933\n",
      "[epoch 71][dev ] Acc@1: 0.377 Acc@10: 0.686 Acc@100: 0.872 AccSum: 1.934\n",
      "[epoch 72][dev ] Acc@1: 0.374 Acc@10: 0.683 Acc@100: 0.871 AccSum: 1.928\n",
      "[epoch 73][dev ] Acc@1: 0.376 Acc@10: 0.684 Acc@100: 0.871 AccSum: 1.931\n",
      "[epoch 74][dev ] Acc@1: 0.379 Acc@10: 0.686 Acc@100: 0.873 AccSum: 1.937\n",
      "[epoch 74][test] Acc@1: 0.380 Acc@10: 0.692 Acc@100: 0.879 AccSum: 1.951\n",
      "[best epoch: 74]\n",
      "[epoch 75][dev ] Acc@1: 0.378 Acc@10: 0.689 Acc@100: 0.873 AccSum: 1.940\n",
      "[epoch 75][test] Acc@1: 0.378 Acc@10: 0.696 Acc@100: 0.880 AccSum: 1.954\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.377 Acc@10: 0.688 Acc@100: 0.873 AccSum: 1.938\n",
      "[epoch 77][dev ] Acc@1: 0.378 Acc@10: 0.688 Acc@100: 0.874 AccSum: 1.940\n",
      "[epoch 78][dev ] Acc@1: 0.376 Acc@10: 0.689 Acc@100: 0.873 AccSum: 1.939\n",
      "[epoch 79][dev ] Acc@1: 0.377 Acc@10: 0.690 Acc@100: 0.873 AccSum: 1.940\n",
      "[epoch 80][dev ] Acc@1: 0.380 Acc@10: 0.689 Acc@100: 0.873 AccSum: 1.942\n",
      "[epoch 80][test] Acc@1: 0.381 Acc@10: 0.696 Acc@100: 0.881 AccSum: 1.957\n",
      "[best epoch: 80]\n",
      "[epoch 81][dev ] Acc@1: 0.378 Acc@10: 0.690 Acc@100: 0.873 AccSum: 1.941\n",
      "[epoch 82][dev ] Acc@1: 0.378 Acc@10: 0.692 Acc@100: 0.873 AccSum: 1.942\n",
      "[epoch 82][test] Acc@1: 0.380 Acc@10: 0.698 Acc@100: 0.881 AccSum: 1.959\n",
      "[best epoch: 82]\n",
      "[epoch 83][dev ] Acc@1: 0.376 Acc@10: 0.693 Acc@100: 0.872 AccSum: 1.941\n",
      "[epoch 84][dev ] Acc@1: 0.380 Acc@10: 0.692 Acc@100: 0.872 AccSum: 1.943\n",
      "[epoch 84][test] Acc@1: 0.381 Acc@10: 0.698 Acc@100: 0.881 AccSum: 1.960\n",
      "[best epoch: 84]\n",
      "[epoch 85][dev ] Acc@1: 0.381 Acc@10: 0.691 Acc@100: 0.873 AccSum: 1.945\n",
      "[epoch 85][test] Acc@1: 0.382 Acc@10: 0.698 Acc@100: 0.882 AccSum: 1.962\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.378 Acc@10: 0.689 Acc@100: 0.874 AccSum: 1.941\n",
      "[epoch 87][dev ] Acc@1: 0.380 Acc@10: 0.689 Acc@100: 0.874 AccSum: 1.944\n",
      "[epoch 88][dev ] Acc@1: 0.381 Acc@10: 0.689 Acc@100: 0.875 AccSum: 1.945\n",
      "[epoch 89][dev ] Acc@1: 0.379 Acc@10: 0.691 Acc@100: 0.874 AccSum: 1.943\n",
      "[epoch 90][dev ] Acc@1: 0.377 Acc@10: 0.691 Acc@100: 0.873 AccSum: 1.941\n",
      "[epoch 91][dev ] Acc@1: 0.379 Acc@10: 0.691 Acc@100: 0.873 AccSum: 1.944\n",
      "[epoch 92][dev ] Acc@1: 0.380 Acc@10: 0.691 Acc@100: 0.873 AccSum: 1.944\n",
      "[epoch 93][dev ] Acc@1: 0.380 Acc@10: 0.690 Acc@100: 0.873 AccSum: 1.943\n",
      "[epoch 94][dev ] Acc@1: 0.381 Acc@10: 0.691 Acc@100: 0.873 AccSum: 1.945\n",
      "[epoch 95][dev ] Acc@1: 0.380 Acc@10: 0.692 Acc@100: 0.873 AccSum: 1.946\n",
      "[epoch 95][test] Acc@1: 0.384 Acc@10: 0.701 Acc@100: 0.882 AccSum: 1.967\n",
      "[best epoch: 95]\n",
      "[epoch 96][dev ] Acc@1: 0.380 Acc@10: 0.693 Acc@100: 0.873 AccSum: 1.946\n",
      "[epoch 96][test] Acc@1: 0.384 Acc@10: 0.703 Acc@100: 0.881 AccSum: 1.968\n",
      "[best epoch: 96]\n",
      "[epoch 97][dev ] Acc@1: 0.379 Acc@10: 0.693 Acc@100: 0.874 AccSum: 1.946\n",
      "[epoch 98][dev ] Acc@1: 0.378 Acc@10: 0.692 Acc@100: 0.873 AccSum: 1.943\n",
      "[epoch 99][dev ] Acc@1: 0.378 Acc@10: 0.692 Acc@100: 0.872 AccSum: 1.941\n",
      "[epoch 100][dev ] Acc@1: 0.378 Acc@10: 0.694 Acc@100: 0.872 AccSum: 1.944\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=300, target_size=300).cuda(GPU_INDEX)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2,max_violation=True,device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"ft_term_to_surface_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=300, target_size=300).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109fb20c02024d379fdb038b5c5785fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.495\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=128, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGRD: %.3f MGRD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### term -> graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_node2vec_300d_20wl_embeddings.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.001 AccSum: 0.001\n",
      "[epoch 1][dev ] Acc@1: 0.007 Acc@10: 0.031 Acc@100: 0.124 AccSum: 0.162\n",
      "[epoch 1][test] Acc@1: 0.008 Acc@10: 0.033 Acc@100: 0.125 AccSum: 0.165\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.016 Acc@10: 0.071 Acc@100: 0.205 AccSum: 0.292\n",
      "[epoch 2][test] Acc@1: 0.017 Acc@10: 0.069 Acc@100: 0.208 AccSum: 0.295\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.026 Acc@10: 0.088 Acc@100: 0.236 AccSum: 0.350\n",
      "[epoch 3][test] Acc@1: 0.025 Acc@10: 0.089 Acc@100: 0.244 AccSum: 0.358\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.028 Acc@10: 0.100 Acc@100: 0.284 AccSum: 0.412\n",
      "[epoch 4][test] Acc@1: 0.030 Acc@10: 0.104 Acc@100: 0.286 AccSum: 0.420\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.037 Acc@10: 0.109 Acc@100: 0.298 AccSum: 0.444\n",
      "[epoch 5][test] Acc@1: 0.038 Acc@10: 0.119 Acc@100: 0.297 AccSum: 0.454\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.038 Acc@10: 0.124 Acc@100: 0.323 AccSum: 0.486\n",
      "[epoch 6][test] Acc@1: 0.039 Acc@10: 0.132 Acc@100: 0.325 AccSum: 0.496\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.040 Acc@10: 0.131 Acc@100: 0.333 AccSum: 0.504\n",
      "[epoch 7][test] Acc@1: 0.041 Acc@10: 0.136 Acc@100: 0.336 AccSum: 0.512\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.044 Acc@10: 0.146 Acc@100: 0.352 AccSum: 0.542\n",
      "[epoch 8][test] Acc@1: 0.046 Acc@10: 0.155 Acc@100: 0.354 AccSum: 0.554\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.050 Acc@10: 0.161 Acc@100: 0.377 AccSum: 0.589\n",
      "[epoch 9][test] Acc@1: 0.052 Acc@10: 0.166 Acc@100: 0.380 AccSum: 0.598\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.053 Acc@10: 0.166 Acc@100: 0.380 AccSum: 0.598\n",
      "[epoch 10][test] Acc@1: 0.056 Acc@10: 0.171 Acc@100: 0.383 AccSum: 0.609\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.055 Acc@10: 0.170 Acc@100: 0.391 AccSum: 0.616\n",
      "[epoch 11][test] Acc@1: 0.057 Acc@10: 0.176 Acc@100: 0.389 AccSum: 0.621\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.062 Acc@10: 0.189 Acc@100: 0.410 AccSum: 0.660\n",
      "[epoch 12][test] Acc@1: 0.059 Acc@10: 0.191 Acc@100: 0.406 AccSum: 0.656\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.067 Acc@10: 0.198 Acc@100: 0.426 AccSum: 0.691\n",
      "[epoch 13][test] Acc@1: 0.063 Acc@10: 0.202 Acc@100: 0.424 AccSum: 0.689\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.073 Acc@10: 0.200 Acc@100: 0.433 AccSum: 0.705\n",
      "[epoch 14][test] Acc@1: 0.070 Acc@10: 0.202 Acc@100: 0.432 AccSum: 0.705\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.068 Acc@10: 0.197 Acc@100: 0.435 AccSum: 0.701\n",
      "[epoch 16][dev ] Acc@1: 0.074 Acc@10: 0.201 Acc@100: 0.440 AccSum: 0.716\n",
      "[epoch 16][test] Acc@1: 0.070 Acc@10: 0.207 Acc@100: 0.434 AccSum: 0.711\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.075 Acc@10: 0.211 Acc@100: 0.453 AccSum: 0.739\n",
      "[epoch 17][test] Acc@1: 0.073 Acc@10: 0.218 Acc@100: 0.442 AccSum: 0.732\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.076 Acc@10: 0.222 Acc@100: 0.459 AccSum: 0.757\n",
      "[epoch 18][test] Acc@1: 0.074 Acc@10: 0.229 Acc@100: 0.450 AccSum: 0.753\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.078 Acc@10: 0.229 Acc@100: 0.460 AccSum: 0.767\n",
      "[epoch 19][test] Acc@1: 0.076 Acc@10: 0.231 Acc@100: 0.453 AccSum: 0.760\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.081 Acc@10: 0.231 Acc@100: 0.467 AccSum: 0.779\n",
      "[epoch 20][test] Acc@1: 0.081 Acc@10: 0.233 Acc@100: 0.460 AccSum: 0.774\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.085 Acc@10: 0.234 Acc@100: 0.471 AccSum: 0.790\n",
      "[epoch 21][test] Acc@1: 0.084 Acc@10: 0.237 Acc@100: 0.465 AccSum: 0.787\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.087 Acc@10: 0.235 Acc@100: 0.473 AccSum: 0.795\n",
      "[epoch 22][test] Acc@1: 0.085 Acc@10: 0.240 Acc@100: 0.466 AccSum: 0.792\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.088 Acc@10: 0.240 Acc@100: 0.479 AccSum: 0.807\n",
      "[epoch 23][test] Acc@1: 0.086 Acc@10: 0.245 Acc@100: 0.470 AccSum: 0.801\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.088 Acc@10: 0.242 Acc@100: 0.480 AccSum: 0.811\n",
      "[epoch 24][test] Acc@1: 0.086 Acc@10: 0.247 Acc@100: 0.473 AccSum: 0.805\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.092 Acc@10: 0.249 Acc@100: 0.484 AccSum: 0.824\n",
      "[epoch 25][test] Acc@1: 0.090 Acc@10: 0.251 Acc@100: 0.476 AccSum: 0.818\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.096 Acc@10: 0.251 Acc@100: 0.495 AccSum: 0.842\n",
      "[epoch 26][test] Acc@1: 0.096 Acc@10: 0.252 Acc@100: 0.485 AccSum: 0.832\n",
      "[best epoch: 26]\n",
      "[epoch 27][dev ] Acc@1: 0.096 Acc@10: 0.254 Acc@100: 0.500 AccSum: 0.850\n",
      "[epoch 27][test] Acc@1: 0.096 Acc@10: 0.257 Acc@100: 0.490 AccSum: 0.843\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.096 Acc@10: 0.254 Acc@100: 0.504 AccSum: 0.853\n",
      "[epoch 28][test] Acc@1: 0.096 Acc@10: 0.259 Acc@100: 0.491 AccSum: 0.847\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.098 Acc@10: 0.255 Acc@100: 0.503 AccSum: 0.857\n",
      "[epoch 29][test] Acc@1: 0.095 Acc@10: 0.258 Acc@100: 0.491 AccSum: 0.843\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.099 Acc@10: 0.258 Acc@100: 0.502 AccSum: 0.859\n",
      "[epoch 30][test] Acc@1: 0.096 Acc@10: 0.260 Acc@100: 0.491 AccSum: 0.847\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.103 Acc@10: 0.261 Acc@100: 0.504 AccSum: 0.868\n",
      "[epoch 31][test] Acc@1: 0.100 Acc@10: 0.261 Acc@100: 0.494 AccSum: 0.855\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.105 Acc@10: 0.261 Acc@100: 0.508 AccSum: 0.874\n",
      "[epoch 32][test] Acc@1: 0.102 Acc@10: 0.264 Acc@100: 0.501 AccSum: 0.867\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.106 Acc@10: 0.264 Acc@100: 0.511 AccSum: 0.881\n",
      "[epoch 33][test] Acc@1: 0.105 Acc@10: 0.268 Acc@100: 0.506 AccSum: 0.879\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.106 Acc@10: 0.267 Acc@100: 0.511 AccSum: 0.884\n",
      "[epoch 34][test] Acc@1: 0.106 Acc@10: 0.271 Acc@100: 0.506 AccSum: 0.883\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.104 Acc@10: 0.269 Acc@100: 0.512 AccSum: 0.885\n",
      "[epoch 35][test] Acc@1: 0.105 Acc@10: 0.273 Acc@100: 0.507 AccSum: 0.886\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.106 Acc@10: 0.271 Acc@100: 0.514 AccSum: 0.891\n",
      "[epoch 36][test] Acc@1: 0.105 Acc@10: 0.276 Acc@100: 0.509 AccSum: 0.891\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.110 Acc@10: 0.272 Acc@100: 0.518 AccSum: 0.900\n",
      "[epoch 37][test] Acc@1: 0.109 Acc@10: 0.277 Acc@100: 0.514 AccSum: 0.900\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.112 Acc@10: 0.273 Acc@100: 0.519 AccSum: 0.904\n",
      "[epoch 38][test] Acc@1: 0.111 Acc@10: 0.279 Acc@100: 0.514 AccSum: 0.905\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.112 Acc@10: 0.276 Acc@100: 0.525 AccSum: 0.913\n",
      "[epoch 39][test] Acc@1: 0.111 Acc@10: 0.282 Acc@100: 0.520 AccSum: 0.913\n",
      "[best epoch: 39]\n",
      "[epoch 40][dev ] Acc@1: 0.110 Acc@10: 0.275 Acc@100: 0.524 AccSum: 0.909\n",
      "[epoch 41][dev ] Acc@1: 0.112 Acc@10: 0.275 Acc@100: 0.528 AccSum: 0.914\n",
      "[epoch 41][test] Acc@1: 0.112 Acc@10: 0.283 Acc@100: 0.523 AccSum: 0.918\n",
      "[best epoch: 41]\n",
      "[epoch 42][dev ] Acc@1: 0.113 Acc@10: 0.275 Acc@100: 0.527 AccSum: 0.915\n",
      "[epoch 42][test] Acc@1: 0.113 Acc@10: 0.284 Acc@100: 0.524 AccSum: 0.921\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.116 Acc@10: 0.279 Acc@100: 0.530 AccSum: 0.925\n",
      "[epoch 43][test] Acc@1: 0.117 Acc@10: 0.287 Acc@100: 0.528 AccSum: 0.932\n",
      "[best epoch: 43]\n",
      "[epoch 44][dev ] Acc@1: 0.115 Acc@10: 0.279 Acc@100: 0.532 AccSum: 0.926\n",
      "[epoch 44][test] Acc@1: 0.115 Acc@10: 0.287 Acc@100: 0.529 AccSum: 0.931\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.115 Acc@10: 0.281 Acc@100: 0.535 AccSum: 0.931\n",
      "[epoch 45][test] Acc@1: 0.116 Acc@10: 0.290 Acc@100: 0.531 AccSum: 0.937\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.115 Acc@10: 0.284 Acc@100: 0.536 AccSum: 0.935\n",
      "[epoch 46][test] Acc@1: 0.117 Acc@10: 0.292 Acc@100: 0.532 AccSum: 0.940\n",
      "[best epoch: 46]\n",
      "[epoch 47][dev ] Acc@1: 0.116 Acc@10: 0.285 Acc@100: 0.537 AccSum: 0.937\n",
      "[epoch 47][test] Acc@1: 0.117 Acc@10: 0.292 Acc@100: 0.532 AccSum: 0.941\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.113 Acc@10: 0.285 Acc@100: 0.535 AccSum: 0.933\n",
      "[epoch 49][dev ] Acc@1: 0.114 Acc@10: 0.285 Acc@100: 0.537 AccSum: 0.936\n",
      "[epoch 50][dev ] Acc@1: 0.116 Acc@10: 0.289 Acc@100: 0.540 AccSum: 0.946\n",
      "[epoch 50][test] Acc@1: 0.117 Acc@10: 0.298 Acc@100: 0.536 AccSum: 0.952\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.117 Acc@10: 0.290 Acc@100: 0.541 AccSum: 0.948\n",
      "[epoch 51][test] Acc@1: 0.119 Acc@10: 0.297 Acc@100: 0.538 AccSum: 0.954\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.117 Acc@10: 0.291 Acc@100: 0.543 AccSum: 0.951\n",
      "[epoch 52][test] Acc@1: 0.118 Acc@10: 0.300 Acc@100: 0.539 AccSum: 0.958\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.116 Acc@10: 0.292 Acc@100: 0.546 AccSum: 0.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 53][test] Acc@1: 0.117 Acc@10: 0.301 Acc@100: 0.542 AccSum: 0.960\n",
      "[best epoch: 53]\n",
      "[epoch 54][dev ] Acc@1: 0.117 Acc@10: 0.290 Acc@100: 0.545 AccSum: 0.951\n",
      "[epoch 55][dev ] Acc@1: 0.117 Acc@10: 0.292 Acc@100: 0.545 AccSum: 0.954\n",
      "[epoch 56][dev ] Acc@1: 0.117 Acc@10: 0.292 Acc@100: 0.546 AccSum: 0.956\n",
      "[epoch 56][test] Acc@1: 0.117 Acc@10: 0.303 Acc@100: 0.543 AccSum: 0.963\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.119 Acc@10: 0.293 Acc@100: 0.548 AccSum: 0.960\n",
      "[epoch 57][test] Acc@1: 0.118 Acc@10: 0.302 Acc@100: 0.545 AccSum: 0.965\n",
      "[best epoch: 57]\n",
      "[epoch 58][dev ] Acc@1: 0.122 Acc@10: 0.295 Acc@100: 0.547 AccSum: 0.965\n",
      "[epoch 58][test] Acc@1: 0.119 Acc@10: 0.304 Acc@100: 0.546 AccSum: 0.969\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.126 Acc@10: 0.296 Acc@100: 0.547 AccSum: 0.969\n",
      "[epoch 59][test] Acc@1: 0.121 Acc@10: 0.305 Acc@100: 0.547 AccSum: 0.973\n",
      "[best epoch: 59]\n",
      "[epoch 60][dev ] Acc@1: 0.124 Acc@10: 0.298 Acc@100: 0.549 AccSum: 0.971\n",
      "[epoch 60][test] Acc@1: 0.120 Acc@10: 0.306 Acc@100: 0.548 AccSum: 0.975\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.124 Acc@10: 0.298 Acc@100: 0.550 AccSum: 0.972\n",
      "[epoch 61][test] Acc@1: 0.121 Acc@10: 0.306 Acc@100: 0.549 AccSum: 0.976\n",
      "[best epoch: 61]\n",
      "[epoch 62][dev ] Acc@1: 0.125 Acc@10: 0.304 Acc@100: 0.551 AccSum: 0.980\n",
      "[epoch 62][test] Acc@1: 0.124 Acc@10: 0.310 Acc@100: 0.550 AccSum: 0.984\n",
      "[best epoch: 62]\n",
      "[epoch 63][dev ] Acc@1: 0.124 Acc@10: 0.304 Acc@100: 0.555 AccSum: 0.983\n",
      "[epoch 63][test] Acc@1: 0.124 Acc@10: 0.311 Acc@100: 0.554 AccSum: 0.989\n",
      "[best epoch: 63]\n",
      "[epoch 64][dev ] Acc@1: 0.126 Acc@10: 0.303 Acc@100: 0.552 AccSum: 0.981\n",
      "[epoch 65][dev ] Acc@1: 0.127 Acc@10: 0.302 Acc@100: 0.551 AccSum: 0.980\n",
      "[epoch 66][dev ] Acc@1: 0.128 Acc@10: 0.301 Acc@100: 0.553 AccSum: 0.982\n",
      "[epoch 67][dev ] Acc@1: 0.127 Acc@10: 0.301 Acc@100: 0.553 AccSum: 0.982\n",
      "[epoch 68][dev ] Acc@1: 0.129 Acc@10: 0.299 Acc@100: 0.555 AccSum: 0.982\n",
      "[epoch 69][dev ] Acc@1: 0.130 Acc@10: 0.301 Acc@100: 0.556 AccSum: 0.988\n",
      "[epoch 69][test] Acc@1: 0.128 Acc@10: 0.308 Acc@100: 0.556 AccSum: 0.992\n",
      "[best epoch: 69]\n",
      "[epoch 70][dev ] Acc@1: 0.128 Acc@10: 0.304 Acc@100: 0.556 AccSum: 0.988\n",
      "[epoch 70][test] Acc@1: 0.127 Acc@10: 0.310 Acc@100: 0.557 AccSum: 0.993\n",
      "[best epoch: 70]\n",
      "[epoch 71][dev ] Acc@1: 0.131 Acc@10: 0.306 Acc@100: 0.557 AccSum: 0.995\n",
      "[epoch 71][test] Acc@1: 0.128 Acc@10: 0.311 Acc@100: 0.558 AccSum: 0.997\n",
      "[best epoch: 71]\n",
      "[epoch 72][dev ] Acc@1: 0.130 Acc@10: 0.312 Acc@100: 0.558 AccSum: 1.000\n",
      "[epoch 72][test] Acc@1: 0.127 Acc@10: 0.316 Acc@100: 0.560 AccSum: 1.003\n",
      "[best epoch: 72]\n",
      "[epoch 73][dev ] Acc@1: 0.129 Acc@10: 0.312 Acc@100: 0.560 AccSum: 1.001\n",
      "[epoch 73][test] Acc@1: 0.126 Acc@10: 0.316 Acc@100: 0.561 AccSum: 1.003\n",
      "[best epoch: 73]\n",
      "[epoch 74][dev ] Acc@1: 0.129 Acc@10: 0.309 Acc@100: 0.560 AccSum: 0.999\n",
      "[epoch 75][dev ] Acc@1: 0.131 Acc@10: 0.309 Acc@100: 0.563 AccSum: 1.003\n",
      "[epoch 75][test] Acc@1: 0.128 Acc@10: 0.316 Acc@100: 0.560 AccSum: 1.003\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.132 Acc@10: 0.311 Acc@100: 0.563 AccSum: 1.006\n",
      "[epoch 76][test] Acc@1: 0.129 Acc@10: 0.316 Acc@100: 0.560 AccSum: 1.005\n",
      "[best epoch: 76]\n",
      "[epoch 77][dev ] Acc@1: 0.132 Acc@10: 0.312 Acc@100: 0.563 AccSum: 1.007\n",
      "[epoch 77][test] Acc@1: 0.130 Acc@10: 0.317 Acc@100: 0.561 AccSum: 1.008\n",
      "[best epoch: 77]\n",
      "[epoch 78][dev ] Acc@1: 0.132 Acc@10: 0.312 Acc@100: 0.565 AccSum: 1.009\n",
      "[epoch 78][test] Acc@1: 0.130 Acc@10: 0.319 Acc@100: 0.563 AccSum: 1.012\n",
      "[best epoch: 78]\n",
      "[epoch 79][dev ] Acc@1: 0.132 Acc@10: 0.312 Acc@100: 0.564 AccSum: 1.008\n",
      "[epoch 80][dev ] Acc@1: 0.131 Acc@10: 0.312 Acc@100: 0.563 AccSum: 1.005\n",
      "[epoch 81][dev ] Acc@1: 0.131 Acc@10: 0.311 Acc@100: 0.564 AccSum: 1.006\n",
      "[epoch 82][dev ] Acc@1: 0.131 Acc@10: 0.311 Acc@100: 0.565 AccSum: 1.006\n",
      "[epoch 83][dev ] Acc@1: 0.132 Acc@10: 0.314 Acc@100: 0.566 AccSum: 1.013\n",
      "[epoch 83][test] Acc@1: 0.127 Acc@10: 0.319 Acc@100: 0.567 AccSum: 1.013\n",
      "[best epoch: 83]\n",
      "[epoch 84][dev ] Acc@1: 0.134 Acc@10: 0.316 Acc@100: 0.568 AccSum: 1.018\n",
      "[epoch 84][test] Acc@1: 0.129 Acc@10: 0.320 Acc@100: 0.568 AccSum: 1.017\n",
      "[best epoch: 84]\n",
      "[epoch 85][dev ] Acc@1: 0.136 Acc@10: 0.317 Acc@100: 0.567 AccSum: 1.020\n",
      "[epoch 85][test] Acc@1: 0.131 Acc@10: 0.322 Acc@100: 0.569 AccSum: 1.021\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.136 Acc@10: 0.317 Acc@100: 0.567 AccSum: 1.020\n",
      "[epoch 87][dev ] Acc@1: 0.137 Acc@10: 0.319 Acc@100: 0.569 AccSum: 1.025\n",
      "[epoch 87][test] Acc@1: 0.132 Acc@10: 0.323 Acc@100: 0.569 AccSum: 1.024\n",
      "[best epoch: 87]\n",
      "[epoch 88][dev ] Acc@1: 0.139 Acc@10: 0.319 Acc@100: 0.570 AccSum: 1.028\n",
      "[epoch 88][test] Acc@1: 0.133 Acc@10: 0.324 Acc@100: 0.569 AccSum: 1.026\n",
      "[best epoch: 88]\n",
      "[epoch 89][dev ] Acc@1: 0.138 Acc@10: 0.320 Acc@100: 0.570 AccSum: 1.028\n",
      "[epoch 90][dev ] Acc@1: 0.138 Acc@10: 0.320 Acc@100: 0.570 AccSum: 1.028\n",
      "[epoch 90][test] Acc@1: 0.134 Acc@10: 0.324 Acc@100: 0.569 AccSum: 1.026\n",
      "[best epoch: 90]\n",
      "[epoch 91][dev ] Acc@1: 0.139 Acc@10: 0.322 Acc@100: 0.570 AccSum: 1.030\n",
      "[epoch 91][test] Acc@1: 0.134 Acc@10: 0.325 Acc@100: 0.570 AccSum: 1.029\n",
      "[best epoch: 91]\n",
      "[epoch 92][dev ] Acc@1: 0.138 Acc@10: 0.321 Acc@100: 0.569 AccSum: 1.028\n",
      "[epoch 93][dev ] Acc@1: 0.139 Acc@10: 0.324 Acc@100: 0.571 AccSum: 1.033\n",
      "[epoch 93][test] Acc@1: 0.136 Acc@10: 0.328 Acc@100: 0.571 AccSum: 1.035\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.139 Acc@10: 0.325 Acc@100: 0.571 AccSum: 1.035\n",
      "[epoch 94][test] Acc@1: 0.136 Acc@10: 0.329 Acc@100: 0.573 AccSum: 1.038\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.138 Acc@10: 0.327 Acc@100: 0.571 AccSum: 1.036\n",
      "[epoch 95][test] Acc@1: 0.134 Acc@10: 0.332 Acc@100: 0.574 AccSum: 1.040\n",
      "[best epoch: 95]\n",
      "[epoch 96][dev ] Acc@1: 0.138 Acc@10: 0.324 Acc@100: 0.572 AccSum: 1.035\n",
      "[epoch 97][dev ] Acc@1: 0.139 Acc@10: 0.327 Acc@100: 0.574 AccSum: 1.039\n",
      "[epoch 97][test] Acc@1: 0.135 Acc@10: 0.333 Acc@100: 0.575 AccSum: 1.043\n",
      "[best epoch: 97]\n",
      "[epoch 98][dev ] Acc@1: 0.139 Acc@10: 0.327 Acc@100: 0.573 AccSum: 1.039\n",
      "[epoch 99][dev ] Acc@1: 0.140 Acc@10: 0.327 Acc@100: 0.573 AccSum: 1.039\n",
      "[epoch 100][dev ] Acc@1: 0.139 Acc@10: 0.327 Acc@100: 0.574 AccSum: 1.039\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=300, target_size=300).cuda(GPU_INDEX)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"term_to_graph_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=300, target_size=300).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c6b4adad9a457d8c0601fc2dc84ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.203\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=256, \\\n",
    "              dumb=True, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=256, sample=False,\\\n",
    "#             GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGD: %.3f MGD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### term -> surface+graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_fasttext_embeddings_full+snomed_node2vec_300d_20wl_embeddings.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.000 AccSum: 0.000\n",
      "[epoch 1][dev ] Acc@1: 0.051 Acc@10: 0.184 Acc@100: 0.463 AccSum: 0.697\n",
      "[epoch 1][test] Acc@1: 0.051 Acc@10: 0.189 Acc@100: 0.461 AccSum: 0.702\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.092 Acc@10: 0.309 Acc@100: 0.595 AccSum: 0.996\n",
      "[epoch 2][test] Acc@1: 0.097 Acc@10: 0.320 Acc@100: 0.602 AccSum: 1.019\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.136 Acc@10: 0.380 Acc@100: 0.668 AccSum: 1.184\n",
      "[epoch 3][test] Acc@1: 0.141 Acc@10: 0.384 Acc@100: 0.668 AccSum: 1.192\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.155 Acc@10: 0.433 Acc@100: 0.713 AccSum: 1.301\n",
      "[epoch 4][test] Acc@1: 0.165 Acc@10: 0.441 Acc@100: 0.711 AccSum: 1.317\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.190 Acc@10: 0.472 Acc@100: 0.738 AccSum: 1.400\n",
      "[epoch 5][test] Acc@1: 0.196 Acc@10: 0.475 Acc@100: 0.736 AccSum: 1.407\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.208 Acc@10: 0.492 Acc@100: 0.751 AccSum: 1.450\n",
      "[epoch 6][test] Acc@1: 0.211 Acc@10: 0.493 Acc@100: 0.756 AccSum: 1.461\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.233 Acc@10: 0.532 Acc@100: 0.781 AccSum: 1.546\n",
      "[epoch 7][test] Acc@1: 0.232 Acc@10: 0.530 Acc@100: 0.786 AccSum: 1.547\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.245 Acc@10: 0.543 Acc@100: 0.790 AccSum: 1.578\n",
      "[epoch 8][test] Acc@1: 0.242 Acc@10: 0.545 Acc@100: 0.794 AccSum: 1.581\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.248 Acc@10: 0.547 Acc@100: 0.794 AccSum: 1.589\n",
      "[epoch 9][test] Acc@1: 0.246 Acc@10: 0.555 Acc@100: 0.799 AccSum: 1.600\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.268 Acc@10: 0.571 Acc@100: 0.805 AccSum: 1.644\n",
      "[epoch 10][test] Acc@1: 0.264 Acc@10: 0.577 Acc@100: 0.809 AccSum: 1.649\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.280 Acc@10: 0.585 Acc@100: 0.812 AccSum: 1.678\n",
      "[epoch 11][test] Acc@1: 0.281 Acc@10: 0.588 Acc@100: 0.816 AccSum: 1.686\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.286 Acc@10: 0.590 Acc@100: 0.816 AccSum: 1.692\n",
      "[epoch 12][test] Acc@1: 0.285 Acc@10: 0.591 Acc@100: 0.821 AccSum: 1.698\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.285 Acc@10: 0.595 Acc@100: 0.821 AccSum: 1.702\n",
      "[epoch 13][test] Acc@1: 0.285 Acc@10: 0.602 Acc@100: 0.830 AccSum: 1.716\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.288 Acc@10: 0.603 Acc@100: 0.826 AccSum: 1.717\n",
      "[epoch 14][test] Acc@1: 0.290 Acc@10: 0.613 Acc@100: 0.836 AccSum: 1.739\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.293 Acc@10: 0.610 Acc@100: 0.833 AccSum: 1.737\n",
      "[epoch 15][test] Acc@1: 0.296 Acc@10: 0.621 Acc@100: 0.839 AccSum: 1.757\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.306 Acc@10: 0.613 Acc@100: 0.833 AccSum: 1.752\n",
      "[epoch 16][test] Acc@1: 0.306 Acc@10: 0.624 Acc@100: 0.843 AccSum: 1.773\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.311 Acc@10: 0.621 Acc@100: 0.836 AccSum: 1.768\n",
      "[epoch 17][test] Acc@1: 0.311 Acc@10: 0.630 Acc@100: 0.846 AccSum: 1.787\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.316 Acc@10: 0.630 Acc@100: 0.838 AccSum: 1.784\n",
      "[epoch 18][test] Acc@1: 0.314 Acc@10: 0.637 Acc@100: 0.848 AccSum: 1.799\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.320 Acc@10: 0.632 Acc@100: 0.844 AccSum: 1.796\n",
      "[epoch 19][test] Acc@1: 0.319 Acc@10: 0.642 Acc@100: 0.854 AccSum: 1.815\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.322 Acc@10: 0.637 Acc@100: 0.847 AccSum: 1.805\n",
      "[epoch 20][test] Acc@1: 0.323 Acc@10: 0.651 Acc@100: 0.858 AccSum: 1.832\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.329 Acc@10: 0.641 Acc@100: 0.847 AccSum: 1.817\n",
      "[epoch 21][test] Acc@1: 0.329 Acc@10: 0.656 Acc@100: 0.856 AccSum: 1.841\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.331 Acc@10: 0.644 Acc@100: 0.848 AccSum: 1.823\n",
      "[epoch 22][test] Acc@1: 0.329 Acc@10: 0.659 Acc@100: 0.858 AccSum: 1.846\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.338 Acc@10: 0.647 Acc@100: 0.848 AccSum: 1.833\n",
      "[epoch 23][test] Acc@1: 0.335 Acc@10: 0.664 Acc@100: 0.857 AccSum: 1.856\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.337 Acc@10: 0.645 Acc@100: 0.849 AccSum: 1.832\n",
      "[epoch 25][dev ] Acc@1: 0.338 Acc@10: 0.647 Acc@100: 0.850 AccSum: 1.835\n",
      "[epoch 25][test] Acc@1: 0.337 Acc@10: 0.667 Acc@100: 0.861 AccSum: 1.865\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.341 Acc@10: 0.649 Acc@100: 0.851 AccSum: 1.841\n",
      "[epoch 26][test] Acc@1: 0.340 Acc@10: 0.667 Acc@100: 0.861 AccSum: 1.868\n",
      "[best epoch: 26]\n",
      "[epoch 27][dev ] Acc@1: 0.346 Acc@10: 0.655 Acc@100: 0.854 AccSum: 1.855\n",
      "[epoch 27][test] Acc@1: 0.347 Acc@10: 0.673 Acc@100: 0.864 AccSum: 1.884\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.350 Acc@10: 0.658 Acc@100: 0.854 AccSum: 1.862\n",
      "[epoch 28][test] Acc@1: 0.353 Acc@10: 0.676 Acc@100: 0.864 AccSum: 1.894\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.355 Acc@10: 0.660 Acc@100: 0.854 AccSum: 1.869\n",
      "[epoch 29][test] Acc@1: 0.355 Acc@10: 0.677 Acc@100: 0.865 AccSum: 1.896\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.356 Acc@10: 0.662 Acc@100: 0.855 AccSum: 1.873\n",
      "[epoch 30][test] Acc@1: 0.355 Acc@10: 0.678 Acc@100: 0.867 AccSum: 1.900\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.361 Acc@10: 0.665 Acc@100: 0.857 AccSum: 1.883\n",
      "[epoch 31][test] Acc@1: 0.358 Acc@10: 0.681 Acc@100: 0.868 AccSum: 1.907\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.360 Acc@10: 0.663 Acc@100: 0.856 AccSum: 1.879\n",
      "[epoch 33][dev ] Acc@1: 0.359 Acc@10: 0.665 Acc@100: 0.858 AccSum: 1.882\n",
      "[epoch 34][dev ] Acc@1: 0.364 Acc@10: 0.668 Acc@100: 0.859 AccSum: 1.891\n",
      "[epoch 34][test] Acc@1: 0.366 Acc@10: 0.684 Acc@100: 0.870 AccSum: 1.921\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.366 Acc@10: 0.668 Acc@100: 0.859 AccSum: 1.892\n",
      "[epoch 35][test] Acc@1: 0.368 Acc@10: 0.686 Acc@100: 0.870 AccSum: 1.924\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.368 Acc@10: 0.671 Acc@100: 0.860 AccSum: 1.899\n",
      "[epoch 36][test] Acc@1: 0.371 Acc@10: 0.689 Acc@100: 0.871 AccSum: 1.932\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.376 Acc@10: 0.673 Acc@100: 0.862 AccSum: 1.912\n",
      "[epoch 37][test] Acc@1: 0.377 Acc@10: 0.692 Acc@100: 0.873 AccSum: 1.942\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.380 Acc@10: 0.675 Acc@100: 0.863 AccSum: 1.919\n",
      "[epoch 38][test] Acc@1: 0.381 Acc@10: 0.695 Acc@100: 0.875 AccSum: 1.951\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.384 Acc@10: 0.678 Acc@100: 0.864 AccSum: 1.927\n",
      "[epoch 39][test] Acc@1: 0.386 Acc@10: 0.697 Acc@100: 0.876 AccSum: 1.959\n",
      "[best epoch: 39]\n",
      "[epoch 40][dev ] Acc@1: 0.384 Acc@10: 0.678 Acc@100: 0.865 AccSum: 1.927\n",
      "[epoch 40][test] Acc@1: 0.388 Acc@10: 0.698 Acc@100: 0.876 AccSum: 1.962\n",
      "[best epoch: 40]\n",
      "[epoch 41][dev ] Acc@1: 0.383 Acc@10: 0.677 Acc@100: 0.867 AccSum: 1.927\n",
      "[epoch 42][dev ] Acc@1: 0.380 Acc@10: 0.677 Acc@100: 0.866 AccSum: 1.923\n",
      "[epoch 43][dev ] Acc@1: 0.383 Acc@10: 0.677 Acc@100: 0.867 AccSum: 1.926\n",
      "[epoch 44][dev ] Acc@1: 0.383 Acc@10: 0.681 Acc@100: 0.868 AccSum: 1.933\n",
      "[epoch 44][test] Acc@1: 0.391 Acc@10: 0.699 Acc@100: 0.878 AccSum: 1.968\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.385 Acc@10: 0.682 Acc@100: 0.868 AccSum: 1.936\n",
      "[epoch 45][test] Acc@1: 0.394 Acc@10: 0.703 Acc@100: 0.878 AccSum: 1.976\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.388 Acc@10: 0.684 Acc@100: 0.869 AccSum: 1.941\n",
      "[epoch 46][test] Acc@1: 0.398 Acc@10: 0.704 Acc@100: 0.880 AccSum: 1.983\n",
      "[best epoch: 46]\n",
      "[epoch 47][dev ] Acc@1: 0.390 Acc@10: 0.684 Acc@100: 0.868 AccSum: 1.943\n",
      "[epoch 47][test] Acc@1: 0.398 Acc@10: 0.705 Acc@100: 0.879 AccSum: 1.983\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.389 Acc@10: 0.688 Acc@100: 0.868 AccSum: 1.945\n",
      "[epoch 48][test] Acc@1: 0.397 Acc@10: 0.707 Acc@100: 0.879 AccSum: 1.984\n",
      "[best epoch: 48]\n",
      "[epoch 49][dev ] Acc@1: 0.392 Acc@10: 0.691 Acc@100: 0.870 AccSum: 1.953\n",
      "[epoch 49][test] Acc@1: 0.400 Acc@10: 0.707 Acc@100: 0.881 AccSum: 1.988\n",
      "[best epoch: 49]\n",
      "[epoch 50][dev ] Acc@1: 0.394 Acc@10: 0.689 Acc@100: 0.870 AccSum: 1.953\n",
      "[epoch 50][test] Acc@1: 0.400 Acc@10: 0.705 Acc@100: 0.881 AccSum: 1.986\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.394 Acc@10: 0.691 Acc@100: 0.870 AccSum: 1.955\n",
      "[epoch 51][test] Acc@1: 0.402 Acc@10: 0.706 Acc@100: 0.881 AccSum: 1.990\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.398 Acc@10: 0.693 Acc@100: 0.872 AccSum: 1.962\n",
      "[epoch 52][test] Acc@1: 0.404 Acc@10: 0.707 Acc@100: 0.883 AccSum: 1.995\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.395 Acc@10: 0.693 Acc@100: 0.873 AccSum: 1.961\n",
      "[epoch 54][dev ] Acc@1: 0.396 Acc@10: 0.695 Acc@100: 0.872 AccSum: 1.963\n",
      "[epoch 54][test] Acc@1: 0.404 Acc@10: 0.711 Acc@100: 0.883 AccSum: 1.998\n",
      "[best epoch: 54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 55][dev ] Acc@1: 0.396 Acc@10: 0.696 Acc@100: 0.872 AccSum: 1.965\n",
      "[epoch 55][test] Acc@1: 0.403 Acc@10: 0.715 Acc@100: 0.883 AccSum: 2.001\n",
      "[best epoch: 55]\n",
      "[epoch 56][dev ] Acc@1: 0.398 Acc@10: 0.698 Acc@100: 0.873 AccSum: 1.970\n",
      "[epoch 56][test] Acc@1: 0.405 Acc@10: 0.715 Acc@100: 0.885 AccSum: 2.006\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.398 Acc@10: 0.699 Acc@100: 0.874 AccSum: 1.971\n",
      "[epoch 57][test] Acc@1: 0.404 Acc@10: 0.716 Acc@100: 0.885 AccSum: 2.005\n",
      "[best epoch: 57]\n",
      "[epoch 58][dev ] Acc@1: 0.400 Acc@10: 0.698 Acc@100: 0.875 AccSum: 1.973\n",
      "[epoch 58][test] Acc@1: 0.406 Acc@10: 0.717 Acc@100: 0.885 AccSum: 2.008\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.402 Acc@10: 0.698 Acc@100: 0.875 AccSum: 1.976\n",
      "[epoch 59][test] Acc@1: 0.407 Acc@10: 0.717 Acc@100: 0.886 AccSum: 2.009\n",
      "[best epoch: 59]\n",
      "[epoch 60][dev ] Acc@1: 0.403 Acc@10: 0.700 Acc@100: 0.875 AccSum: 1.978\n",
      "[epoch 60][test] Acc@1: 0.408 Acc@10: 0.719 Acc@100: 0.886 AccSum: 2.014\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.405 Acc@10: 0.700 Acc@100: 0.874 AccSum: 1.980\n",
      "[epoch 61][test] Acc@1: 0.408 Acc@10: 0.719 Acc@100: 0.886 AccSum: 2.014\n",
      "[best epoch: 61]\n",
      "[epoch 62][dev ] Acc@1: 0.408 Acc@10: 0.698 Acc@100: 0.873 AccSum: 1.980\n",
      "[epoch 62][test] Acc@1: 0.410 Acc@10: 0.717 Acc@100: 0.885 AccSum: 2.013\n",
      "[best epoch: 62]\n",
      "[epoch 63][dev ] Acc@1: 0.408 Acc@10: 0.698 Acc@100: 0.875 AccSum: 1.981\n",
      "[epoch 63][test] Acc@1: 0.411 Acc@10: 0.717 Acc@100: 0.886 AccSum: 2.014\n",
      "[best epoch: 63]\n",
      "[epoch 64][dev ] Acc@1: 0.407 Acc@10: 0.699 Acc@100: 0.873 AccSum: 1.980\n",
      "[epoch 65][dev ] Acc@1: 0.408 Acc@10: 0.702 Acc@100: 0.873 AccSum: 1.983\n",
      "[epoch 65][test] Acc@1: 0.412 Acc@10: 0.721 Acc@100: 0.884 AccSum: 2.016\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.411 Acc@10: 0.703 Acc@100: 0.873 AccSum: 1.987\n",
      "[epoch 66][test] Acc@1: 0.413 Acc@10: 0.722 Acc@100: 0.884 AccSum: 2.019\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.412 Acc@10: 0.704 Acc@100: 0.873 AccSum: 1.990\n",
      "[epoch 67][test] Acc@1: 0.415 Acc@10: 0.723 Acc@100: 0.884 AccSum: 2.022\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.414 Acc@10: 0.703 Acc@100: 0.874 AccSum: 1.991\n",
      "[epoch 68][test] Acc@1: 0.415 Acc@10: 0.722 Acc@100: 0.886 AccSum: 2.023\n",
      "[best epoch: 68]\n",
      "[epoch 69][dev ] Acc@1: 0.415 Acc@10: 0.705 Acc@100: 0.874 AccSum: 1.994\n",
      "[epoch 69][test] Acc@1: 0.417 Acc@10: 0.724 Acc@100: 0.886 AccSum: 2.026\n",
      "[best epoch: 69]\n",
      "[epoch 70][dev ] Acc@1: 0.417 Acc@10: 0.705 Acc@100: 0.874 AccSum: 1.996\n",
      "[epoch 70][test] Acc@1: 0.420 Acc@10: 0.724 Acc@100: 0.886 AccSum: 2.029\n",
      "[best epoch: 70]\n",
      "[epoch 71][dev ] Acc@1: 0.415 Acc@10: 0.706 Acc@100: 0.873 AccSum: 1.995\n",
      "[epoch 72][dev ] Acc@1: 0.415 Acc@10: 0.704 Acc@100: 0.873 AccSum: 1.992\n",
      "[epoch 73][dev ] Acc@1: 0.412 Acc@10: 0.704 Acc@100: 0.874 AccSum: 1.990\n",
      "[epoch 74][dev ] Acc@1: 0.414 Acc@10: 0.704 Acc@100: 0.875 AccSum: 1.992\n",
      "[epoch 75][dev ] Acc@1: 0.415 Acc@10: 0.704 Acc@100: 0.876 AccSum: 1.994\n",
      "[epoch 76][dev ] Acc@1: 0.415 Acc@10: 0.704 Acc@100: 0.875 AccSum: 1.995\n",
      "[epoch 77][dev ] Acc@1: 0.414 Acc@10: 0.706 Acc@100: 0.877 AccSum: 1.996\n",
      "[epoch 77][test] Acc@1: 0.423 Acc@10: 0.725 Acc@100: 0.888 AccSum: 2.035\n",
      "[best epoch: 77]\n",
      "[epoch 78][dev ] Acc@1: 0.414 Acc@10: 0.707 Acc@100: 0.875 AccSum: 1.997\n",
      "[epoch 78][test] Acc@1: 0.422 Acc@10: 0.727 Acc@100: 0.887 AccSum: 2.037\n",
      "[best epoch: 78]\n",
      "[epoch 79][dev ] Acc@1: 0.416 Acc@10: 0.708 Acc@100: 0.875 AccSum: 2.000\n",
      "[epoch 79][test] Acc@1: 0.425 Acc@10: 0.727 Acc@100: 0.887 AccSum: 2.039\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.416 Acc@10: 0.707 Acc@100: 0.875 AccSum: 1.998\n",
      "[epoch 81][dev ] Acc@1: 0.419 Acc@10: 0.708 Acc@100: 0.874 AccSum: 2.001\n",
      "[epoch 81][test] Acc@1: 0.427 Acc@10: 0.726 Acc@100: 0.886 AccSum: 2.039\n",
      "[best epoch: 81]\n",
      "[epoch 82][dev ] Acc@1: 0.419 Acc@10: 0.711 Acc@100: 0.874 AccSum: 2.005\n",
      "[epoch 82][test] Acc@1: 0.428 Acc@10: 0.728 Acc@100: 0.886 AccSum: 2.043\n",
      "[best epoch: 82]\n",
      "[epoch 83][dev ] Acc@1: 0.420 Acc@10: 0.711 Acc@100: 0.876 AccSum: 2.007\n",
      "[epoch 83][test] Acc@1: 0.431 Acc@10: 0.730 Acc@100: 0.887 AccSum: 2.047\n",
      "[best epoch: 83]\n",
      "[epoch 84][dev ] Acc@1: 0.420 Acc@10: 0.712 Acc@100: 0.876 AccSum: 2.008\n",
      "[epoch 84][test] Acc@1: 0.430 Acc@10: 0.731 Acc@100: 0.887 AccSum: 2.048\n",
      "[best epoch: 84]\n",
      "[epoch 85][dev ] Acc@1: 0.420 Acc@10: 0.713 Acc@100: 0.875 AccSum: 2.008\n",
      "[epoch 85][test] Acc@1: 0.430 Acc@10: 0.733 Acc@100: 0.887 AccSum: 2.050\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.420 Acc@10: 0.713 Acc@100: 0.875 AccSum: 2.008\n",
      "[epoch 87][dev ] Acc@1: 0.421 Acc@10: 0.713 Acc@100: 0.874 AccSum: 2.009\n",
      "[epoch 87][test] Acc@1: 0.432 Acc@10: 0.732 Acc@100: 0.886 AccSum: 2.051\n",
      "[best epoch: 87]\n",
      "[epoch 88][dev ] Acc@1: 0.421 Acc@10: 0.714 Acc@100: 0.873 AccSum: 2.009\n",
      "[epoch 89][dev ] Acc@1: 0.421 Acc@10: 0.716 Acc@100: 0.875 AccSum: 2.012\n",
      "[epoch 89][test] Acc@1: 0.433 Acc@10: 0.734 Acc@100: 0.886 AccSum: 2.053\n",
      "[best epoch: 89]\n",
      "[epoch 90][dev ] Acc@1: 0.422 Acc@10: 0.716 Acc@100: 0.875 AccSum: 2.013\n",
      "[epoch 90][test] Acc@1: 0.433 Acc@10: 0.734 Acc@100: 0.886 AccSum: 2.053\n",
      "[best epoch: 90]\n",
      "[epoch 91][dev ] Acc@1: 0.423 Acc@10: 0.714 Acc@100: 0.876 AccSum: 2.013\n",
      "[epoch 91][test] Acc@1: 0.431 Acc@10: 0.732 Acc@100: 0.888 AccSum: 2.052\n",
      "[best epoch: 91]\n",
      "[epoch 92][dev ] Acc@1: 0.423 Acc@10: 0.715 Acc@100: 0.877 AccSum: 2.015\n",
      "[epoch 92][test] Acc@1: 0.433 Acc@10: 0.733 Acc@100: 0.888 AccSum: 2.054\n",
      "[best epoch: 92]\n",
      "[epoch 93][dev ] Acc@1: 0.425 Acc@10: 0.715 Acc@100: 0.876 AccSum: 2.016\n",
      "[epoch 93][test] Acc@1: 0.435 Acc@10: 0.733 Acc@100: 0.887 AccSum: 2.055\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.426 Acc@10: 0.715 Acc@100: 0.878 AccSum: 2.019\n",
      "[epoch 94][test] Acc@1: 0.436 Acc@10: 0.732 Acc@100: 0.889 AccSum: 2.057\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.424 Acc@10: 0.715 Acc@100: 0.877 AccSum: 2.016\n",
      "[epoch 96][dev ] Acc@1: 0.427 Acc@10: 0.716 Acc@100: 0.877 AccSum: 2.020\n",
      "[epoch 96][test] Acc@1: 0.438 Acc@10: 0.733 Acc@100: 0.889 AccSum: 2.060\n",
      "[best epoch: 96]\n",
      "[epoch 97][dev ] Acc@1: 0.428 Acc@10: 0.716 Acc@100: 0.878 AccSum: 2.021\n",
      "[epoch 97][test] Acc@1: 0.439 Acc@10: 0.733 Acc@100: 0.889 AccSum: 2.061\n",
      "[best epoch: 97]\n",
      "[epoch 98][dev ] Acc@1: 0.428 Acc@10: 0.717 Acc@100: 0.878 AccSum: 2.022\n",
      "[epoch 98][test] Acc@1: 0.439 Acc@10: 0.733 Acc@100: 0.889 AccSum: 2.061\n",
      "[best epoch: 98]\n",
      "[epoch 99][dev ] Acc@1: 0.428 Acc@10: 0.718 Acc@100: 0.877 AccSum: 2.023\n",
      "[epoch 99][test] Acc@1: 0.438 Acc@10: 0.733 Acc@100: 0.888 AccSum: 2.059\n",
      "[best epoch: 99]\n",
      "[epoch 100][dev ] Acc@1: 0.427 Acc@10: 0.717 Acc@100: 0.877 AccSum: 2.020\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=300, target_size=600).cuda(GPU_INDEX)\n",
    "train_params = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_params, lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2,max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, train_params, optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=300, out_features=600, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"ft_term_to_surface+graph_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=300, target_size=600).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191ab3e0cc5484cbb8c74f6cfcbe82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.541\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=128, dumb=True, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, sample=False,\\\n",
    "#             GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGD: %.3f MGD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine BERT with fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ft_term+bert_term -> ft_surface+bert_surface+graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_fasttext_embeddings_full+snomed_surface_bert_ts100k_embeddings_all_names_mean_full_new+snomed_node2vec_300d_20wl_embeddings.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings+chv_term_embeddings_BERTbr_ts100k.pkl\")\n",
    "\n",
    "gran = \"specific\"\n",
    "train_dict = build_train_dict(chv_train_path, gran=gran)\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=gran)\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=gran)\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=gran, \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.000 AccSum: 0.000\n",
      "[epoch 1][dev ] Acc@1: 0.190 Acc@10: 0.453 Acc@100: 0.680 AccSum: 1.323\n",
      "[epoch 1][test] Acc@1: 0.190 Acc@10: 0.445 Acc@100: 0.678 AccSum: 1.312\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.248 Acc@10: 0.531 Acc@100: 0.755 AccSum: 1.534\n",
      "[epoch 2][test] Acc@1: 0.239 Acc@10: 0.523 Acc@100: 0.751 AccSum: 1.512\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.271 Acc@10: 0.564 Acc@100: 0.782 AccSum: 1.617\n",
      "[epoch 3][test] Acc@1: 0.274 Acc@10: 0.562 Acc@100: 0.775 AccSum: 1.611\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.290 Acc@10: 0.576 Acc@100: 0.787 AccSum: 1.654\n",
      "[epoch 4][test] Acc@1: 0.291 Acc@10: 0.584 Acc@100: 0.786 AccSum: 1.661\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.311 Acc@10: 0.604 Acc@100: 0.801 AccSum: 1.716\n",
      "[epoch 5][test] Acc@1: 0.312 Acc@10: 0.605 Acc@100: 0.805 AccSum: 1.722\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.326 Acc@10: 0.612 Acc@100: 0.812 AccSum: 1.750\n",
      "[epoch 6][test] Acc@1: 0.330 Acc@10: 0.615 Acc@100: 0.813 AccSum: 1.759\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.337 Acc@10: 0.613 Acc@100: 0.820 AccSum: 1.771\n",
      "[epoch 7][test] Acc@1: 0.339 Acc@10: 0.622 Acc@100: 0.817 AccSum: 1.778\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.345 Acc@10: 0.622 Acc@100: 0.826 AccSum: 1.793\n",
      "[epoch 8][test] Acc@1: 0.348 Acc@10: 0.634 Acc@100: 0.826 AccSum: 1.809\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.360 Acc@10: 0.636 Acc@100: 0.842 AccSum: 1.837\n",
      "[epoch 9][test] Acc@1: 0.360 Acc@10: 0.646 Acc@100: 0.840 AccSum: 1.846\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.359 Acc@10: 0.639 Acc@100: 0.842 AccSum: 1.839\n",
      "[epoch 10][test] Acc@1: 0.363 Acc@10: 0.651 Acc@100: 0.844 AccSum: 1.858\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.363 Acc@10: 0.647 Acc@100: 0.843 AccSum: 1.854\n",
      "[epoch 11][test] Acc@1: 0.367 Acc@10: 0.656 Acc@100: 0.845 AccSum: 1.868\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.372 Acc@10: 0.657 Acc@100: 0.850 AccSum: 1.879\n",
      "[epoch 12][test] Acc@1: 0.374 Acc@10: 0.663 Acc@100: 0.848 AccSum: 1.885\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.375 Acc@10: 0.663 Acc@100: 0.850 AccSum: 1.888\n",
      "[epoch 13][test] Acc@1: 0.380 Acc@10: 0.667 Acc@100: 0.857 AccSum: 1.904\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.380 Acc@10: 0.668 Acc@100: 0.854 AccSum: 1.901\n",
      "[epoch 14][test] Acc@1: 0.382 Acc@10: 0.670 Acc@100: 0.859 AccSum: 1.911\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.383 Acc@10: 0.672 Acc@100: 0.854 AccSum: 1.908\n",
      "[epoch 15][test] Acc@1: 0.387 Acc@10: 0.675 Acc@100: 0.861 AccSum: 1.923\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.389 Acc@10: 0.676 Acc@100: 0.856 AccSum: 1.921\n",
      "[epoch 16][test] Acc@1: 0.391 Acc@10: 0.682 Acc@100: 0.862 AccSum: 1.935\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.392 Acc@10: 0.676 Acc@100: 0.859 AccSum: 1.927\n",
      "[epoch 17][test] Acc@1: 0.392 Acc@10: 0.684 Acc@100: 0.865 AccSum: 1.941\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.394 Acc@10: 0.679 Acc@100: 0.860 AccSum: 1.934\n",
      "[epoch 18][test] Acc@1: 0.395 Acc@10: 0.685 Acc@100: 0.867 AccSum: 1.946\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.394 Acc@10: 0.682 Acc@100: 0.862 AccSum: 1.937\n",
      "[epoch 19][test] Acc@1: 0.398 Acc@10: 0.688 Acc@100: 0.867 AccSum: 1.952\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.397 Acc@10: 0.683 Acc@100: 0.864 AccSum: 1.945\n",
      "[epoch 20][test] Acc@1: 0.402 Acc@10: 0.693 Acc@100: 0.868 AccSum: 1.963\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.400 Acc@10: 0.690 Acc@100: 0.866 AccSum: 1.955\n",
      "[epoch 21][test] Acc@1: 0.402 Acc@10: 0.696 Acc@100: 0.870 AccSum: 1.968\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.403 Acc@10: 0.692 Acc@100: 0.867 AccSum: 1.961\n",
      "[epoch 22][test] Acc@1: 0.403 Acc@10: 0.700 Acc@100: 0.874 AccSum: 1.977\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.404 Acc@10: 0.694 Acc@100: 0.868 AccSum: 1.966\n",
      "[epoch 23][test] Acc@1: 0.407 Acc@10: 0.703 Acc@100: 0.875 AccSum: 1.985\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.405 Acc@10: 0.696 Acc@100: 0.872 AccSum: 1.973\n",
      "[epoch 24][test] Acc@1: 0.409 Acc@10: 0.705 Acc@100: 0.876 AccSum: 1.989\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.406 Acc@10: 0.696 Acc@100: 0.873 AccSum: 1.975\n",
      "[epoch 25][test] Acc@1: 0.411 Acc@10: 0.705 Acc@100: 0.876 AccSum: 1.993\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.408 Acc@10: 0.700 Acc@100: 0.871 AccSum: 1.979\n",
      "[epoch 26][test] Acc@1: 0.414 Acc@10: 0.709 Acc@100: 0.877 AccSum: 1.999\n",
      "[best epoch: 26]\n",
      "[epoch 27][dev ] Acc@1: 0.410 Acc@10: 0.701 Acc@100: 0.871 AccSum: 1.982\n",
      "[epoch 27][test] Acc@1: 0.412 Acc@10: 0.710 Acc@100: 0.877 AccSum: 1.999\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.411 Acc@10: 0.701 Acc@100: 0.871 AccSum: 1.982\n",
      "[epoch 29][dev ] Acc@1: 0.411 Acc@10: 0.705 Acc@100: 0.873 AccSum: 1.989\n",
      "[epoch 29][test] Acc@1: 0.414 Acc@10: 0.713 Acc@100: 0.879 AccSum: 2.006\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.410 Acc@10: 0.705 Acc@100: 0.875 AccSum: 1.990\n",
      "[epoch 30][test] Acc@1: 0.419 Acc@10: 0.714 Acc@100: 0.880 AccSum: 2.013\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.416 Acc@10: 0.706 Acc@100: 0.875 AccSum: 1.997\n",
      "[epoch 31][test] Acc@1: 0.422 Acc@10: 0.717 Acc@100: 0.882 AccSum: 2.020\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.421 Acc@10: 0.706 Acc@100: 0.876 AccSum: 2.003\n",
      "[epoch 32][test] Acc@1: 0.424 Acc@10: 0.720 Acc@100: 0.881 AccSum: 2.025\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.422 Acc@10: 0.708 Acc@100: 0.876 AccSum: 2.006\n",
      "[epoch 33][test] Acc@1: 0.427 Acc@10: 0.722 Acc@100: 0.881 AccSum: 2.030\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.419 Acc@10: 0.712 Acc@100: 0.877 AccSum: 2.007\n",
      "[epoch 34][test] Acc@1: 0.427 Acc@10: 0.721 Acc@100: 0.881 AccSum: 2.028\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.420 Acc@10: 0.710 Acc@100: 0.875 AccSum: 2.005\n",
      "[epoch 36][dev ] Acc@1: 0.421 Acc@10: 0.711 Acc@100: 0.876 AccSum: 2.008\n",
      "[epoch 36][test] Acc@1: 0.428 Acc@10: 0.725 Acc@100: 0.881 AccSum: 2.035\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.424 Acc@10: 0.712 Acc@100: 0.877 AccSum: 2.014\n",
      "[epoch 37][test] Acc@1: 0.429 Acc@10: 0.727 Acc@100: 0.883 AccSum: 2.038\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.426 Acc@10: 0.717 Acc@100: 0.878 AccSum: 2.021\n",
      "[epoch 38][test] Acc@1: 0.431 Acc@10: 0.730 Acc@100: 0.883 AccSum: 2.044\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.430 Acc@10: 0.718 Acc@100: 0.880 AccSum: 2.029\n",
      "[epoch 39][test] Acc@1: 0.434 Acc@10: 0.732 Acc@100: 0.884 AccSum: 2.050\n",
      "[best epoch: 39]\n",
      "[epoch 40][dev ] Acc@1: 0.430 Acc@10: 0.717 Acc@100: 0.881 AccSum: 2.028\n",
      "[epoch 41][dev ] Acc@1: 0.433 Acc@10: 0.718 Acc@100: 0.881 AccSum: 2.031\n",
      "[epoch 41][test] Acc@1: 0.436 Acc@10: 0.734 Acc@100: 0.885 AccSum: 2.055\n",
      "[best epoch: 41]\n",
      "[epoch 42][dev ] Acc@1: 0.431 Acc@10: 0.719 Acc@100: 0.880 AccSum: 2.030\n",
      "[epoch 43][dev ] Acc@1: 0.431 Acc@10: 0.719 Acc@100: 0.880 AccSum: 2.031\n",
      "[epoch 44][dev ] Acc@1: 0.433 Acc@10: 0.722 Acc@100: 0.880 AccSum: 2.035\n",
      "[epoch 44][test] Acc@1: 0.438 Acc@10: 0.736 Acc@100: 0.885 AccSum: 2.059\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.435 Acc@10: 0.723 Acc@100: 0.882 AccSum: 2.040\n",
      "[epoch 45][test] Acc@1: 0.441 Acc@10: 0.736 Acc@100: 0.885 AccSum: 2.062\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.437 Acc@10: 0.723 Acc@100: 0.881 AccSum: 2.041\n",
      "[epoch 46][test] Acc@1: 0.441 Acc@10: 0.737 Acc@100: 0.885 AccSum: 2.063\n",
      "[best epoch: 46]\n",
      "[epoch 47][dev ] Acc@1: 0.438 Acc@10: 0.724 Acc@100: 0.881 AccSum: 2.043\n",
      "[epoch 47][test] Acc@1: 0.441 Acc@10: 0.738 Acc@100: 0.885 AccSum: 2.064\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.437 Acc@10: 0.723 Acc@100: 0.882 AccSum: 2.041\n",
      "[epoch 49][dev ] Acc@1: 0.437 Acc@10: 0.723 Acc@100: 0.882 AccSum: 2.042\n",
      "[epoch 50][dev ] Acc@1: 0.437 Acc@10: 0.724 Acc@100: 0.881 AccSum: 2.042\n",
      "[epoch 51][dev ] Acc@1: 0.440 Acc@10: 0.723 Acc@100: 0.882 AccSum: 2.045\n",
      "[epoch 51][test] Acc@1: 0.448 Acc@10: 0.742 Acc@100: 0.886 AccSum: 2.076\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.439 Acc@10: 0.727 Acc@100: 0.882 AccSum: 2.047\n",
      "[epoch 52][test] Acc@1: 0.448 Acc@10: 0.743 Acc@100: 0.886 AccSum: 2.077\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.439 Acc@10: 0.728 Acc@100: 0.882 AccSum: 2.049\n",
      "[epoch 53][test] Acc@1: 0.449 Acc@10: 0.744 Acc@100: 0.886 AccSum: 2.078\n",
      "[best epoch: 53]\n",
      "[epoch 54][dev ] Acc@1: 0.437 Acc@10: 0.728 Acc@100: 0.883 AccSum: 2.048\n",
      "[epoch 55][dev ] Acc@1: 0.437 Acc@10: 0.729 Acc@100: 0.882 AccSum: 2.048\n",
      "[epoch 56][dev ] Acc@1: 0.438 Acc@10: 0.728 Acc@100: 0.883 AccSum: 2.049\n",
      "[epoch 57][dev ] Acc@1: 0.440 Acc@10: 0.731 Acc@100: 0.884 AccSum: 2.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 57][test] Acc@1: 0.453 Acc@10: 0.745 Acc@100: 0.887 AccSum: 2.085\n",
      "[best epoch: 57]\n",
      "[epoch 58][dev ] Acc@1: 0.444 Acc@10: 0.733 Acc@100: 0.885 AccSum: 2.062\n",
      "[epoch 58][test] Acc@1: 0.455 Acc@10: 0.746 Acc@100: 0.887 AccSum: 2.088\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.444 Acc@10: 0.734 Acc@100: 0.884 AccSum: 2.063\n",
      "[epoch 59][test] Acc@1: 0.455 Acc@10: 0.747 Acc@100: 0.888 AccSum: 2.090\n",
      "[best epoch: 59]\n",
      "[epoch 60][dev ] Acc@1: 0.446 Acc@10: 0.735 Acc@100: 0.885 AccSum: 2.065\n",
      "[epoch 60][test] Acc@1: 0.456 Acc@10: 0.747 Acc@100: 0.889 AccSum: 2.092\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.447 Acc@10: 0.734 Acc@100: 0.884 AccSum: 2.066\n",
      "[epoch 61][test] Acc@1: 0.456 Acc@10: 0.748 Acc@100: 0.889 AccSum: 2.093\n",
      "[best epoch: 61]\n",
      "[epoch 62][dev ] Acc@1: 0.446 Acc@10: 0.734 Acc@100: 0.885 AccSum: 2.065\n",
      "[epoch 63][dev ] Acc@1: 0.447 Acc@10: 0.735 Acc@100: 0.885 AccSum: 2.067\n",
      "[epoch 63][test] Acc@1: 0.456 Acc@10: 0.748 Acc@100: 0.887 AccSum: 2.092\n",
      "[best epoch: 63]\n",
      "[epoch 64][dev ] Acc@1: 0.447 Acc@10: 0.736 Acc@100: 0.885 AccSum: 2.068\n",
      "[epoch 64][test] Acc@1: 0.456 Acc@10: 0.749 Acc@100: 0.887 AccSum: 2.092\n",
      "[best epoch: 64]\n",
      "[epoch 65][dev ] Acc@1: 0.447 Acc@10: 0.740 Acc@100: 0.887 AccSum: 2.073\n",
      "[epoch 65][test] Acc@1: 0.458 Acc@10: 0.750 Acc@100: 0.888 AccSum: 2.096\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.448 Acc@10: 0.741 Acc@100: 0.886 AccSum: 2.075\n",
      "[epoch 66][test] Acc@1: 0.460 Acc@10: 0.751 Acc@100: 0.889 AccSum: 2.099\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.449 Acc@10: 0.742 Acc@100: 0.886 AccSum: 2.078\n",
      "[epoch 67][test] Acc@1: 0.460 Acc@10: 0.751 Acc@100: 0.889 AccSum: 2.100\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.450 Acc@10: 0.741 Acc@100: 0.887 AccSum: 2.078\n",
      "[epoch 69][dev ] Acc@1: 0.452 Acc@10: 0.739 Acc@100: 0.887 AccSum: 2.078\n",
      "[epoch 70][dev ] Acc@1: 0.451 Acc@10: 0.740 Acc@100: 0.887 AccSum: 2.078\n",
      "[epoch 70][test] Acc@1: 0.462 Acc@10: 0.751 Acc@100: 0.890 AccSum: 2.103\n",
      "[best epoch: 70]\n",
      "[epoch 71][dev ] Acc@1: 0.452 Acc@10: 0.741 Acc@100: 0.888 AccSum: 2.081\n",
      "[epoch 71][test] Acc@1: 0.463 Acc@10: 0.751 Acc@100: 0.891 AccSum: 2.105\n",
      "[best epoch: 71]\n",
      "[epoch 72][dev ] Acc@1: 0.453 Acc@10: 0.743 Acc@100: 0.888 AccSum: 2.084\n",
      "[epoch 72][test] Acc@1: 0.463 Acc@10: 0.752 Acc@100: 0.890 AccSum: 2.106\n",
      "[best epoch: 72]\n",
      "[epoch 73][dev ] Acc@1: 0.454 Acc@10: 0.742 Acc@100: 0.888 AccSum: 2.084\n",
      "[epoch 74][dev ] Acc@1: 0.454 Acc@10: 0.742 Acc@100: 0.888 AccSum: 2.084\n",
      "[epoch 75][dev ] Acc@1: 0.453 Acc@10: 0.744 Acc@100: 0.888 AccSum: 2.086\n",
      "[epoch 75][test] Acc@1: 0.465 Acc@10: 0.754 Acc@100: 0.890 AccSum: 2.108\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.454 Acc@10: 0.745 Acc@100: 0.890 AccSum: 2.090\n",
      "[epoch 76][test] Acc@1: 0.465 Acc@10: 0.752 Acc@100: 0.890 AccSum: 2.107\n",
      "[best epoch: 76]\n",
      "[epoch 77][dev ] Acc@1: 0.454 Acc@10: 0.745 Acc@100: 0.891 AccSum: 2.090\n",
      "[epoch 77][test] Acc@1: 0.466 Acc@10: 0.753 Acc@100: 0.891 AccSum: 2.109\n",
      "[best epoch: 77]\n",
      "[epoch 78][dev ] Acc@1: 0.458 Acc@10: 0.745 Acc@100: 0.891 AccSum: 2.093\n",
      "[epoch 78][test] Acc@1: 0.467 Acc@10: 0.754 Acc@100: 0.891 AccSum: 2.112\n",
      "[best epoch: 78]\n",
      "[epoch 79][dev ] Acc@1: 0.460 Acc@10: 0.747 Acc@100: 0.891 AccSum: 2.098\n",
      "[epoch 79][test] Acc@1: 0.468 Acc@10: 0.754 Acc@100: 0.891 AccSum: 2.114\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.461 Acc@10: 0.748 Acc@100: 0.891 AccSum: 2.100\n",
      "[epoch 80][test] Acc@1: 0.469 Acc@10: 0.755 Acc@100: 0.891 AccSum: 2.115\n",
      "[best epoch: 80]\n",
      "[epoch 81][dev ] Acc@1: 0.463 Acc@10: 0.747 Acc@100: 0.891 AccSum: 2.101\n",
      "[epoch 81][test] Acc@1: 0.470 Acc@10: 0.755 Acc@100: 0.891 AccSum: 2.116\n",
      "[best epoch: 81]\n",
      "[epoch 82][dev ] Acc@1: 0.463 Acc@10: 0.748 Acc@100: 0.891 AccSum: 2.101\n",
      "[epoch 83][dev ] Acc@1: 0.460 Acc@10: 0.749 Acc@100: 0.890 AccSum: 2.099\n",
      "[epoch 84][dev ] Acc@1: 0.462 Acc@10: 0.749 Acc@100: 0.890 AccSum: 2.101\n",
      "[epoch 85][dev ] Acc@1: 0.463 Acc@10: 0.750 Acc@100: 0.890 AccSum: 2.103\n",
      "[epoch 85][test] Acc@1: 0.471 Acc@10: 0.756 Acc@100: 0.892 AccSum: 2.119\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.463 Acc@10: 0.750 Acc@100: 0.891 AccSum: 2.103\n",
      "[epoch 87][dev ] Acc@1: 0.463 Acc@10: 0.750 Acc@100: 0.891 AccSum: 2.103\n",
      "[epoch 87][test] Acc@1: 0.472 Acc@10: 0.758 Acc@100: 0.892 AccSum: 2.122\n",
      "[best epoch: 87]\n",
      "[epoch 88][dev ] Acc@1: 0.463 Acc@10: 0.750 Acc@100: 0.890 AccSum: 2.104\n",
      "[epoch 88][test] Acc@1: 0.474 Acc@10: 0.758 Acc@100: 0.892 AccSum: 2.124\n",
      "[best epoch: 88]\n",
      "[epoch 89][dev ] Acc@1: 0.464 Acc@10: 0.751 Acc@100: 0.891 AccSum: 2.106\n",
      "[epoch 89][test] Acc@1: 0.474 Acc@10: 0.759 Acc@100: 0.892 AccSum: 2.125\n",
      "[best epoch: 89]\n",
      "[epoch 90][dev ] Acc@1: 0.465 Acc@10: 0.750 Acc@100: 0.891 AccSum: 2.106\n",
      "[epoch 90][test] Acc@1: 0.475 Acc@10: 0.759 Acc@100: 0.892 AccSum: 2.126\n",
      "[best epoch: 90]\n",
      "[epoch 91][dev ] Acc@1: 0.467 Acc@10: 0.751 Acc@100: 0.891 AccSum: 2.108\n",
      "[epoch 91][test] Acc@1: 0.476 Acc@10: 0.759 Acc@100: 0.893 AccSum: 2.127\n",
      "[best epoch: 91]\n",
      "[epoch 92][dev ] Acc@1: 0.469 Acc@10: 0.751 Acc@100: 0.891 AccSum: 2.110\n",
      "[epoch 92][test] Acc@1: 0.476 Acc@10: 0.759 Acc@100: 0.893 AccSum: 2.127\n",
      "[best epoch: 92]\n",
      "[epoch 93][dev ] Acc@1: 0.470 Acc@10: 0.751 Acc@100: 0.890 AccSum: 2.111\n",
      "[epoch 93][test] Acc@1: 0.477 Acc@10: 0.760 Acc@100: 0.893 AccSum: 2.129\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.471 Acc@10: 0.752 Acc@100: 0.892 AccSum: 2.115\n",
      "[epoch 94][test] Acc@1: 0.477 Acc@10: 0.759 Acc@100: 0.893 AccSum: 2.130\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.469 Acc@10: 0.753 Acc@100: 0.892 AccSum: 2.114\n",
      "[epoch 96][dev ] Acc@1: 0.470 Acc@10: 0.753 Acc@100: 0.892 AccSum: 2.115\n",
      "[epoch 97][dev ] Acc@1: 0.469 Acc@10: 0.752 Acc@100: 0.892 AccSum: 2.113\n",
      "[epoch 98][dev ] Acc@1: 0.471 Acc@10: 0.752 Acc@100: 0.891 AccSum: 2.115\n",
      "[epoch 99][dev ] Acc@1: 0.472 Acc@10: 0.753 Acc@100: 0.890 AccSum: 2.115\n",
      "[epoch 100][dev ] Acc@1: 0.472 Acc@10: 0.754 Acc@100: 0.891 AccSum: 2.117\n",
      "[epoch 100][test] Acc@1: 0.480 Acc@10: 0.761 Acc@100: 0.896 AccSum: 2.137\n",
      "[best epoch: 100]\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=1068, target_size=1368).cuda(GPU_INDEX)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=1068, out_features=1368, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"ft_bert_context_term_to_ft_bert_surface+graph_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=1068, target_size=1368).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156bb15fde944d35995884f6574079c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.581\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=64, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, \\\n",
    "#              GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGRD: %.3f MGRD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio attempted by heuristics: 51.1%\n",
      "0.44632639047837036\n",
      "[dict+model] Acc@1: 0.657 Acc@10: 0.787 Acc@100: 0.862 Acc sum: 2.306\n",
      "ratio attempted by heuristics: 45.2%\n",
      "0.381551842526894\n",
      "[smatch+model] Acc@1: 0.590 Acc@10: 0.751 Acc@100: 0.847 Acc sum: 2.189\n",
      "ratio attempted by heuristics: 69.3%\n",
      "0.596932936598764\n",
      "[dict+smatch+model] Acc@1: 0.708 Acc@10: 0.785 Acc@100: 0.841 Acc sum: 2.335\n"
     ]
    }
   ],
   "source": [
    "# test back-off\n",
    "accs, pred_dict = compute_metrics_backoff(test_loader, testset, model, sf2id=None, train_dict=train_dict, \\\n",
    "                           topks=(1,10,100), bsz=64, GPU_INDEX=GPU_INDEX)\n",
    "print (\"[dict+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "       (accs[0], accs[1], accs[2], sum(accs)))\n",
    "\n",
    "# test back-off\n",
    "accs, pred_dict = compute_metrics_backoff(test_loader, testset, model, sf2id=SF2ID, train_dict=None, \\\n",
    "                           topks=(1,10,100), bsz=64, GPU_INDEX=GPU_INDEX)\n",
    "print (\"[smatch+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "       (accs[0], accs[1], accs[2], sum(accs)))\n",
    "\n",
    "# test back-off\n",
    "accs, pred_dict = compute_metrics_backoff(test_loader, testset, model, sf2id=SF2ID, train_dict=train_dict, \\\n",
    "                           topks=(1,10,100), bsz=64, GPU_INDEX=GPU_INDEX)\n",
    "print (\"[dict+smatch+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "       (accs[0], accs[1], accs[2], sum(accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ft_term+bert_term -> ft_surface+bert_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH, \"snomed_surface_fasttext_embeddings_full+snomed_surface_bert_ts100k_embeddings_all_names_mean_full_new.pkl\")\n",
    "term_vec_path = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings+chv_term_embeddings_BERTbr_ts100k.pkl\")\n",
    "\n",
    "train_loader, _ = get_loader_single(FULL_CHV_PATH, chv_train_path,\n",
    "                                    term_vec_path, snomed_vec_path, \n",
    "                                    batch_size=64, shuffle=True, \n",
    "                                    num_workers=10, gran=\"specific\")\n",
    "val_loader, valset = get_loader_single(FULL_CHV_PATH, chv_dev_path, \n",
    "                                       term_vec_path, snomed_vec_path, \n",
    "                                       batch_size=64, shuffle=False, \n",
    "                                       num_workers=10, gran=\"specific\")\n",
    "test_loader, testset = get_loader_single(FULL_CHV_PATH, chv_test_path, \n",
    "                                         term_vec_path, snomed_vec_path, \n",
    "                                         batch_size=64, shuffle=False, \n",
    "                                         num_workers=10, gran=\"specific\", \n",
    "                                         load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.000 AccSum: 0.000\n",
      "[epoch 1][dev ] Acc@1: 0.182 Acc@10: 0.441 Acc@100: 0.677 AccSum: 1.300\n",
      "[epoch 1][test] Acc@1: 0.190 Acc@10: 0.442 Acc@100: 0.672 AccSum: 1.304\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.230 Acc@10: 0.498 Acc@100: 0.729 AccSum: 1.457\n",
      "[epoch 2][test] Acc@1: 0.233 Acc@10: 0.505 Acc@100: 0.726 AccSum: 1.464\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.249 Acc@10: 0.521 Acc@100: 0.739 AccSum: 1.508\n",
      "[epoch 3][test] Acc@1: 0.253 Acc@10: 0.526 Acc@100: 0.735 AccSum: 1.514\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.267 Acc@10: 0.544 Acc@100: 0.764 AccSum: 1.575\n",
      "[epoch 4][test] Acc@1: 0.279 Acc@10: 0.550 Acc@100: 0.753 AccSum: 1.582\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.287 Acc@10: 0.566 Acc@100: 0.776 AccSum: 1.629\n",
      "[epoch 5][test] Acc@1: 0.290 Acc@10: 0.572 Acc@100: 0.771 AccSum: 1.633\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.293 Acc@10: 0.573 Acc@100: 0.779 AccSum: 1.645\n",
      "[epoch 6][test] Acc@1: 0.293 Acc@10: 0.577 Acc@100: 0.775 AccSum: 1.645\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.307 Acc@10: 0.589 Acc@100: 0.789 AccSum: 1.685\n",
      "[epoch 7][test] Acc@1: 0.309 Acc@10: 0.590 Acc@100: 0.785 AccSum: 1.683\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.313 Acc@10: 0.594 Acc@100: 0.800 AccSum: 1.707\n",
      "[epoch 8][test] Acc@1: 0.316 Acc@10: 0.598 Acc@100: 0.791 AccSum: 1.705\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.314 Acc@10: 0.600 Acc@100: 0.805 AccSum: 1.718\n",
      "[epoch 9][test] Acc@1: 0.319 Acc@10: 0.604 Acc@100: 0.799 AccSum: 1.723\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.320 Acc@10: 0.610 Acc@100: 0.813 AccSum: 1.743\n",
      "[epoch 10][test] Acc@1: 0.327 Acc@10: 0.614 Acc@100: 0.807 AccSum: 1.748\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.323 Acc@10: 0.615 Acc@100: 0.815 AccSum: 1.753\n",
      "[epoch 11][test] Acc@1: 0.332 Acc@10: 0.617 Acc@100: 0.810 AccSum: 1.759\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.331 Acc@10: 0.621 Acc@100: 0.819 AccSum: 1.771\n",
      "[epoch 12][test] Acc@1: 0.335 Acc@10: 0.621 Acc@100: 0.813 AccSum: 1.769\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.335 Acc@10: 0.628 Acc@100: 0.822 AccSum: 1.785\n",
      "[epoch 13][test] Acc@1: 0.340 Acc@10: 0.628 Acc@100: 0.815 AccSum: 1.783\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.337 Acc@10: 0.631 Acc@100: 0.824 AccSum: 1.792\n",
      "[epoch 14][test] Acc@1: 0.340 Acc@10: 0.631 Acc@100: 0.818 AccSum: 1.789\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.337 Acc@10: 0.632 Acc@100: 0.825 AccSum: 1.793\n",
      "[epoch 15][test] Acc@1: 0.343 Acc@10: 0.632 Acc@100: 0.821 AccSum: 1.797\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.343 Acc@10: 0.635 Acc@100: 0.824 AccSum: 1.802\n",
      "[epoch 16][test] Acc@1: 0.346 Acc@10: 0.634 Acc@100: 0.824 AccSum: 1.804\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.348 Acc@10: 0.643 Acc@100: 0.829 AccSum: 1.820\n",
      "[epoch 17][test] Acc@1: 0.348 Acc@10: 0.640 Acc@100: 0.828 AccSum: 1.816\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.346 Acc@10: 0.644 Acc@100: 0.830 AccSum: 1.820\n",
      "[epoch 19][dev ] Acc@1: 0.347 Acc@10: 0.645 Acc@100: 0.832 AccSum: 1.825\n",
      "[epoch 19][test] Acc@1: 0.353 Acc@10: 0.642 Acc@100: 0.831 AccSum: 1.827\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.350 Acc@10: 0.642 Acc@100: 0.833 AccSum: 1.825\n",
      "[epoch 20][test] Acc@1: 0.355 Acc@10: 0.642 Acc@100: 0.832 AccSum: 1.830\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.352 Acc@10: 0.645 Acc@100: 0.836 AccSum: 1.833\n",
      "[epoch 21][test] Acc@1: 0.358 Acc@10: 0.646 Acc@100: 0.835 AccSum: 1.840\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.355 Acc@10: 0.646 Acc@100: 0.837 AccSum: 1.838\n",
      "[epoch 22][test] Acc@1: 0.361 Acc@10: 0.652 Acc@100: 0.837 AccSum: 1.851\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.362 Acc@10: 0.647 Acc@100: 0.837 AccSum: 1.846\n",
      "[epoch 23][test] Acc@1: 0.364 Acc@10: 0.655 Acc@100: 0.839 AccSum: 1.858\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.361 Acc@10: 0.653 Acc@100: 0.840 AccSum: 1.854\n",
      "[epoch 24][test] Acc@1: 0.367 Acc@10: 0.658 Acc@100: 0.840 AccSum: 1.865\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.361 Acc@10: 0.657 Acc@100: 0.840 AccSum: 1.858\n",
      "[epoch 25][test] Acc@1: 0.367 Acc@10: 0.661 Acc@100: 0.843 AccSum: 1.870\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.361 Acc@10: 0.656 Acc@100: 0.840 AccSum: 1.857\n",
      "[epoch 27][dev ] Acc@1: 0.361 Acc@10: 0.658 Acc@100: 0.841 AccSum: 1.860\n",
      "[epoch 27][test] Acc@1: 0.368 Acc@10: 0.661 Acc@100: 0.842 AccSum: 1.870\n",
      "[best epoch: 27]\n",
      "[epoch 28][dev ] Acc@1: 0.362 Acc@10: 0.656 Acc@100: 0.841 AccSum: 1.860\n",
      "[epoch 29][dev ] Acc@1: 0.365 Acc@10: 0.657 Acc@100: 0.841 AccSum: 1.862\n",
      "[epoch 29][test] Acc@1: 0.370 Acc@10: 0.664 Acc@100: 0.843 AccSum: 1.878\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.366 Acc@10: 0.658 Acc@100: 0.843 AccSum: 1.866\n",
      "[epoch 30][test] Acc@1: 0.372 Acc@10: 0.667 Acc@100: 0.843 AccSum: 1.882\n",
      "[best epoch: 30]\n",
      "[epoch 31][dev ] Acc@1: 0.368 Acc@10: 0.663 Acc@100: 0.845 AccSum: 1.876\n",
      "[epoch 31][test] Acc@1: 0.376 Acc@10: 0.667 Acc@100: 0.846 AccSum: 1.889\n",
      "[best epoch: 31]\n",
      "[epoch 32][dev ] Acc@1: 0.370 Acc@10: 0.665 Acc@100: 0.847 AccSum: 1.881\n",
      "[epoch 32][test] Acc@1: 0.377 Acc@10: 0.668 Acc@100: 0.848 AccSum: 1.894\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.371 Acc@10: 0.666 Acc@100: 0.847 AccSum: 1.884\n",
      "[epoch 33][test] Acc@1: 0.378 Acc@10: 0.671 Acc@100: 0.848 AccSum: 1.897\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.370 Acc@10: 0.666 Acc@100: 0.845 AccSum: 1.881\n",
      "[epoch 35][dev ] Acc@1: 0.371 Acc@10: 0.665 Acc@100: 0.844 AccSum: 1.881\n",
      "[epoch 36][dev ] Acc@1: 0.373 Acc@10: 0.667 Acc@100: 0.846 AccSum: 1.886\n",
      "[epoch 36][test] Acc@1: 0.380 Acc@10: 0.673 Acc@100: 0.847 AccSum: 1.900\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.377 Acc@10: 0.667 Acc@100: 0.847 AccSum: 1.891\n",
      "[epoch 37][test] Acc@1: 0.382 Acc@10: 0.674 Acc@100: 0.848 AccSum: 1.903\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.378 Acc@10: 0.668 Acc@100: 0.849 AccSum: 1.895\n",
      "[epoch 38][test] Acc@1: 0.385 Acc@10: 0.677 Acc@100: 0.849 AccSum: 1.911\n",
      "[best epoch: 38]\n",
      "[epoch 39][dev ] Acc@1: 0.378 Acc@10: 0.668 Acc@100: 0.850 AccSum: 1.897\n",
      "[epoch 39][test] Acc@1: 0.385 Acc@10: 0.678 Acc@100: 0.850 AccSum: 1.913\n",
      "[best epoch: 39]\n",
      "[epoch 40][dev ] Acc@1: 0.379 Acc@10: 0.669 Acc@100: 0.851 AccSum: 1.899\n",
      "[epoch 40][test] Acc@1: 0.386 Acc@10: 0.680 Acc@100: 0.851 AccSum: 1.916\n",
      "[best epoch: 40]\n",
      "[epoch 41][dev ] Acc@1: 0.379 Acc@10: 0.668 Acc@100: 0.852 AccSum: 1.898\n",
      "[epoch 42][dev ] Acc@1: 0.380 Acc@10: 0.667 Acc@100: 0.854 AccSum: 1.901\n",
      "[epoch 42][test] Acc@1: 0.386 Acc@10: 0.682 Acc@100: 0.851 AccSum: 1.919\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.382 Acc@10: 0.667 Acc@100: 0.854 AccSum: 1.903\n",
      "[epoch 43][test] Acc@1: 0.387 Acc@10: 0.682 Acc@100: 0.850 AccSum: 1.919\n",
      "[best epoch: 43]\n",
      "[epoch 44][dev ] Acc@1: 0.384 Acc@10: 0.669 Acc@100: 0.855 AccSum: 1.907\n",
      "[epoch 44][test] Acc@1: 0.388 Acc@10: 0.682 Acc@100: 0.851 AccSum: 1.921\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.385 Acc@10: 0.671 Acc@100: 0.854 AccSum: 1.911\n",
      "[epoch 45][test] Acc@1: 0.390 Acc@10: 0.685 Acc@100: 0.853 AccSum: 1.927\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.385 Acc@10: 0.671 Acc@100: 0.854 AccSum: 1.910\n",
      "[epoch 47][dev ] Acc@1: 0.385 Acc@10: 0.673 Acc@100: 0.854 AccSum: 1.912\n",
      "[epoch 47][test] Acc@1: 0.390 Acc@10: 0.684 Acc@100: 0.853 AccSum: 1.927\n",
      "[best epoch: 47]\n",
      "[epoch 48][dev ] Acc@1: 0.388 Acc@10: 0.673 Acc@100: 0.854 AccSum: 1.914\n",
      "[epoch 48][test] Acc@1: 0.391 Acc@10: 0.684 Acc@100: 0.854 AccSum: 1.929\n",
      "[best epoch: 48]\n",
      "[epoch 49][dev ] Acc@1: 0.388 Acc@10: 0.673 Acc@100: 0.854 AccSum: 1.915\n",
      "[epoch 49][test] Acc@1: 0.392 Acc@10: 0.684 Acc@100: 0.853 AccSum: 1.928\n",
      "[best epoch: 49]\n",
      "[epoch 50][dev ] Acc@1: 0.387 Acc@10: 0.673 Acc@100: 0.854 AccSum: 1.915\n",
      "[epoch 51][dev ] Acc@1: 0.388 Acc@10: 0.673 Acc@100: 0.855 AccSum: 1.916\n",
      "[epoch 51][test] Acc@1: 0.393 Acc@10: 0.686 Acc@100: 0.854 AccSum: 1.933\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.387 Acc@10: 0.675 Acc@100: 0.857 AccSum: 1.919\n",
      "[epoch 52][test] Acc@1: 0.393 Acc@10: 0.686 Acc@100: 0.854 AccSum: 1.934\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.387 Acc@10: 0.676 Acc@100: 0.856 AccSum: 1.920\n",
      "[epoch 53][test] Acc@1: 0.395 Acc@10: 0.686 Acc@100: 0.856 AccSum: 1.937\n",
      "[best epoch: 53]\n",
      "[epoch 54][dev ] Acc@1: 0.390 Acc@10: 0.675 Acc@100: 0.857 AccSum: 1.922\n",
      "[epoch 54][test] Acc@1: 0.396 Acc@10: 0.687 Acc@100: 0.855 AccSum: 1.939\n",
      "[best epoch: 54]\n",
      "[epoch 55][dev ] Acc@1: 0.390 Acc@10: 0.678 Acc@100: 0.857 AccSum: 1.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 55][test] Acc@1: 0.398 Acc@10: 0.685 Acc@100: 0.855 AccSum: 1.938\n",
      "[best epoch: 55]\n",
      "[epoch 56][dev ] Acc@1: 0.391 Acc@10: 0.679 Acc@100: 0.857 AccSum: 1.928\n",
      "[epoch 56][test] Acc@1: 0.397 Acc@10: 0.686 Acc@100: 0.856 AccSum: 1.940\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.390 Acc@10: 0.680 Acc@100: 0.857 AccSum: 1.927\n",
      "[epoch 58][dev ] Acc@1: 0.394 Acc@10: 0.679 Acc@100: 0.859 AccSum: 1.931\n",
      "[epoch 58][test] Acc@1: 0.398 Acc@10: 0.689 Acc@100: 0.857 AccSum: 1.944\n",
      "[best epoch: 58]\n",
      "[epoch 59][dev ] Acc@1: 0.392 Acc@10: 0.678 Acc@100: 0.859 AccSum: 1.929\n",
      "[epoch 60][dev ] Acc@1: 0.393 Acc@10: 0.678 Acc@100: 0.859 AccSum: 1.931\n",
      "[epoch 61][dev ] Acc@1: 0.393 Acc@10: 0.678 Acc@100: 0.861 AccSum: 1.932\n",
      "[epoch 61][test] Acc@1: 0.399 Acc@10: 0.691 Acc@100: 0.858 AccSum: 1.948\n",
      "[best epoch: 61]\n",
      "[epoch 62][dev ] Acc@1: 0.394 Acc@10: 0.680 Acc@100: 0.860 AccSum: 1.934\n",
      "[epoch 62][test] Acc@1: 0.399 Acc@10: 0.690 Acc@100: 0.859 AccSum: 1.948\n",
      "[best epoch: 62]\n",
      "[epoch 63][dev ] Acc@1: 0.395 Acc@10: 0.680 Acc@100: 0.861 AccSum: 1.936\n",
      "[epoch 63][test] Acc@1: 0.401 Acc@10: 0.690 Acc@100: 0.859 AccSum: 1.950\n",
      "[best epoch: 63]\n",
      "[epoch 64][dev ] Acc@1: 0.395 Acc@10: 0.680 Acc@100: 0.862 AccSum: 1.937\n",
      "[epoch 64][test] Acc@1: 0.403 Acc@10: 0.691 Acc@100: 0.860 AccSum: 1.954\n",
      "[best epoch: 64]\n",
      "[epoch 65][dev ] Acc@1: 0.397 Acc@10: 0.680 Acc@100: 0.863 AccSum: 1.940\n",
      "[epoch 65][test] Acc@1: 0.403 Acc@10: 0.691 Acc@100: 0.860 AccSum: 1.954\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.397 Acc@10: 0.680 Acc@100: 0.863 AccSum: 1.941\n",
      "[epoch 66][test] Acc@1: 0.403 Acc@10: 0.690 Acc@100: 0.860 AccSum: 1.953\n",
      "[best epoch: 66]\n",
      "[epoch 67][dev ] Acc@1: 0.399 Acc@10: 0.682 Acc@100: 0.863 AccSum: 1.944\n",
      "[epoch 67][test] Acc@1: 0.404 Acc@10: 0.692 Acc@100: 0.860 AccSum: 1.955\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.399 Acc@10: 0.683 Acc@100: 0.862 AccSum: 1.944\n",
      "[epoch 68][test] Acc@1: 0.403 Acc@10: 0.692 Acc@100: 0.859 AccSum: 1.955\n",
      "[best epoch: 68]\n",
      "[epoch 69][dev ] Acc@1: 0.400 Acc@10: 0.684 Acc@100: 0.862 AccSum: 1.946\n",
      "[epoch 69][test] Acc@1: 0.405 Acc@10: 0.692 Acc@100: 0.860 AccSum: 1.957\n",
      "[best epoch: 69]\n",
      "[epoch 70][dev ] Acc@1: 0.399 Acc@10: 0.684 Acc@100: 0.862 AccSum: 1.944\n",
      "[epoch 71][dev ] Acc@1: 0.400 Acc@10: 0.684 Acc@100: 0.862 AccSum: 1.946\n",
      "[epoch 71][test] Acc@1: 0.405 Acc@10: 0.693 Acc@100: 0.861 AccSum: 1.959\n",
      "[best epoch: 71]\n",
      "[epoch 72][dev ] Acc@1: 0.400 Acc@10: 0.685 Acc@100: 0.863 AccSum: 1.947\n",
      "[epoch 72][test] Acc@1: 0.405 Acc@10: 0.694 Acc@100: 0.861 AccSum: 1.961\n",
      "[best epoch: 72]\n",
      "[epoch 73][dev ] Acc@1: 0.401 Acc@10: 0.685 Acc@100: 0.863 AccSum: 1.949\n",
      "[epoch 73][test] Acc@1: 0.406 Acc@10: 0.695 Acc@100: 0.862 AccSum: 1.962\n",
      "[best epoch: 73]\n",
      "[epoch 74][dev ] Acc@1: 0.403 Acc@10: 0.684 Acc@100: 0.863 AccSum: 1.951\n",
      "[epoch 74][test] Acc@1: 0.406 Acc@10: 0.695 Acc@100: 0.862 AccSum: 1.963\n",
      "[best epoch: 74]\n",
      "[epoch 75][dev ] Acc@1: 0.403 Acc@10: 0.686 Acc@100: 0.864 AccSum: 1.953\n",
      "[epoch 75][test] Acc@1: 0.407 Acc@10: 0.695 Acc@100: 0.863 AccSum: 1.964\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.402 Acc@10: 0.686 Acc@100: 0.863 AccSum: 1.951\n",
      "[epoch 77][dev ] Acc@1: 0.402 Acc@10: 0.686 Acc@100: 0.862 AccSum: 1.950\n",
      "[epoch 78][dev ] Acc@1: 0.403 Acc@10: 0.687 Acc@100: 0.862 AccSum: 1.952\n",
      "[epoch 79][dev ] Acc@1: 0.403 Acc@10: 0.689 Acc@100: 0.863 AccSum: 1.955\n",
      "[epoch 79][test] Acc@1: 0.408 Acc@10: 0.696 Acc@100: 0.863 AccSum: 1.967\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.404 Acc@10: 0.688 Acc@100: 0.862 AccSum: 1.954\n",
      "[epoch 81][dev ] Acc@1: 0.404 Acc@10: 0.688 Acc@100: 0.863 AccSum: 1.956\n",
      "[epoch 81][test] Acc@1: 0.410 Acc@10: 0.698 Acc@100: 0.863 AccSum: 1.971\n",
      "[best epoch: 81]\n",
      "[epoch 82][dev ] Acc@1: 0.404 Acc@10: 0.688 Acc@100: 0.863 AccSum: 1.954\n",
      "[epoch 83][dev ] Acc@1: 0.404 Acc@10: 0.687 Acc@100: 0.863 AccSum: 1.953\n",
      "[epoch 84][dev ] Acc@1: 0.405 Acc@10: 0.688 Acc@100: 0.862 AccSum: 1.955\n",
      "[epoch 85][dev ] Acc@1: 0.404 Acc@10: 0.689 Acc@100: 0.861 AccSum: 1.955\n",
      "[epoch 86][dev ] Acc@1: 0.403 Acc@10: 0.689 Acc@100: 0.863 AccSum: 1.955\n",
      "[epoch 87][dev ] Acc@1: 0.402 Acc@10: 0.690 Acc@100: 0.863 AccSum: 1.956\n",
      "[epoch 88][dev ] Acc@1: 0.402 Acc@10: 0.693 Acc@100: 0.864 AccSum: 1.958\n",
      "[epoch 88][test] Acc@1: 0.412 Acc@10: 0.698 Acc@100: 0.864 AccSum: 1.974\n",
      "[best epoch: 88]\n",
      "[epoch 89][dev ] Acc@1: 0.404 Acc@10: 0.693 Acc@100: 0.864 AccSum: 1.961\n",
      "[epoch 89][test] Acc@1: 0.412 Acc@10: 0.699 Acc@100: 0.864 AccSum: 1.975\n",
      "[best epoch: 89]\n",
      "[epoch 90][dev ] Acc@1: 0.404 Acc@10: 0.692 Acc@100: 0.864 AccSum: 1.960\n",
      "[epoch 91][dev ] Acc@1: 0.404 Acc@10: 0.691 Acc@100: 0.864 AccSum: 1.959\n",
      "[epoch 92][dev ] Acc@1: 0.404 Acc@10: 0.692 Acc@100: 0.864 AccSum: 1.960\n",
      "[epoch 93][dev ] Acc@1: 0.404 Acc@10: 0.695 Acc@100: 0.864 AccSum: 1.963\n",
      "[epoch 93][test] Acc@1: 0.413 Acc@10: 0.700 Acc@100: 0.865 AccSum: 1.978\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.404 Acc@10: 0.695 Acc@100: 0.864 AccSum: 1.963\n",
      "[epoch 95][dev ] Acc@1: 0.405 Acc@10: 0.697 Acc@100: 0.864 AccSum: 1.965\n",
      "[epoch 95][test] Acc@1: 0.415 Acc@10: 0.701 Acc@100: 0.866 AccSum: 1.983\n",
      "[best epoch: 95]\n",
      "[epoch 96][dev ] Acc@1: 0.406 Acc@10: 0.697 Acc@100: 0.864 AccSum: 1.968\n",
      "[epoch 96][test] Acc@1: 0.415 Acc@10: 0.701 Acc@100: 0.866 AccSum: 1.982\n",
      "[best epoch: 96]\n",
      "[epoch 97][dev ] Acc@1: 0.405 Acc@10: 0.696 Acc@100: 0.865 AccSum: 1.966\n",
      "[epoch 98][dev ] Acc@1: 0.407 Acc@10: 0.696 Acc@100: 0.864 AccSum: 1.966\n",
      "[epoch 99][dev ] Acc@1: 0.406 Acc@10: 0.695 Acc@100: 0.864 AccSum: 1.966\n",
      "[epoch 100][dev ] Acc@1: 0.409 Acc@10: 0.696 Acc@100: 0.864 AccSum: 1.969\n",
      "[epoch 100][test] Acc@1: 0.415 Acc@10: 0.702 Acc@100: 0.867 AccSum: 1.984\n",
      "[best epoch: 100]\n"
     ]
    }
   ],
   "source": [
    "model = fc_aligner(input_size=1068, target_size=1068).cuda(GPU_INDEX)\n",
    "train_params = model.parameters()\n",
    "optimizer = torch.optim.AdamW(train_params, lr=1e-4)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train(model, train_params, optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_aligner(\n",
       "  (fc1): Linear(in_features=1068, out_features=1068, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"ft_bert_context_term_to_ft_bert_surface_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = fc_aligner(input_size=1068, target_size=1068).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca6a629a1b346c09152c05a0c775e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.517\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=64, dumb=True, GPU_INDEX=GPU_INDEX)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=256, sample=False, GPU_INDEX=GPU_INDEX)\n",
    "# print (\"MGRD: %.3f MGRD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ft_term+bert_term (multilevel attention) -> ft_surface+bert_surface(+graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target embeddings loaded, search space size: 350830]\n"
     ]
    }
   ],
   "source": [
    "chv_train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "chv_dev_path = os.path.join(DATA_DIR, 'dev.csv')\n",
    "chv_test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "#snomed_vec_path = os.path.join(FEATURE_PATH,\"snomed_surface_fasttext_embeddings_full+snomed_surface_bert_ts100k_embeddings_all_names_mean_full_last_layer_with_ST.pkl\")\n",
    "snomed_vec_path = os.path.join(FEATURE_PATH,\"snomed_surface_fasttext_embeddings_full+snomed_surface_bert_ts100k_embeddings_all_names_mean_full_last_layer_with_ST+snomed_node2vec_300d_20wl_embeddings.pkl\")\n",
    "term_vec_path1 = os.path.join(FEATURE_PATH,\"fasttext_term_embeddings.pkl\")\n",
    "term_vec_path2 = os.path.join(FEATURE_PATH,\"chv_term_embeddings_BERTbr_ts100k_multilevel_all.pkl\")\n",
    "\n",
    "gran=\"specific\"\n",
    "\n",
    "train_dict = build_train_dict(chv_train_path, gran=gran)\n",
    "\n",
    "train_loader, _ = get_loader_mla(FULL_CHV_PATH, chv_train_path, \n",
    "                                 term_vec_path1, term_vec_path2, \n",
    "                                 snomed_vec_path, batch_size=64, \n",
    "                                 shuffle=True, num_workers=10, gran=gran)\n",
    "val_loader, valset = get_loader_mla(FULL_CHV_PATH, chv_dev_path, \n",
    "                                    term_vec_path1, term_vec_path2, \n",
    "                                    snomed_vec_path, batch_size=64, \n",
    "                                    shuffle=False, num_workers=10, gran=gran)\n",
    "test_loader, testset = get_loader_mla(FULL_CHV_PATH, chv_test_path, \n",
    "                                      term_vec_path1, term_vec_path2, \n",
    "                                      snomed_vec_path, batch_size=64,\n",
    "                                      shuffle=False,  num_workers=10, \n",
    "                                      gran=gran, load_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][dev ] Acc@1: 0.000 Acc@10: 0.000 Acc@100: 0.001 AccSum: 0.001\n",
      "[epoch 1][dev ] Acc@1: 0.038 Acc@10: 0.153 Acc@100: 0.347 AccSum: 0.538\n",
      "[epoch 1][test] Acc@1: 0.043 Acc@10: 0.157 Acc@100: 0.348 AccSum: 0.549\n",
      "[best epoch: 1]\n",
      "[epoch 2][dev ] Acc@1: 0.188 Acc@10: 0.452 Acc@100: 0.684 AccSum: 1.324\n",
      "[epoch 2][test] Acc@1: 0.203 Acc@10: 0.458 Acc@100: 0.676 AccSum: 1.337\n",
      "[best epoch: 2]\n",
      "[epoch 3][dev ] Acc@1: 0.278 Acc@10: 0.552 Acc@100: 0.746 AccSum: 1.577\n",
      "[epoch 3][test] Acc@1: 0.283 Acc@10: 0.557 Acc@100: 0.738 AccSum: 1.579\n",
      "[best epoch: 3]\n",
      "[epoch 4][dev ] Acc@1: 0.293 Acc@10: 0.572 Acc@100: 0.764 AccSum: 1.630\n",
      "[epoch 4][test] Acc@1: 0.304 Acc@10: 0.578 Acc@100: 0.762 AccSum: 1.644\n",
      "[best epoch: 4]\n",
      "[epoch 5][dev ] Acc@1: 0.335 Acc@10: 0.611 Acc@100: 0.793 AccSum: 1.739\n",
      "[epoch 5][test] Acc@1: 0.334 Acc@10: 0.611 Acc@100: 0.795 AccSum: 1.740\n",
      "[best epoch: 5]\n",
      "[epoch 6][dev ] Acc@1: 0.346 Acc@10: 0.616 Acc@100: 0.797 AccSum: 1.760\n",
      "[epoch 6][test] Acc@1: 0.346 Acc@10: 0.623 Acc@100: 0.800 AccSum: 1.770\n",
      "[best epoch: 6]\n",
      "[epoch 7][dev ] Acc@1: 0.369 Acc@10: 0.641 Acc@100: 0.821 AccSum: 1.831\n",
      "[epoch 7][test] Acc@1: 0.372 Acc@10: 0.643 Acc@100: 0.820 AccSum: 1.835\n",
      "[best epoch: 7]\n",
      "[epoch 8][dev ] Acc@1: 0.385 Acc@10: 0.659 Acc@100: 0.835 AccSum: 1.879\n",
      "[epoch 8][test] Acc@1: 0.385 Acc@10: 0.665 Acc@100: 0.836 AccSum: 1.886\n",
      "[best epoch: 8]\n",
      "[epoch 9][dev ] Acc@1: 0.387 Acc@10: 0.662 Acc@100: 0.839 AccSum: 1.888\n",
      "[epoch 9][test] Acc@1: 0.393 Acc@10: 0.673 Acc@100: 0.842 AccSum: 1.907\n",
      "[best epoch: 9]\n",
      "[epoch 10][dev ] Acc@1: 0.407 Acc@10: 0.681 Acc@100: 0.854 AccSum: 1.942\n",
      "[epoch 10][test] Acc@1: 0.410 Acc@10: 0.695 Acc@100: 0.857 AccSum: 1.962\n",
      "[best epoch: 10]\n",
      "[epoch 11][dev ] Acc@1: 0.419 Acc@10: 0.694 Acc@100: 0.863 AccSum: 1.976\n",
      "[epoch 11][test] Acc@1: 0.420 Acc@10: 0.708 Acc@100: 0.870 AccSum: 1.998\n",
      "[best epoch: 11]\n",
      "[epoch 12][dev ] Acc@1: 0.421 Acc@10: 0.700 Acc@100: 0.869 AccSum: 1.990\n",
      "[epoch 12][test] Acc@1: 0.428 Acc@10: 0.715 Acc@100: 0.872 AccSum: 2.014\n",
      "[best epoch: 12]\n",
      "[epoch 13][dev ] Acc@1: 0.427 Acc@10: 0.705 Acc@100: 0.867 AccSum: 1.999\n",
      "[epoch 13][test] Acc@1: 0.437 Acc@10: 0.721 Acc@100: 0.877 AccSum: 2.034\n",
      "[best epoch: 13]\n",
      "[epoch 14][dev ] Acc@1: 0.438 Acc@10: 0.721 Acc@100: 0.876 AccSum: 2.035\n",
      "[epoch 14][test] Acc@1: 0.446 Acc@10: 0.733 Acc@100: 0.882 AccSum: 2.061\n",
      "[best epoch: 14]\n",
      "[epoch 15][dev ] Acc@1: 0.445 Acc@10: 0.727 Acc@100: 0.881 AccSum: 2.053\n",
      "[epoch 15][test] Acc@1: 0.452 Acc@10: 0.743 Acc@100: 0.886 AccSum: 2.082\n",
      "[best epoch: 15]\n",
      "[epoch 16][dev ] Acc@1: 0.450 Acc@10: 0.727 Acc@100: 0.880 AccSum: 2.058\n",
      "[epoch 16][test] Acc@1: 0.464 Acc@10: 0.744 Acc@100: 0.889 AccSum: 2.097\n",
      "[best epoch: 16]\n",
      "[epoch 17][dev ] Acc@1: 0.454 Acc@10: 0.733 Acc@100: 0.883 AccSum: 2.071\n",
      "[epoch 17][test] Acc@1: 0.465 Acc@10: 0.753 Acc@100: 0.894 AccSum: 2.113\n",
      "[best epoch: 17]\n",
      "[epoch 18][dev ] Acc@1: 0.462 Acc@10: 0.737 Acc@100: 0.888 AccSum: 2.087\n",
      "[epoch 18][test] Acc@1: 0.473 Acc@10: 0.761 Acc@100: 0.900 AccSum: 2.134\n",
      "[best epoch: 18]\n",
      "[epoch 19][dev ] Acc@1: 0.462 Acc@10: 0.740 Acc@100: 0.890 AccSum: 2.092\n",
      "[epoch 19][test] Acc@1: 0.475 Acc@10: 0.762 Acc@100: 0.900 AccSum: 2.137\n",
      "[best epoch: 19]\n",
      "[epoch 20][dev ] Acc@1: 0.467 Acc@10: 0.748 Acc@100: 0.892 AccSum: 2.107\n",
      "[epoch 20][test] Acc@1: 0.480 Acc@10: 0.769 Acc@100: 0.903 AccSum: 2.151\n",
      "[best epoch: 20]\n",
      "[epoch 21][dev ] Acc@1: 0.472 Acc@10: 0.752 Acc@100: 0.895 AccSum: 2.119\n",
      "[epoch 21][test] Acc@1: 0.484 Acc@10: 0.773 Acc@100: 0.907 AccSum: 2.164\n",
      "[best epoch: 21]\n",
      "[epoch 22][dev ] Acc@1: 0.473 Acc@10: 0.752 Acc@100: 0.896 AccSum: 2.121\n",
      "[epoch 22][test] Acc@1: 0.485 Acc@10: 0.776 Acc@100: 0.906 AccSum: 2.167\n",
      "[best epoch: 22]\n",
      "[epoch 23][dev ] Acc@1: 0.476 Acc@10: 0.759 Acc@100: 0.899 AccSum: 2.135\n",
      "[epoch 23][test] Acc@1: 0.491 Acc@10: 0.781 Acc@100: 0.910 AccSum: 2.183\n",
      "[best epoch: 23]\n",
      "[epoch 24][dev ] Acc@1: 0.487 Acc@10: 0.768 Acc@100: 0.905 AccSum: 2.160\n",
      "[epoch 24][test] Acc@1: 0.503 Acc@10: 0.791 Acc@100: 0.915 AccSum: 2.209\n",
      "[best epoch: 24]\n",
      "[epoch 25][dev ] Acc@1: 0.491 Acc@10: 0.768 Acc@100: 0.907 AccSum: 2.166\n",
      "[epoch 25][test] Acc@1: 0.505 Acc@10: 0.792 Acc@100: 0.916 AccSum: 2.214\n",
      "[best epoch: 25]\n",
      "[epoch 26][dev ] Acc@1: 0.487 Acc@10: 0.763 Acc@100: 0.903 AccSum: 2.153\n",
      "[epoch 27][dev ] Acc@1: 0.488 Acc@10: 0.766 Acc@100: 0.904 AccSum: 2.158\n",
      "[epoch 28][dev ] Acc@1: 0.499 Acc@10: 0.780 Acc@100: 0.913 AccSum: 2.192\n",
      "[epoch 28][test] Acc@1: 0.517 Acc@10: 0.802 Acc@100: 0.919 AccSum: 2.237\n",
      "[best epoch: 28]\n",
      "[epoch 29][dev ] Acc@1: 0.504 Acc@10: 0.785 Acc@100: 0.916 AccSum: 2.205\n",
      "[epoch 29][test] Acc@1: 0.523 Acc@10: 0.809 Acc@100: 0.922 AccSum: 2.255\n",
      "[best epoch: 29]\n",
      "[epoch 30][dev ] Acc@1: 0.502 Acc@10: 0.782 Acc@100: 0.910 AccSum: 2.194\n",
      "[epoch 31][dev ] Acc@1: 0.502 Acc@10: 0.781 Acc@100: 0.910 AccSum: 2.193\n",
      "[epoch 32][dev ] Acc@1: 0.512 Acc@10: 0.788 Acc@100: 0.915 AccSum: 2.215\n",
      "[epoch 32][test] Acc@1: 0.526 Acc@10: 0.808 Acc@100: 0.921 AccSum: 2.255\n",
      "[best epoch: 32]\n",
      "[epoch 33][dev ] Acc@1: 0.512 Acc@10: 0.794 Acc@100: 0.917 AccSum: 2.223\n",
      "[epoch 33][test] Acc@1: 0.533 Acc@10: 0.813 Acc@100: 0.924 AccSum: 2.271\n",
      "[best epoch: 33]\n",
      "[epoch 34][dev ] Acc@1: 0.514 Acc@10: 0.796 Acc@100: 0.917 AccSum: 2.228\n",
      "[epoch 34][test] Acc@1: 0.536 Acc@10: 0.813 Acc@100: 0.925 AccSum: 2.273\n",
      "[best epoch: 34]\n",
      "[epoch 35][dev ] Acc@1: 0.516 Acc@10: 0.800 Acc@100: 0.917 AccSum: 2.233\n",
      "[epoch 35][test] Acc@1: 0.538 Acc@10: 0.812 Acc@100: 0.924 AccSum: 2.274\n",
      "[best epoch: 35]\n",
      "[epoch 36][dev ] Acc@1: 0.523 Acc@10: 0.802 Acc@100: 0.919 AccSum: 2.244\n",
      "[epoch 36][test] Acc@1: 0.541 Acc@10: 0.816 Acc@100: 0.925 AccSum: 2.282\n",
      "[best epoch: 36]\n",
      "[epoch 37][dev ] Acc@1: 0.529 Acc@10: 0.804 Acc@100: 0.921 AccSum: 2.254\n",
      "[epoch 37][test] Acc@1: 0.546 Acc@10: 0.819 Acc@100: 0.927 AccSum: 2.292\n",
      "[best epoch: 37]\n",
      "[epoch 38][dev ] Acc@1: 0.527 Acc@10: 0.805 Acc@100: 0.919 AccSum: 2.251\n",
      "[epoch 39][dev ] Acc@1: 0.527 Acc@10: 0.807 Acc@100: 0.918 AccSum: 2.253\n",
      "[epoch 40][dev ] Acc@1: 0.527 Acc@10: 0.809 Acc@100: 0.918 AccSum: 2.254\n",
      "[epoch 41][dev ] Acc@1: 0.533 Acc@10: 0.811 Acc@100: 0.920 AccSum: 2.264\n",
      "[epoch 41][test] Acc@1: 0.552 Acc@10: 0.824 Acc@100: 0.929 AccSum: 2.305\n",
      "[best epoch: 41]\n",
      "[epoch 42][dev ] Acc@1: 0.540 Acc@10: 0.810 Acc@100: 0.922 AccSum: 2.272\n",
      "[epoch 42][test] Acc@1: 0.555 Acc@10: 0.824 Acc@100: 0.929 AccSum: 2.309\n",
      "[best epoch: 42]\n",
      "[epoch 43][dev ] Acc@1: 0.540 Acc@10: 0.810 Acc@100: 0.922 AccSum: 2.271\n",
      "[epoch 44][dev ] Acc@1: 0.541 Acc@10: 0.809 Acc@100: 0.921 AccSum: 2.272\n",
      "[epoch 44][test] Acc@1: 0.556 Acc@10: 0.825 Acc@100: 0.929 AccSum: 2.310\n",
      "[best epoch: 44]\n",
      "[epoch 45][dev ] Acc@1: 0.546 Acc@10: 0.816 Acc@100: 0.922 AccSum: 2.284\n",
      "[epoch 45][test] Acc@1: 0.563 Acc@10: 0.831 Acc@100: 0.930 AccSum: 2.324\n",
      "[best epoch: 45]\n",
      "[epoch 46][dev ] Acc@1: 0.546 Acc@10: 0.817 Acc@100: 0.922 AccSum: 2.285\n",
      "[epoch 46][test] Acc@1: 0.566 Acc@10: 0.833 Acc@100: 0.932 AccSum: 2.330\n",
      "[best epoch: 46]\n",
      "[epoch 47][dev ] Acc@1: 0.544 Acc@10: 0.816 Acc@100: 0.922 AccSum: 2.283\n",
      "[epoch 48][dev ] Acc@1: 0.546 Acc@10: 0.816 Acc@100: 0.921 AccSum: 2.283\n",
      "[epoch 49][dev ] Acc@1: 0.546 Acc@10: 0.816 Acc@100: 0.922 AccSum: 2.284\n",
      "[epoch 49][test] Acc@1: 0.565 Acc@10: 0.831 Acc@100: 0.931 AccSum: 2.328\n",
      "[best epoch: 49]\n",
      "[epoch 50][dev ] Acc@1: 0.551 Acc@10: 0.819 Acc@100: 0.925 AccSum: 2.294\n",
      "[epoch 50][test] Acc@1: 0.570 Acc@10: 0.836 Acc@100: 0.933 AccSum: 2.338\n",
      "[best epoch: 50]\n",
      "[epoch 51][dev ] Acc@1: 0.554 Acc@10: 0.819 Acc@100: 0.926 AccSum: 2.299\n",
      "[epoch 51][test] Acc@1: 0.572 Acc@10: 0.838 Acc@100: 0.933 AccSum: 2.343\n",
      "[best epoch: 51]\n",
      "[epoch 52][dev ] Acc@1: 0.555 Acc@10: 0.819 Acc@100: 0.923 AccSum: 2.297\n",
      "[epoch 52][test] Acc@1: 0.572 Acc@10: 0.836 Acc@100: 0.931 AccSum: 2.339\n",
      "[best epoch: 52]\n",
      "[epoch 53][dev ] Acc@1: 0.555 Acc@10: 0.818 Acc@100: 0.922 AccSum: 2.295\n",
      "[epoch 54][dev ] Acc@1: 0.557 Acc@10: 0.820 Acc@100: 0.925 AccSum: 2.302\n",
      "[epoch 54][test] Acc@1: 0.577 Acc@10: 0.839 Acc@100: 0.932 AccSum: 2.347\n",
      "[best epoch: 54]\n",
      "[epoch 55][dev ] Acc@1: 0.562 Acc@10: 0.823 Acc@100: 0.926 AccSum: 2.311\n",
      "[epoch 55][test] Acc@1: 0.578 Acc@10: 0.841 Acc@100: 0.935 AccSum: 2.354\n",
      "[best epoch: 55]\n",
      "[epoch 56][dev ] Acc@1: 0.566 Acc@10: 0.825 Acc@100: 0.926 AccSum: 2.317\n",
      "[epoch 56][test] Acc@1: 0.579 Acc@10: 0.841 Acc@100: 0.933 AccSum: 2.353\n",
      "[best epoch: 56]\n",
      "[epoch 57][dev ] Acc@1: 0.564 Acc@10: 0.822 Acc@100: 0.926 AccSum: 2.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 58][dev ] Acc@1: 0.564 Acc@10: 0.821 Acc@100: 0.925 AccSum: 2.310\n",
      "[epoch 59][dev ] Acc@1: 0.568 Acc@10: 0.825 Acc@100: 0.926 AccSum: 2.319\n",
      "[epoch 59][test] Acc@1: 0.583 Acc@10: 0.843 Acc@100: 0.935 AccSum: 2.360\n",
      "[best epoch: 59]\n",
      "[epoch 60][dev ] Acc@1: 0.574 Acc@10: 0.829 Acc@100: 0.929 AccSum: 2.332\n",
      "[epoch 60][test] Acc@1: 0.587 Acc@10: 0.844 Acc@100: 0.937 AccSum: 2.367\n",
      "[best epoch: 60]\n",
      "[epoch 61][dev ] Acc@1: 0.574 Acc@10: 0.829 Acc@100: 0.930 AccSum: 2.332\n",
      "[epoch 62][dev ] Acc@1: 0.571 Acc@10: 0.826 Acc@100: 0.927 AccSum: 2.324\n",
      "[epoch 63][dev ] Acc@1: 0.573 Acc@10: 0.827 Acc@100: 0.927 AccSum: 2.327\n",
      "[epoch 64][dev ] Acc@1: 0.572 Acc@10: 0.832 Acc@100: 0.928 AccSum: 2.332\n",
      "[epoch 65][dev ] Acc@1: 0.575 Acc@10: 0.832 Acc@100: 0.929 AccSum: 2.336\n",
      "[epoch 65][test] Acc@1: 0.590 Acc@10: 0.848 Acc@100: 0.934 AccSum: 2.373\n",
      "[best epoch: 65]\n",
      "[epoch 66][dev ] Acc@1: 0.575 Acc@10: 0.830 Acc@100: 0.927 AccSum: 2.332\n",
      "[epoch 67][dev ] Acc@1: 0.576 Acc@10: 0.830 Acc@100: 0.928 AccSum: 2.334\n",
      "[epoch 67][test] Acc@1: 0.588 Acc@10: 0.848 Acc@100: 0.934 AccSum: 2.370\n",
      "[best epoch: 67]\n",
      "[epoch 68][dev ] Acc@1: 0.574 Acc@10: 0.833 Acc@100: 0.928 AccSum: 2.336\n",
      "[epoch 69][dev ] Acc@1: 0.576 Acc@10: 0.834 Acc@100: 0.929 AccSum: 2.339\n",
      "[epoch 69][test] Acc@1: 0.592 Acc@10: 0.849 Acc@100: 0.934 AccSum: 2.374\n",
      "[best epoch: 69]\n",
      "[epoch 70][dev ] Acc@1: 0.576 Acc@10: 0.834 Acc@100: 0.929 AccSum: 2.339\n",
      "[epoch 71][dev ] Acc@1: 0.576 Acc@10: 0.834 Acc@100: 0.928 AccSum: 2.339\n",
      "[epoch 72][dev ] Acc@1: 0.581 Acc@10: 0.833 Acc@100: 0.928 AccSum: 2.342\n",
      "[epoch 72][test] Acc@1: 0.593 Acc@10: 0.850 Acc@100: 0.934 AccSum: 2.377\n",
      "[best epoch: 72]\n",
      "[epoch 73][dev ] Acc@1: 0.582 Acc@10: 0.834 Acc@100: 0.928 AccSum: 2.344\n",
      "[epoch 73][test] Acc@1: 0.594 Acc@10: 0.850 Acc@100: 0.935 AccSum: 2.378\n",
      "[best epoch: 73]\n",
      "[epoch 74][dev ] Acc@1: 0.585 Acc@10: 0.835 Acc@100: 0.929 AccSum: 2.348\n",
      "[epoch 74][test] Acc@1: 0.598 Acc@10: 0.851 Acc@100: 0.936 AccSum: 2.385\n",
      "[best epoch: 74]\n",
      "[epoch 75][dev ] Acc@1: 0.588 Acc@10: 0.835 Acc@100: 0.930 AccSum: 2.353\n",
      "[epoch 75][test] Acc@1: 0.600 Acc@10: 0.854 Acc@100: 0.936 AccSum: 2.390\n",
      "[best epoch: 75]\n",
      "[epoch 76][dev ] Acc@1: 0.586 Acc@10: 0.835 Acc@100: 0.929 AccSum: 2.351\n",
      "[epoch 77][dev ] Acc@1: 0.586 Acc@10: 0.835 Acc@100: 0.928 AccSum: 2.349\n",
      "[epoch 78][dev ] Acc@1: 0.588 Acc@10: 0.834 Acc@100: 0.927 AccSum: 2.349\n",
      "[epoch 79][dev ] Acc@1: 0.589 Acc@10: 0.835 Acc@100: 0.929 AccSum: 2.353\n",
      "[epoch 79][test] Acc@1: 0.603 Acc@10: 0.850 Acc@100: 0.935 AccSum: 2.388\n",
      "[best epoch: 79]\n",
      "[epoch 80][dev ] Acc@1: 0.588 Acc@10: 0.837 Acc@100: 0.930 AccSum: 2.356\n",
      "[epoch 81][dev ] Acc@1: 0.590 Acc@10: 0.839 Acc@100: 0.932 AccSum: 2.361\n",
      "[epoch 81][test] Acc@1: 0.603 Acc@10: 0.854 Acc@100: 0.939 AccSum: 2.396\n",
      "[best epoch: 81]\n",
      "[epoch 82][dev ] Acc@1: 0.591 Acc@10: 0.839 Acc@100: 0.930 AccSum: 2.360\n",
      "[epoch 82][test] Acc@1: 0.604 Acc@10: 0.855 Acc@100: 0.937 AccSum: 2.396\n",
      "[best epoch: 82]\n",
      "[epoch 83][dev ] Acc@1: 0.592 Acc@10: 0.839 Acc@100: 0.928 AccSum: 2.359\n",
      "[epoch 83][test] Acc@1: 0.605 Acc@10: 0.854 Acc@100: 0.936 AccSum: 2.395\n",
      "[best epoch: 83]\n",
      "[epoch 84][dev ] Acc@1: 0.591 Acc@10: 0.840 Acc@100: 0.928 AccSum: 2.360\n",
      "[epoch 85][dev ] Acc@1: 0.593 Acc@10: 0.842 Acc@100: 0.928 AccSum: 2.363\n",
      "[epoch 85][test] Acc@1: 0.607 Acc@10: 0.855 Acc@100: 0.936 AccSum: 2.398\n",
      "[best epoch: 85]\n",
      "[epoch 86][dev ] Acc@1: 0.593 Acc@10: 0.843 Acc@100: 0.930 AccSum: 2.366\n",
      "[epoch 87][dev ] Acc@1: 0.594 Acc@10: 0.841 Acc@100: 0.928 AccSum: 2.363\n",
      "[epoch 87][test] Acc@1: 0.609 Acc@10: 0.855 Acc@100: 0.936 AccSum: 2.400\n",
      "[best epoch: 87]\n",
      "[epoch 88][dev ] Acc@1: 0.592 Acc@10: 0.840 Acc@100: 0.928 AccSum: 2.361\n",
      "[epoch 89][dev ] Acc@1: 0.594 Acc@10: 0.839 Acc@100: 0.928 AccSum: 2.361\n",
      "[epoch 89][test] Acc@1: 0.609 Acc@10: 0.854 Acc@100: 0.934 AccSum: 2.398\n",
      "[best epoch: 89]\n",
      "[epoch 90][dev ] Acc@1: 0.598 Acc@10: 0.839 Acc@100: 0.929 AccSum: 2.366\n",
      "[epoch 90][test] Acc@1: 0.610 Acc@10: 0.854 Acc@100: 0.935 AccSum: 2.398\n",
      "[best epoch: 90]\n",
      "[epoch 91][dev ] Acc@1: 0.600 Acc@10: 0.841 Acc@100: 0.929 AccSum: 2.370\n",
      "[epoch 91][test] Acc@1: 0.610 Acc@10: 0.853 Acc@100: 0.936 AccSum: 2.400\n",
      "[best epoch: 91]\n",
      "[epoch 92][dev ] Acc@1: 0.600 Acc@10: 0.839 Acc@100: 0.929 AccSum: 2.369\n",
      "[epoch 92][test] Acc@1: 0.611 Acc@10: 0.855 Acc@100: 0.936 AccSum: 2.402\n",
      "[best epoch: 92]\n",
      "[epoch 93][dev ] Acc@1: 0.600 Acc@10: 0.839 Acc@100: 0.928 AccSum: 2.368\n",
      "[epoch 93][test] Acc@1: 0.611 Acc@10: 0.855 Acc@100: 0.935 AccSum: 2.401\n",
      "[best epoch: 93]\n",
      "[epoch 94][dev ] Acc@1: 0.601 Acc@10: 0.841 Acc@100: 0.927 AccSum: 2.369\n",
      "[epoch 94][test] Acc@1: 0.610 Acc@10: 0.855 Acc@100: 0.935 AccSum: 2.399\n",
      "[best epoch: 94]\n",
      "[epoch 95][dev ] Acc@1: 0.600 Acc@10: 0.842 Acc@100: 0.928 AccSum: 2.371\n",
      "[epoch 96][dev ] Acc@1: 0.601 Acc@10: 0.844 Acc@100: 0.931 AccSum: 2.376\n",
      "[epoch 97][dev ] Acc@1: 0.603 Acc@10: 0.843 Acc@100: 0.931 AccSum: 2.376\n",
      "[epoch 97][test] Acc@1: 0.612 Acc@10: 0.856 Acc@100: 0.934 AccSum: 2.403\n",
      "[best epoch: 97]\n",
      "[epoch 98][dev ] Acc@1: 0.602 Acc@10: 0.842 Acc@100: 0.927 AccSum: 2.371\n",
      "[epoch 99][dev ] Acc@1: 0.601 Acc@10: 0.841 Acc@100: 0.925 AccSum: 2.366\n",
      "[epoch 100][dev ] Acc@1: 0.600 Acc@10: 0.839 Acc@100: 0.923 AccSum: 2.363\n"
     ]
    }
   ],
   "source": [
    "model = mla_bert_ft_ensemble(target_len=1368).cuda(GPU_INDEX)\n",
    "#save_path = \"bert_context_term_to_surface_attn_state_dict.pkl\"\n",
    "#model.mla_bert.load_state_dict(torch.load(save_path))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = TripletLoss(margin=0.2, max_violation=True, device=GPU_INDEX)\n",
    "\n",
    "best_sd = train_joint(model, model.parameters(), optimizer, criterion, \\\n",
    "      train_loader, val_loader, valset, test_loader, \\\n",
    "      testset, num_epoch=100, dor=0.0, GPU_INDEX=GPU_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mla_bert_ft_ensemble(\n",
       "  (mla_bert): multilevel_attention(\n",
       "    (self_attn): SelfAttention()\n",
       "  )\n",
       "  (fc): Linear(in_features=1068, out_features=1368, bias=True)\n",
       "  (fc_aligner): fc_aligner(\n",
       "    (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"ensemble_w_graph_state_dict.pkl\"\n",
    "torch.save(best_sd, save_path)\n",
    "model = mla_bert_ft_ensemble(target_len=1368).cuda(GPU_INDEX)\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18c8045ff8642d792774da4deee88f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=69.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MRR: 0.702\n"
     ]
    }
   ],
   "source": [
    "mrr = evalMRR(test_loader, model, testset.search_space_embeddings, bsz=64, dumb=True, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "print (\"MRR: %.3f\" % mrr)\n",
    "\n",
    "# gds = evalGD(test_loader, testset, model, topk=10, dor=0.0, bsz=128, \\\n",
    "#              dumb=False, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "# print (\"MGRD: %.3f MGRD@10: %.3f\" % gds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio attempted by heuristics: 69.3%\n",
      "0.596932936598764\n",
      "[dict+smatch+model] Acc@1: 0.734 Acc@10: 0.815 Acc@100: 0.857 Acc sum: 2.405\n"
     ]
    }
   ],
   "source": [
    "# Dict + Neural\n",
    "# accs, pred_dict = compute_metrics_backoff(test_loader, testset, model, sf2id=None, train_dict=train_dict, \\\n",
    "#                            ed_dict=None, topks=(1,10,100), bsz=128, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "# print (\"[dict+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "#        (accs[0], accs[1], accs[2], sum(accs)))\n",
    "\n",
    "# # Exact Match + Neural\n",
    "# accs, pred_dict= compute_metrics_backoff(test_loader, testset, model, sf2id=SF2ID, train_dict=None, \\\n",
    "#                            ed_dict=None, topks=(1,10,100), bsz=128, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "# print (\"[smatch+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "#        (accs[0], accs[1], accs[2], sum(accs)))\n",
    "\n",
    "# # Dict + Exact Match + Neural\n",
    "# accs, pred_dict= compute_metrics_backoff(test_loader, testset, model, sf2id=SF2ID, train_dict=train_dict, \\\n",
    "#                            ed_dict=None, topks=(1,10,100), bsz=128, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "# print (\"[dict+smatch+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "#        (accs[0], accs[1], accs[2], sum(accs)))\n",
    "\n",
    "# Dict + Stoilos + Neural\n",
    "accs, pred_dict= compute_metrics_backoff(test_loader, testset, model, sf2id=SF2ID, train_dict=train_dict, \\\n",
    "                           ed_dict=None, topks=(1,10,100), bsz=64, GPU_INDEX=GPU_INDEX, ensemble=True)\n",
    "print (\"[dict+smatch+model] Acc@1: %.3f Acc@10: %.3f Acc@100: %.3f Acc sum: %.3f\" % \\\n",
    "       (accs[0], accs[1], accs[2], sum(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.967px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
